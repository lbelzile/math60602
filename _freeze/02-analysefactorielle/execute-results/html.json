{
  "hash": "8578b9e97e84e267feaf2f33931b0296",
  "result": {
    "markdown": "# Réduction de la dimension {#analyse-factorielle}\n\n\n::: {.cell file='_common.R' hash='02-analysefactorielle_cache/html/setup_b4751a045b38b460a92d0ea731915a0a'}\n\n:::\n\n\n\n## Introduction\n\nCe chapitre traite de réduction de la dimensionalité d'un problème d'analyse multidimensionnelle. On dispose de $p$ variables $X_1, \\ldots, X_p$: comment résumer cet ensemble avec moins de variables (disons $k$) tout en conservant le plus de variabilité possible? Nous couvrons deux méthodes dans ce chapitre: la première, intitulée **analyse en composantes principales**, cherche à **réduire le nombre de variables explicatives** tout en préservant le plus possible de variabilité exprimée et en créant de nouvelles variables explicatives qui ne sont pas corrélées les unes avec les autres.\n\nLa deuxième, appelée analyse factorielle exploratoire, cherche à expliquer la structure de corrélation entre les $p$ variables à l'aide d'un nombre restreint de facteurs. Elle répond aux questions suivantes: \n\n- Y a-t-il des groupements de variables?\n- Est-ce que les variables faisant partie d'un groupement semblent mesurer certains aspects d'un facteur commun (non observé)? \n\nDe tels groupements peuvent être détecté si plusieurs variables sont très corrélées entre elles. Une analyse factorielle cherchera à identifier automatiquement ces groupes de variables.\n \n\nLes facteurs sont des variables latentes qui mesurent des constructions. Par exemple, l'habileté quantitative, habileté sociale, importance accordée à la qualité du service, importance accordée à la loyauté, habileté de leader, etc.\n\nL'analyse factorielle est aussi une méthode de réduction du nombre de variables. En effet, une fois qu'on a identifié les facteurs, on peut remplacer les variables individuelles par un résumé pour chaque facteur (qui est souvent la moyenne des variables qui font partie du facteur). \n\n\n## Coefficient de corrélation linéaire\n\nOn veut examiner la relation entre deux variables $X_j$ et $X_k$ et on dispose de $n$ couples d'observations, où $x_{i, j}$ (respectivement $x_{i, k}$) est la valeur de la variable $X_j$ ($X_k$) pour la $i$e observation.\n\nLe coefficient de corrélation linéaire entre $X_j$ et $X_k$, que l'on note $r_{j, k}$, cherche à mesurer la force de la relation linéaire entre deux variables, c'est-à-dire à quantifier à quel point les observations sont alignées autour d'une droite. Le coefficient de corrélation est \n\\begin{align*}\nr_{j, k} &= \\frac{\\widehat{\\mathsf{Co}}(X_j, X_k)}{\\{\\widehat{\\mathsf{Va}}(X_j) \\widehat{\\mathsf{Va}}(X_k)\\}^{1/2}} \n%\\\\&=\\frac{\\sum_{i=1}^n (x_{i, j}-\\overline{x}_j)(x_{i, k} -\\overline{x}_{k})}{\\left\\{\\sum_{i=1}^n (x_{i, j}-\\overline{x}_j)^2 \\sum_{i=1}^n(x_{i, k} -\\overline{x}_{k})^2\\right\\}^{1/2}}\n\\end{align*}\n\nLes propriétés les plus importantes du coefficient de corrélation linéaire $r$ sont les suivantes:\n\n1) $-1 \\leq r \\leq 1$;\n2) $r=1$ (respectivement $r=-1$) si et seulement si les $n$ observations sont exactement alignées sur une droite de pente positive (négative). C'est-à-dire, s'il existe deux constantes $a$ et $b>0$ ($b<0$) telles que $y_i=a+b x_i$ pour tout $i=1, \\ldots, n$.\n\nRègle générale, \n\n- Le signe de la corrélation détermine l'orientation de la pente (négative ou positive)\n- Plus la corrélation est près de 1 en valeur absolue, plus les points auront tendance à être alignés autour d'une droite.\n- Lorsque la corrélation est presque nulle, les points n'auront pas tendance à être alignés autour d'une droite. Il est très important de noter que cela n'implique pas qu'il n'y a pas de relation entre les deux variables. Cela implique seulement qu'il n'y a pas de **relation linéaire** entre les deux variables. La @fig-datasaurus montre bien ce point: ces jeux de données ont la même corrélation linéaire (quasi-nulle), mais ne sont pas clairement pas indépendantes puisqu'elles permettent de dessiner un dinosaure ou une étoile.\n\n::: {.content-visible when-format=\"pdf\"}\n\n![Datasaurus (Alberto Cairo): une douzaine de jeux de données qui ont les mêmes statistiques descriptives (à deux décimales près) et une faible corrélation, mais qui sont visuellement distincts.](figures/DataSaurusDozen.png){#fig-datasaurus}\n\n:::\n\n::: {.content-visible when-format=\"html\"}\n\n\n::: {.cell layout-align=\"center\" hash='02-analysefactorielle_cache/html/fig-datasaurus_f0d775b0bcc68e1ac5fec5d28f6f2fa0'}\n::: {.cell-output-display}\n![Datasaurus (Alberto Cairo): une douzaine de jeux de données qui ont les mêmes statistiques descriptives (à deux décimales près) et dont les deux variables sont très faiblement corrélées.](figures/DataSaurusDozen.gif){#fig-datasaurus fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n\nLa matrice de corrélation entre $X_1, \\ldots, X_p$, dont l'entrée $(i, j)$ contient la corrélation entre $X_i$ et $X_j$, est une matrice symmétrique dont les éléments de la diagonale sont égaux à 1. À mesure que le nombre de variables augmente, le nombre de corrélations à estimer augmente: puisque la matrice est $p \\times p$, ce nombre augmente comme le carré du nombre de variables explicatives. L'estimation ne sera pas fiable à moins que $n \\gg p$.\n\n## Présentation des données\n\nLe questionnaire suivant porte sur une étude dans un magasin. Pour les besoins d'une enquête, on a demandé à 200 consommateurs adultes de répondre aux questions suivantes par rapport à un certain type de magasin sur une échelle de 1 à 5, où \n\n1. pas important\n2. peu important\n3. moyennement important\n4. assez important\n5. très important\n\nPour vous, à quel point est-ce important\\ldots\n\n1. que le magasin offre de bons prix tous les jours?\n2. que le magasin accepte les cartes de crédit majeures (Visa, Mastercard)?\n3. que le magasin offre des produits de qualité?\n4. que les vendeurs connaissent bien les produits?\n5. qu'il y ait des ventes spéciales régulièrement?\n6. que les marques connues soient disponibles?\n7. que le magasin ait sa propre carte de crédit?\n8. que le service soit rapide?\n9. qu'il y ait une vaste sélection de produits?\n10. que le magasin accepte le paiement par carte de débit?\n11. que le personnel soit courtois?\n12. que le magasin ait en stock les produits annoncés?\n\n\nLes statistiques descriptives ainsi que la matrice des corrélations sont obtenues en exécutant les lignes suivantes:\n\n\n::: {.cell layout-align=\"center\" hash='02-analysefactorielle_cache/html/correlation-facto_8c3d2bcbde4cb44eb268871f9bae74c5'}\n\n```{.r .cell-code}\ndata(factor, package = \"hecmulti\")\n# Matrice de corrélation\ncor(factor)\n# Statistiques descriptives\nsummary(factor)\n```\n:::\n\n::: {#tbl-corrmat .cell layout-align=\"center\" tbl-cap='Matrice de corrélation de `factor`.' hash='02-analysefactorielle_cache/html/tbl-corrmat_3a1b2ed239ec783063ddae3a06068a98'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> x1 </th>\n   <th style=\"text-align:right;\"> x2 </th>\n   <th style=\"text-align:right;\"> x3 </th>\n   <th style=\"text-align:right;\"> x4 </th>\n   <th style=\"text-align:right;\"> x5 </th>\n   <th style=\"text-align:right;\"> x6 </th>\n   <th style=\"text-align:right;\"> x7 </th>\n   <th style=\"text-align:right;\"> x8 </th>\n   <th style=\"text-align:right;\"> x9 </th>\n   <th style=\"text-align:right;\"> x10 </th>\n   <th style=\"text-align:right;\"> x11 </th>\n   <th style=\"text-align:right;\"> x12 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> x1 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> -0.08 </td>\n   <td style=\"text-align:right;\"> -0.14 </td>\n   <td style=\"text-align:right;\"> -0.07 </td>\n   <td style=\"text-align:right;\"> 0.38 </td>\n   <td style=\"text-align:right;\"> -0.01 </td>\n   <td style=\"text-align:right;\"> -0.10 </td>\n   <td style=\"text-align:right;\"> -0.13 </td>\n   <td style=\"text-align:right;\"> -0.03 </td>\n   <td style=\"text-align:right;\"> -0.11 </td>\n   <td style=\"text-align:right;\"> -0.12 </td>\n   <td style=\"text-align:right;\"> -0.01 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x2 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> -0.02 </td>\n   <td style=\"text-align:right;\"> -0.08 </td>\n   <td style=\"text-align:right;\"> 0.06 </td>\n   <td style=\"text-align:right;\"> 0.50 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> -0.01 </td>\n   <td style=\"text-align:right;\"> 0.43 </td>\n   <td style=\"text-align:right;\"> -0.12 </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x3 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 0.10 </td>\n   <td style=\"text-align:right;\"> -0.06 </td>\n   <td style=\"text-align:right;\"> 0.39 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.47 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.13 </td>\n   <td style=\"text-align:right;\"> 0.46 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x4 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> -0.05 </td>\n   <td style=\"text-align:right;\"> 0.06 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.57 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n   <td style=\"text-align:right;\"> 0.50 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x5 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> -0.04 </td>\n   <td style=\"text-align:right;\"> -0.04 </td>\n   <td style=\"text-align:right;\"> -0.02 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n   <td style=\"text-align:right;\"> -0.07 </td>\n   <td style=\"text-align:right;\"> -0.06 </td>\n   <td style=\"text-align:right;\"> -0.07 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x6 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.32 </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n   <td style=\"text-align:right;\"> -0.04 </td>\n   <td style=\"text-align:right;\"> 0.32 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x7 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n   <td style=\"text-align:right;\"> -0.02 </td>\n   <td style=\"text-align:right;\"> 0.51 </td>\n   <td style=\"text-align:right;\"> -0.03 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x8 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> -0.03 </td>\n   <td style=\"text-align:right;\"> 0.16 </td>\n   <td style=\"text-align:right;\"> 0.55 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x9 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n   <td style=\"text-align:right;\"> 0.39 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x10 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x11 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x12 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='02-analysefactorielle_cache/html/fig-corrmat_150f1008b2b14ebb357e9af07b990c80'}\n::: {.cell-output-display}\n![Corrélogramme de la base de données `factor`.](02-analysefactorielle_files/figure-html/fig-corrmat-1.png){#fig-corrmat fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n::: {.content-visible when-format=\"pdf\"}\n\n\n::: {#tbl-statdescriptfactorpdf .cell layout-align=\"center\" tbl-cap='Statistiques descriptives des 12 variables du jeu de données factor.' hash='02-analysefactorielle_cache/html/tbl-statdescriptfactorpdf_ce23767f6c5e2fcc45e5580c0dd6e86e'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> moyenne </th>\n   <th style=\"text-align:right;\"> écart-type </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> max </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 2.26 </td>\n   <td style=\"text-align:right;\"> 1.13 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.51 </td>\n   <td style=\"text-align:right;\"> 1.24 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3.00 </td>\n   <td style=\"text-align:right;\"> 1.19 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.91 </td>\n   <td style=\"text-align:right;\"> 1.33 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3.55 </td>\n   <td style=\"text-align:right;\"> 1.17 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.14 </td>\n   <td style=\"text-align:right;\"> 1.14 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1.82 </td>\n   <td style=\"text-align:right;\"> 1.06 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.92 </td>\n   <td style=\"text-align:right;\"> 1.32 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3.04 </td>\n   <td style=\"text-align:right;\"> 1.12 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.59 </td>\n   <td style=\"text-align:right;\"> 1.32 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.98 </td>\n   <td style=\"text-align:right;\"> 1.33 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3.45 </td>\n   <td style=\"text-align:right;\"> 1.16 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n:::\n\n::: {.content-visible when-format=\"html\"}\n\n\n::: {#tbl-statdescriptfactorhtml .cell layout-align=\"center\" tbl-cap='Statistiques descriptives des 12 variables du jeu de données factor.' hash='02-analysefactorielle_cache/html/tbl-statdescriptfactorhtml_90d0a0d78325760992be5350e8489f09'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> moyenne </th>\n   <th style=\"text-align:right;\"> écart-type </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:left;\"> histogramme </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 2.26 </td>\n   <td style=\"text-align:right;\"> 1.13 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▇▇▆▃▁ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.51 </td>\n   <td style=\"text-align:right;\"> 1.24 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▇▇▇▅▂ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3.00 </td>\n   <td style=\"text-align:right;\"> 1.19 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▃▆▇▇▃ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.91 </td>\n   <td style=\"text-align:right;\"> 1.33 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▆▇▇▆▅ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3.55 </td>\n   <td style=\"text-align:right;\"> 1.17 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▂▃▇▇▇ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.14 </td>\n   <td style=\"text-align:right;\"> 1.14 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▇▅▅▂▁ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1.82 </td>\n   <td style=\"text-align:right;\"> 1.06 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▇▃▂▁▁ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.92 </td>\n   <td style=\"text-align:right;\"> 1.32 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▆▇▇▇▅ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3.04 </td>\n   <td style=\"text-align:right;\"> 1.12 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▃▃▇▇▂ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.59 </td>\n   <td style=\"text-align:right;\"> 1.32 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▇▆▆▅▂ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2.98 </td>\n   <td style=\"text-align:right;\"> 1.33 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▆▅▇▆▅ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3.45 </td>\n   <td style=\"text-align:right;\"> 1.16 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> ▂▃▇▇▆ </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n:::\n\n\nOn voit dans la @fig-corrmat que quelques groupes de variables sont corrélés entre eux. On peut également regrouper certaines questions sous des thèmes manuellement: le but de l'analyse factorielle sera d'automatiser ce regroupement.\n\n## Analyse en composantes principales\n\nLe but de l'analyse en composantes principales est de réduire le nombre de variables explicatives. En partant de $p$ variables $X_1, \\ldots, X_p$, on forme de nouvelles variables qui sont des combinaisons linéaires des variables originales, \n\\begin{align*}\nC_j &= \\underset{\\text{somme de poids fois variables explicatives}}{w_{j1} X_1 + w_{j2} X_2 + \\cdots + w_{jp} X_p}, \\qquad (j=1, \\ldots, p),\n\\\\\n1 &= \\underset{\\text{poids standardisés}}{w_{j1}^2 + \\cdots + w_{jp}^2}\n\\end{align*}\nde telle sorte que \n\n- La première variable formée, $C_1$, appelée première composante principale, possède la variance maximale parmi toutes les combinaisons linéaires sous la contrainte $w_{1i}^2 + \\cdots + w_{1p}^2=1$.^[Les contraintes  sur les poids sont nécessaires afin de standardiser le problème car il serait possible d'avoir des variances infinies sinon.]\n- Pour $j=2, \\ldots, p$, la $j$e composante principale $C_j$ possède la variance maximale parmi toutes les combinaisons linéaires qui sont non corrélées avec $C_1, \\ldots, C_{j-1}$  sous la contrainte $w_{j1}^2 + \\cdots + w_{jp}^2=1$.\n\nAinsi, les composantes principales forment un ensemble de variables non corrélées entre elles, qui récupèrent en ordre décroissant le plus possible de la variance des variables originales. La somme des variances des $p$ composantes principales est égale à la somme des variances des $p$ variables originales. \n\nMathématiquement, les composantes principales correspondent aux vecteurs propres de la matrice de covariance, mais on peut également utiliser la matrice de corrélation^[La fonction `princomp` peut directement utiliser la base de données numériques, ou la matrice de covariance. Dans le premier cas, on peut spécifier que l'on veut la décomposition de la matrice de corrélation à l'aide de l'argument, `cor`]. L'avantage de la matrice de corrélation (ou de la standardisation des variables) est que l'unité de mesure n'impacte pas le résultat; autrement, un poids plus important est attribué aux variables qui ont la plus forte hétérogénéité.\n\nSi on conserve toutes les composantes principales, cela revient à changer le système de coordonnées dans lequel sont exprimées nos observations en effectuant une rotation: avec deux variables, on on trouve la direction dans le système 2D dans lequel l'étendue est la plus grande. Si une simple rotation peut sembler inutile, la méthode est fort utile en haute dimension. On espère en général qu'un petit nombre de composantes principales réussira à expliquer la plus grande partie de la variance totale. \n\n\n::: {.cell layout-align=\"center\" hash='02-analysefactorielle_cache/html/fig-acprotation_438ebc3aa48bf33e8c668ed85dfcf376'}\n::: {.cell-output-display}\n![Nuage de points avant (gauche) et après (droite) analyse en composantes principales. Les directions des composantes principales (lignes pleines et traitillés), qui forment un angle droit, sont ajoutées au nuage de points à gauche. On peut constater que la corrélation entre les deux composantes principales est nulle.](02-analysefactorielle_files/figure-html/fig-acprotation-1.png){#fig-acprotation fig-align='center' width=90%}\n:::\n:::\n\n\nLa @fig-acprotation démontre cette décomposition sur des données bidimensionnelles simulées. La variance des données dans le premier panneau est 13.51 pour l'axe des abscisse et 6.43 pour l'axe des ordonnées avec une corrélation de 0.86, à comparer avec des variances de 18.65 et 1.21 et une corrélation nulle entre les deux composantes principales.\n\nDans une analyse en composantes principales, on conservera un nombre $k<p$ de variables explicatives pour résumer les données. Ce outil est utilisé à des fins exploratoires, puisqu'on n'implique pas de variable réponse dans le modèle.\nL'analyse en composantes principales est utilisé pour réduire la dimension afin de faire de la classification, de l'analyse de regroupements et aussi réduire les coûts associés à ces méthodes en projetant les données dans un sous-espace de dimension plus faible.\n\nEn **R**, on effectue l'analyse en composantes principales avec la fonction `princomp` ou `prcomp`^[La différence entre les deux sorties est due à deux choses: `princomp` utilise la décomposition en valeurs propres avec $n^{-1}\\mathbf{X}^\\top\\mathbf{X}$ pour la matrice de covariance, tandis que `prcomp` utilise la décomposition en valeurs singulières avec un dénominateur de $n-1$; cette dernière option est plus stable numériquement. On pourrait aussi utiliser `eigen(cor(factor))` pour extraire directement la décomposition en valeurs propres/vecteurs propres, mais on n'aurait pas accès aux méthodes pour la visualisation.].\n\nLa sortie contient \n\n- les coordonnées des composantes principales, `acp$scores`; la première est celle qui a la plus grande variabilité.\n- l'écart-type de chaque composante, `acp$sdev`. Chaque écart-type est la racine carrée d'une des valeurs propres. \n- les poids $w_{ij}$, appelés chargements (*loadings*), qui donnent la correspondance entre le système de coordonnées des composantes principales et celui des variables $\\boldsymbol{X}$ originales.\n\n\nOn peut représenter les données à l'aide d'un bigramme: c'est une nuage de points de chaque observations dans l'espace des deux premières composantes principales. Si on couple cela avec les directions offertes par les chargements pour chacune des variables explicatives $X_1, \\ldots, X_p$, il en ressort que certaines variables augmentent/diminuent de pair. Ainsi, on voit dans la @fig-biplot que les variables `x3`, `x6`, `x9` et `x12` tendent dans la même direction, comme `x4`, `x8` et `x11`. On reviendra sur ce point dans une section subséquente.\n\n\nUne fois qu'on a choisit le nombre de composantes, on pourrait ne conserver que les $k$ premières colonnes de la matrice des composantes principales `acp$scores` pour faire les graphiques ou pour approximer la matrice de covariance. Il faut garder en tête qu'il faudra néanmoins collecter les mêmes questions pour recréer les composantes principales avec de nouvelles observations, ce qui est peu commode si on veut réduire le coût de la collecte. \n\n\n\n::: {.cell layout-align=\"center\" hash='02-analysefactorielle_cache/html/acpfactor_3e153e2d1fdafef1619748527353215c'}\n\n```{.r .cell-code}\n# Analyse en composantes principales\n# de la matrice de corrélation\nacp <- princomp(factor, cor = TRUE)\nloadings(acp) # chargements\nbiplot(acp) # bigramme\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='02-analysefactorielle_cache/html/fig-biplot_a4aa1393bae457218f3e05a0eaec6b6d'}\n::: {.cell-output-display}\n![Bigramme: nuage de point des coordonnées des deux premières composantes principales et direction selon chargements des variables explicatives originales.](02-analysefactorielle_files/figure-html/fig-biplot-1.png){#fig-biplot fig-align='center' width=60%}\n:::\n:::\n\n\nOn peut étudier la sortie pour vérifier les propriétés de notre décomposition. Le @tbl-eigenvalues montre la variance de chaque composante principale. Si on additionne l'ensemble des variances (sans arrondir), on obtient une variance cumulative des 12 composantes principales, 12, soit le même que le nombre de variables explicatives puisque les variables standardisées ont variance unitaire. Si on calcule la matrice de corrélation, `cor(acp$scores)`, on remarquera que la corrélation est nulle entre les variables.\n\n\n::: {#tbl-eigenvalues .cell layout-align=\"center\" tbl-align='center' tbl-cap='Variance des composantes principales' hash='02-analysefactorielle_cache/html/tbl-eigenvalues_4abb1b12e4ba93508685a0c84208bf8e'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> C1 </th>\n   <th style=\"text-align:center;\"> C2 </th>\n   <th style=\"text-align:center;\"> C3 </th>\n   <th style=\"text-align:center;\"> C4 </th>\n   <th style=\"text-align:center;\"> C5 </th>\n   <th style=\"text-align:center;\"> C6 </th>\n   <th style=\"text-align:center;\"> C7 </th>\n   <th style=\"text-align:center;\"> C8 </th>\n   <th style=\"text-align:center;\"> C9 </th>\n   <th style=\"text-align:center;\"> C10 </th>\n   <th style=\"text-align:center;\"> C11 </th>\n   <th style=\"text-align:center;\"> C12 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 2.43 </td>\n   <td style=\"text-align:center;\"> 2.00 </td>\n   <td style=\"text-align:center;\"> 1.94 </td>\n   <td style=\"text-align:center;\"> 1.30 </td>\n   <td style=\"text-align:center;\"> 0.74 </td>\n   <td style=\"text-align:center;\"> 0.69 </td>\n   <td style=\"text-align:center;\"> 0.57 </td>\n   <td style=\"text-align:center;\"> 0.54 </td>\n   <td style=\"text-align:center;\"> 0.51 </td>\n   <td style=\"text-align:center;\"> 0.47 </td>\n   <td style=\"text-align:center;\"> 0.46 </td>\n   <td style=\"text-align:center;\"> 0.36 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n### Choix du nombre de composantes principales {#sec-acp-choix}\n\nSi on désire réduire la dimension, il nous faudra choisir $k \\leq p$ variables. Cette section traite du choix du nombre de variables explicatives à retenir. Idéalement, ce nombre devrait être beaucoup plus petit que le nombre original de variables. \n\nUne première approche est de regarder le pourcentage de la variance totale expliquée. Puisque les composantes principales sont ordonnées en ordre décroissant de variance, on peut étudier la variance cumulative des $k$ premières composantes et choisir un nombre qui explique le plus possible. Si l'ajout d'une variable augmente peu la variabilité totale expliquée par l'ensemble, alors cette variable est probablement superflue. On pourrait choisir un nombre de composantes pour expliquer un pourcentage prédéfini de la vairance totale, disons 70%. Deux autres critères couramment employés sont:\n\n- **critère du coude de Cattell**: ce critère consiste à sélectionner un nombre de composantes dans le diagramme d'éboulis  (`screeplot`), un graphique des variances des composantes principales^[Soit les valeurs propres de la matrice de covariance ou corrélation]. Habituellement, il y a une décroissance rapide de la variance suivie d'un plateau: on prendra le nombre de composantes qui correspond au $k$ juste avant l'apparition du plateau (le début du coude, où il a stabilisation apparente). C'est un critère très subjectif, puisqu'il y a souvent plusieurs plateaux et que la variance peut décroître très lentement. On peut utiliser la fonction `screeplot` pour obtenir le diagramme d'éboulis mais il est facile de le créer manuellement et le résultat est esthétiquement plus réussi.\n- **critère des valeurs propres de Kaiser**: un critère basé sur les valeurs propres de la matrice de corrélation. Le nombre de facteurs choisis est le nombre de composantes principales dont la variance est supérieures à 1. L’idée est de garder seulement les facteurs qui expliquent plus de variance qu’une variable individuelle. \n\nSi on utilise le critère de Kaiser avec les données `factor`, on conservera 4 composantes principales qui expliqueront 63.9 pourcent de la variance totale des variables originales - voir le @tbl-eigenvalues. Le diagramme d'éboulis de la @fig-screeplot, qui peut être produit avec la fonction `hecmulti::eboulis(eigen(cor(factor))` suggère quant à lui cinq composantes.\n\n\n::: {.cell layout-align=\"center\" hash='02-analysefactorielle_cache/html/fig-screeplot_8646fe490d643d3b03d9bfb40fbcbafb'}\n::: {.cell-output-display}\n![Diagramme d'éboulis (gauche) représentant la variance des composantes principales (en ordonnée) en fonction du nombre composantes principales (en abscisse). Variance cumulative en fonction du nombre de composantes principales (droite).](02-analysefactorielle_files/figure-html/fig-screeplot-1.png){#fig-screeplot fig-align='center' width=85%}\n:::\n:::\n\n\nUne fois qu'on a déterminé le nombre de facteurs, on peut extraire les nouvelles variables explicatives à partir de l'analyse en composantes principales. Les colonnes sont stockées dans `acp$score` et il suffit de conserver les premières colonnes.\n\n### Formulation mathématique\n\nCe complément d'information est optionnel.\n\nMathématiquement, le problème de l'analyse en composantes principales revient à calculer la décomposition en valeurs propres et vecteurs propres de la matrice de covariance $\\mathsf{Co}(\\boldsymbol{X})=\\boldsymbol{\\Sigma}$.\nOn peut écrire\n\\begin{align*}\n\\boldsymbol{\\Sigma} = \\boldsymbol{Q}\\boldsymbol{\\Lambda}\\boldsymbol{Q}^\\top\n\\end{align*}\noù $\\boldsymbol{\\Lambda} = \\mathrm{diag}\\{\\lambda_1, \\ldots, \\lambda_p\\}$ est une matrice diagonale contenant les valeurs propres en ordre décroissant ($\\lambda_1 \\geq \\cdots \\geq \\lambda_p > 0$) et $\\boldsymbol{Q}$ est une matrice carrée $p \\times p$ orthogonale contenant les vecteurs propres.\nLa meilleure approximation de rang $k \\leq p$ de $\\boldsymbol{\\Sigma}$ est obtenue en spécifiant\n\\begin{align*}\n\\widetilde{\\boldsymbol{\\Sigma}}_k = \\sum_{j=1}^k \\lambda_j \\boldsymbol{q}_j\\boldsymbol{q}_j^\\top,\n\\end{align*}\nune combinaison des vecteurs propres $\\boldsymbol{q}_1, \\ldots, \\boldsymbol{q}_k \\in \\mathbb{R}^p$ non corrélés.\n\n\n::: {.callout-note}\n\n## En résumé\n\n- La corrélation mesure la force de la dépendance linéaire entre deux variables: plus elle est élevée, plus les points s'alignent.\n- Si le nombre de variables explicatives $p$ est conséquent par rapport au nombre d'observations $n$, on a peu d'information disponible pour estimer de manière fiable les corrélations.\n- Une analyse en composante principales fait une décomposition en valeurs propres/vecteurs propres de la matrice de covariance ou de corrélation. \n   - Ces nouvelles variables sont orthogonales (corrélation nulle) entre elles.\n   - Les composantes principales sont ordonnées en ordre décroissant de variance: si on ne conserve que $k<p$ de variables, on maximise la variance expliquée.\n   - Le choix du nombre de variables est basé sur des règles du pouce: le critère des valeurs propres de Kaiser suggère de prendre autant de composantes principales que de variances supérieures à 1.\n    - Un bigramme permet de représenter graphiquement les directions des variables en fonction des deux premières composantes principales.\n    \n    \n:::\n\n## Analyse factorielle exploratoire\n\nSi le bigramme a permis de faire ressortir quelques orientations communes, on aimerait aller plus loin dans notre exploration.\nOn considère encore une fois la matrice de covariance associée avec $p$ variables explicatives $X_1, \\ldots, X_p$: le modèle d'analyse factorielle cherche à décrire cette dernière en fonction d'un plus petit nombre de paramètres.\n\nConceptuellement, le modèle d'analyse factorielle suppose qu'on peut regrouper les variables explicatives numériques (parfois avec quelques variables binaires) à l'aide de concepts communs appelés facteurs. Certaines variables explicatives devraient donc idéalement être fortements corrélées entre elles. Le choix des variables est dicté par le bon sens: on inclut dans le modèle des variables qui peuvent logiquement être associée, par exemple des items de questionnaires excluant les données sociodémographiques.\n\n\nLe modèle d'analyse factorielle fait l'hypothèse que les variables dépendent linéairement d'un plus petit nombre de variables aléatoires, $F_1, \\ldots, F_m$, appelées facteurs communs. Cette relation n'est pas parfaite, aussi on inclut $p$ termes d'aléas $\\varepsilon_1, \\ldots, \\varepsilon_p$, de moyenne zéro et de variance $\\mathsf{Va}(\\varepsilon_i)=\\psi_i$ ($i=1, \\ldots, p$). À des fins d'identifiabilité,  on suppose que les aléas ne sont pas corrélées aux facteurs $F$ et entre elles et que les facteurs $F_1, \\ldots, F_m$  ont une moyenne nulle et une variance unitaire, donc $\\mathsf{E}(F_i)=0$ et $\\mathsf{Va}(F_i)=1$ ($i=1, \\ldots, p$).\n\n\nLe modèle d'analyse factorielle s'écrit\n\\begin{align*}\n\\boldsymbol{X} &= \\underset{\\text{moyenne}}{\\boldsymbol{\\mu}} + \\underset{\\text{combinaison linéaire de facteurs latents}}{\\boldsymbol{\\Gamma}\\boldsymbol{F}} + \\underset{\\text{aléa}}{\\boldsymbol{\\varepsilon}},\n\\end{align*}\nou si on écrit le système ligne par ligne,\n\\begin{align*}\nX_1 &= \\mu_1 + \\gamma_{11}F_1 + \\gamma_{12} F_2 + \\cdots + \\gamma_{1m}F_m + \\varepsilon_1\\\\\nX_2 &= \\mu_2 + \\gamma_{21}F_1 + \\gamma_{22} F_2 + \\cdots + \\gamma_{2m}F_m + \\varepsilon_2\\\\\n&\\vdots \\\\\nX_p &= \\mu_p + \\gamma_{p1}F_1 + \\gamma_{p2} F_2 + \\cdots + \\gamma_{pm}F_m + \\varepsilon_p, \n\\end{align*}\noù $\\mu_i$ est l'espérance (moyenne théorique) de la variable aléatoire $X_i$, $\\boldsymbol{\\Gamma}$ est une matrice $p \\times m$ avec éléments $\\gamma_{ij}$, qui représentent le chargement (poids) de la variable $X_i$ sur le facteur $F_j$ ($i=1, \\ldots, p$; $j=1, \\ldots, m$).\n\nLes espérances ($\\mu_i$), les chargements ($\\gamma_{ij}$) et les variances ($\\psi_i$) sont des quantités fixes, mais inconnues, tandis que les facteurs communs ($F_i$) et les aléas ($\\varepsilon_i$) sont des variables aléatoires non observables.\n\nSelon ce modèle, on obtient\n\\begin{align*}\n\\mathsf{Va}(\\boldsymbol{X}) &= \\boldsymbol{\\Gamma}\\mathsf{Va}(\\boldsymbol{F})\\boldsymbol{\\Gamma}^\\top + \\mathsf{Va}(\\boldsymbol{\\varepsilon})\\\\\n& = \\boldsymbol{\\Gamma}\\boldsymbol{\\Gamma}^\\top + \\mathrm{diag}(\\boldsymbol{\\psi}).\n\\end{align*}\nLes éléments diagonaux de cette matrice sont  $\\mathsf{Va}(X_j) = \\sum_{l=1}^k \\gamma_{jl}^2 + \\psi_j$: on appelle **communalité** le terme $h_j = \\sum_{l=1}^k \\gamma_{jl}^2$, qui représente la proportion de variance totale de $X_j$ due à la corrélation entre les facteurs. Le terme $\\psi_j$ est dénommé **unicité**.\n\nSi les variables ont été préalablement standardisées de telle sorte que $\\mathsf{E}(X_i)=0$ et $\\mathsf{Va}(X_i)=1$ (ce qui revient à utiliser la matrice de corrélation des observations dans l'analyse), alors $\\mathsf{Cor}(X_i, F_j)=\\gamma_{ij}$, c'est-à-dire, le chargement de la variable $X_i$ sur le facteur $F_j$ est le coefficient de corrélation entre les deux.\n\nSans aucune contrainte sur le modèle, la matrice de covariance de $X_1, \\ldots, X_p$ possède $p(p+1)/2$ paramètres, soit $p$ variances et $p(p-1)/2$ termes de corrélation. Avec le modèle d’analyse factorielle, on suppose que l’on peut décrire cette structure en utilisant seulement $p(m+1) - m(m-1)/2$ paramètres^[Soit $p$ variances spécifiques et $pm$ chargements, moins les contraintes de diagonalisation dues à l'invariance du modèle à des rotations orthogonales.]. Par exemple, avec $p=50$ variables explicatives et $m=6$ facteurs, on essaie de décrire la structure de covariance à l’aide de 350 paramètres au lieu de 1275.\n\n\nPour faire une analyse factorielle, la taille d’échantillon devrait être quand même conséquente: le nombre d’entrées dans la base de données est $np$ et ce nombre représente la quantité d'unités (information) disponible pour estimer les covariances. Plusieurs références suggèrent d’avoir une taille d’échantillon entre cinq et 20 fois le fois le nombre de variables, ou bien un nombre minimal de 100 à 1000 observations. Des études de simulations suggèrent que la taille critique dépend des paramètres, communalités, distribution des données, etc. Ces règles du pouce sont donc essentiellement arbitraires.\n\nIl existe plusieurs méthodes pour extraire les facteurs, c'est-à-dire pour estimer les paramètres du modèle (les $\\psi_i$ et les $\\gamma_{ij}$). Nous allons discuter de deux d'entre elles: la méthode du maximum de vraisemblance et la méthode des composantes principales. L'avantage de l'estimation par maximum de vraisemblance est qu'elle permet l'utilisation de critères d'information et de statistiques de tests pour guider le choix du nombre de facteurs, en supposant toutefois la normalité des facteurs et des aléas. \n\n\n### Rotation des facteurs\n\nDans le modèle d’analyse factorielle, on peut montrer que, lorsqu’il y a deux facteurs ou plus, il existe plusieurs configurations de facteurs qui donnent la même structure de covariance. En fait, les chargements peuvent seulement être déterminés à une transformation orthogonale près^[Une transformation orthogonale est une transformation qui préserve le produit scalaire; elle préserve ainsi toutes les distances et les angles entre deux vecteurs.]. Si les chargements provenant d’une méthode d’extraction des facteurs ne sont pas uniques, la matrice de corrélation estimée par le modèle est par contre unique.\n\nIl existe plusieurs techniques de rotation de facteurs. Le but de ces techniques est d’essayer de trouver une solution qui fera en sorte que les facteurs seront facilement interprétables. La méthode la plus utilisée est la méthode **varimax**: elle produit une configuration de chargement en maximisant la variance de la somme des carrés des chargements pour les $m$ facteurs. \n\nLa méthode varimax tend à produire une configuration de facteurs tel que les chargements de chaque variable sont dispersés (des chargements élevés positifs ou négatifs et d’autres presque nuls). Il est conseillé de toujours tenter d’interpréter la solution avec une rotation varimax. Si ce n’est pas suffisamment clair, il existe d’autres méthodes de rotation dont certaines (les rotations de type oblique) permettent la présence de corrélation entre les facteurs. \n\n\n\n#### Estimation par la méthode des composantes principales\n\nLa façon la plus simple d'estimer les chargements est d'utiliser la méthode des composantes principales en prenant comme estimation \n\\begin{align*}\n\\widehat{\\boldsymbol{\\Gamma}} = \\boldsymbol{Q}_{1:m} \\mathrm{diag}(\\lambda_1^{1/2}, \\ldots, \\lambda_m^{1/2}),\n\\end{align*}\noù $\\lambda_j$ est la $j$e plus grande valeur propre de la matrice de covariance empirique $\\mathbf{S}$ et $\\boldsymbol{Q}_{1:m}$ est la sous-matrice formée par les $m$ premières colonnes de vecteurs propres de $\\boldsymbol{Q}$. On peut estimer les variances des aléas à travers \n\\begin{align*}\n\\widehat{\\boldsymbol{\\psi}} = \\mathrm{diag}\\left(\\mathbf{S} - \\widehat{\\boldsymbol{\\Gamma}}\\widehat{\\boldsymbol{\\Gamma}}^\\top\\right).\n\\end{align*}\nL'avantage de cette approche est que l'on peut utiliser la même décomposition en valeurs propres et vecteurs propres pour chaque valeur de $m$: seule la rotation dépend de la dimension choisie. La solution est également toujours valide avec la garantie que $\\widehat{\\psi}_j>0$. On peut utiliser la discussion de la @sec-acp-choix pour choisir le nombre de variables.\n\n\n::: {.cell layout-align=\"center\" hash='02-analysefactorielle_cache/html/acp-factor_ed067ea5088d7f340b21dc08f4c3020b'}\n\n```{.r .cell-code}\n# Solution (chargements) avec rotation varimax\nfacto_cp <- hecmulti::factocp(factor, nfact = \"kaiser\", cor = TRUE)\n```\n:::\n\n\n#### Estimation par maximum de vraisemblance\n\nSi on suppose que les aléas et les facteurs suivent des lois Gaussiennes, alors on peut obtenir une forme explicite pour la fonction de vraisemblance de la matrice de covariance.\nL'estimation des paramètres requiert une optimisation numérique qui est souvent difficile et qui mène parfois à des solutions paradoxales. On obtient un cas de quasi-Heywood quand $h_j=1$ pour une variable $j$, (on parle de cas de Heywood si $h_j > 1$). Si on modélise des variables explicatives centrées réduites, $\\mathsf{Va}(X_j)=1$, d'où un problème d'interprétation car le terme $\\psi_j$ serait nul (cas de quasi-Heywood) ou négatif (cas de Heywood) alors même que ce terme représente la variance du $j$e aléa. Les cas de quasi-Heywood ont plusieurs causes, lesquelles sont listées dans la [documentation **SAS**](https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_factor_sect022.htm). Souvent, c'est dû à l'utilisation d'un trop petit ou trop grand nombre de facteurs ou une taille d'échantillon trop petite, etc. Cela complique l'interprétation et nous amène à questionner la validité du modèle d'analyse factorielle comme simplification de la structure de covariance.\n\n\nLes chargements estimés pour la solution à quatre facteurs, suite à la rotation varimax, sont obtenus avec le code suivant:\n\n\n::: {.cell layout-align=\"center\" hash='02-analysefactorielle_cache/html/factanal4_0ec5cf3ce41447c5a3d06d71a443ea51'}\n\n```{.r .cell-code}\n# Ajuster le modèle factoriel par maximum de vraisemblance\nfa4 <- factanal(x = factor, \n                factors = 4L)\n# Imprimer les chargements en omettant les valeurs inférieures à 0.3\nprint(fa4$loadings, \n      cutoff = 0.3)\n```\n:::\n\n::: {#tbl-factanal4 .cell layout-align=\"center\" tbl-cap='Estimés des chargements (multipliés par 100) pour le modèle à quatres facteurs avec rotation varimax estimé à l\\'aide de la méthode du maximum de vraisemblance. Les chargements inférieurs à 0.3 sont omis.' hash='02-analysefactorielle_cache/html/tbl-factanal4_5fc130322b88093ed5c2144af0bb3fd9'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> F1 </th>\n   <th style=\"text-align:right;\"> F2 </th>\n   <th style=\"text-align:right;\"> F3 </th>\n   <th style=\"text-align:right;\"> F4 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> x1 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 99 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x2 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 67 </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x3 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 75 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x4 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x5 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 37 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x6 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 51 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x7 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 75 </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x8 </td>\n   <td style=\"text-align:right;\"> 79 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x9 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x10 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 66 </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x11 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x12 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 61 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nOn constate à la lecture du @tbl-factanal4 des chargements que le chargement associé à la première variable est de 0.992 pour le facteur 4: cela correspondrait à un facteur avec une corrélation de presque un, donc $F_4 \\approx X_1$. Le modèle obtenu avec la méthode du maximum de vraisemblance n'est donc pas adéquat puisque l'optimisation a convergée vers un cas de quasi-Heywood et que le facteur n'est pas une variable latente, mais une des variables de la base de données de départ. Pour diagnostiquer le tout, on peut aussi analyser les valeurs d'unicité: la minimum de `min(fa4$uniqueness)` est 0.005, ce qui correspond à la tolérance de l'algorithme (valeur minimale permise dans l'optimisation), voir `?factanal`.  On retourne à la planche à dessin en réduisant le nombre de variables.\n\nEn général, on associe une variable à un groupe (facteur) si son chargement est supérieur à 0.3 (en valeur absolue), ce qui donne\n\n- Facteur 1: $X_4$, $X_8$ et $X_{11}$\n- Facteur 2: $X_3$, $X_6$, $X_9$ et $X_{12}$\n- Facteur 3: $X_2$, $X_7$ et $X_{10}$\n- Facteur 4: $X_1$ et $X_5$.\n\nCe point de coupure est arbitraire et peut être augmenté si on note qu'il y a trop de variables disparates. Le signe des chargements est arbitraires.\n\nCes facteurs sont interprétables:\n\n- Le facteur 1 représente l’importance accordée au service.\n- Le facteur 2 représente l’importance accordée aux produits.\n- Le facteur 3 représente l’importance accordée à la facilité de paiement.\n- Le facteur 4 représente l’importance accordée aux prix.\n\nDans cet exemple, les choses se sont bien passées et le nombre de facteurs que nous avons spécifié semble être adéquat (hormis le cas de quasi-Heywood), mais ce n'est pas toujours aussi évident. Il est utile d'avoir des outils pour guider le choix du nombre de facteurs.\n\n### Choix du nombre de facteurs\n\nIl existe différentes méthodes pour se guider dans le nombre de facteurs, $m$, à utiliser. Cependant, le point important à retenir est que, peu importe le nombre choisi, il faut que les facteurs soient **interprétables**. Par conséquent, les méthodes qui\nsuivent ne devraient servir que de guide et non pas être suivies aveuglément.\nLa méthode du maximum de vraisemblance que nous avons utilisée dans l’exemple possède l’avantage de fournir trois critères pour choisir le nombre de facteurs appropriés. Ces critères sont: \n\n- le critère d'information d'Akaike (AIC)\n- le critère d'information bayésien de Schwarz (BIC)\n- le test du rapport de vraisemblance pour l'hypothèse nulle que le modèle de corrélation décrit le modèle factoriel avec $m$ facteurs est adéquat, contre l'alternative qu'il n'est pas adéquat.\n\nLes critères d'information servent à la sélection de modèles; ils seront traités plus en détail dans les chapitres qui suivent. Pour l’instant, il est suffisant de savoir que le modèle avec la valeur du critère AIC (ou BIC) la plus petite est considéré le « meilleur » (selon ce critère).\n\nLe paquet `hecmulti` contient des méthodes pour extraire la log-vraisemblance, les critères d'information pour un modèle d'analyse factorielle  (objet de classe `factanal`).\nOn peut extraire la valeur-$p$ pour le test du rapport de vraisemblance comparant le modèle à 12 variables (corrélation empirique) avec le modèle simplifié obtenu en utilisant quatre facteurs: une valeur-$p$ supérieur à un seuil prédéfini (typiquement $\\alpha=0.05$)  indique que la simplification est adéquate puisqu'on ne rejette pas l'hypothèse nulle. La sortie suivante dans le @tbl-emvcrit présente les diagnostics du modèle en fonction du nombre de facteurs pour les modèles ajustés selon la méthode du maximum de vraisemblance.\n\n\n::: {.cell layout-align=\"center\" hash='02-analysefactorielle_cache/html/emv-criteres_7e539078dc08a95505d4d9e0cd5c0556'}\n\n```{.r .cell-code}\nlibrary(hecmulti)\najustement_factanal(\n    covmat = cov(factor),\n    factors = 1:5,\n    n.obs = nrow(factor))\n```\n:::\n\n::: {#tbl-emvcrit .cell layout-align=\"center\" tbl-cap='Ajustement de modèles d\\'analyse factorielle par la méthode du maximum de vraisemblance pour différent nombres de facteurs: critères d\\'informations AIC et BIC, valeur-_p_ du test de rapport de vraisemblance, nombre de paramètres estimés et indicateur pour les cas de (quasi)-Heywood' hash='02-analysefactorielle_cache/html/tbl-emvcrit_a00534b47f87ede1c062ac0ad1ad790b'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> k </th>\n   <th style=\"text-align:right;\"> AIC </th>\n   <th style=\"text-align:right;\"> BIC </th>\n   <th style=\"text-align:left;\"> valeur-p </th>\n   <th style=\"text-align:right;\"> npar </th>\n   <th style=\"text-align:right;\"> heywood </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 2267 </td>\n   <td style=\"text-align:right;\"> 2346 </td>\n   <td style=\"text-align:left;\"> &lt; 2e-16 </td>\n   <td style=\"text-align:right;\"> 24 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 2138 </td>\n   <td style=\"text-align:right;\"> 2253 </td>\n   <td style=\"text-align:left;\"> &lt; 2e-16 </td>\n   <td style=\"text-align:right;\"> 35 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 2017 </td>\n   <td style=\"text-align:right;\"> 2166 </td>\n   <td style=\"text-align:left;\"> 0.09604 </td>\n   <td style=\"text-align:right;\"> 45 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 2003 </td>\n   <td style=\"text-align:right;\"> 2181 </td>\n   <td style=\"text-align:left;\"> 0.97262 </td>\n   <td style=\"text-align:right;\"> 54 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 2013 </td>\n   <td style=\"text-align:right;\"> 2217 </td>\n   <td style=\"text-align:left;\"> 0.97445 </td>\n   <td style=\"text-align:right;\"> 62 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nLe nombre de facteurs à utiliser selon le AIC est 4, \nversus 3 selon le BIC. Le nombre mimimal de critères selon le test du rapport de vraisemblance est NA. Ainsi, on retient la solution à trois facteurs dans tous les cas: cette adéquation entre les critères est l'exception plutôt que la règle.\n\n\nIl faut garder en tête que l'estimation par maximum de vraisemblance du modèle d'analyse factorielle est très sensible à l'initialisation: on peut aussi parfois obtenir des valeurs différentes selon les logiciels. Cette fragilité, couplée à la haute fréquence de cas de Heywood, fait en sorte que je préfère utiliser la méthode des composantes principales pour l'estimation.\n\nOn peut considérer le modèle avec trois facteurs: les chargements (après rotation varimax) sont données dans le @tbl-factanal3\n\n\n::: {#tbl-factanal3 .cell layout-align=\"center\" tbl-cap='Estimés des chargements (multipliés par 100) pour le modèle à trois facteurs avec rotation varimax estimé à l\\'aide de la méthode du maximum de vraisemblance. Les chargements inférieurs à 0.3 sont omis.' hash='02-analysefactorielle_cache/html/tbl-factanal3_cdfc33c23b20bdeb6cd4ad7f93d491bc'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> F1 </th>\n   <th style=\"text-align:right;\"> F2 </th>\n   <th style=\"text-align:right;\"> F3 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> x1 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x2 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 67 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x3 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 76 </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x4 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x5 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x6 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x7 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 75 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x8 </td>\n   <td style=\"text-align:right;\"> 79 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x9 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x10 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 67 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x11 </td>\n   <td style=\"text-align:right;\"> 72 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x12 </td>\n   <td style=\"text-align:right;\">  </td>\n   <td style=\"text-align:right;\"> 60 </td>\n   <td style=\"text-align:right;\">  </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nCette solution récupère les trois facteurs _service_, _produits_ et _paiement_ de la solution précédente à quatre facteurs. Le facteur _prix_ (qui était formé de $X_1$ et $X_5$) n’est plus présent.\n\nOn suggère d'utiliser les trois critères découlant de l'utilisation de la vraisemblance et de déterminer le nombre de facteurs à extraire selon différents critères avant d'examiner les modèles avec ce nombre de facteurs et ceux\navec un facteur de moins ou de plus. Au final, le plus important est de pouvoir interpréter raisonnablement les facteurs: la configuration de facteurs choisie est logique et compréhensible. \n\n### Construction d'échelles à partir des facteurs\n\nSi le seul but de l’analyse factorielle est de comprendre la structure de corrélation entre les variables, alors se limiter à l’interprétation des facteurs est suffisant.\n\nSi par contre, le but est de réduire le nombre de variables pour pouvoir par la suite procéder à d’autres analyses statistiques, l’analyse factorielle peut alors servir de guide pour construire de nouvelles variables (échelles). En supposant que l’analyse factorielle a produit des facteurs qui sont interprétables et satisfaisants, la méthode de construction d’échelles la plus couramment utilisée consiste à construire $m$ nouvelles variables, une par facteur. Pour un facteur donné, la nouvelle variable est simplement la moyenne des variables ayant des chargements élevés sur ce facteur. Une autre méthode, les scores factoriels, sera présentée plus loin.  Il est important que les corrélations soient de même signe si on veut regrouper les variables dans les échelles pour que ce regroupement soit logique: certaines questions avec des échelles de Likert ont parfois un encodage inverse comme test d'attention.\n\nEst-il logique de calculer des échelles avec autre chose que des items de questionnaire ramenés sur une plage commune? Par forcément... Il faut aussi s'assurer que les variables ont la même plage ou étendue avant des les combiner, sinon certaines variables seront des poids plumes et seule la variable avec la plus grande étendue ressortira.\n\nLorsqu’on construit une échelle, il est important d’examiner sa cohérence interne. Ceci peut être fait à l’aide du coefficient alpha de Cronbach. Ce coefficient mesure à quel point chaque variable faisant partie d’une échelle est corrélée avec le total de toutes les variables pour cette échelle.\nPlus le coefficient est élevé, plus les variables ont tendance à être corrélées entre elles. L'alpha de Cronbach est \n\\begin{align*}\n\\alpha=\\frac{k}{k-1} \\frac{S^2-\\sum_{i=1}^k S_i^2}{S^2}, \n\\end{align*}\noù $k$ est le nombre de variables dans l'échelle, $S^2$ est la variance empirique de la somme des variables et $S_i^2$ est la variance empirique de la $i$e variable. En pratique, on voudra que ce coefficient soit au moins égal à 0.6 pour être satisfait de la cohérence interne de l’échelle.^[Bien que ce nombre soit arbitraire.]\n\nLe paquet `hecmulti` contient une fonction, `alphaC`, pour faire l'estimation du $\\alpha$ de Cronbach\n\n\n::: {.cell layout-align=\"center\" hash='02-analysefactorielle_cache/html/alphaCronbach_2cb8d349b3b09a7ec5448fd5f7fc4e83'}\n\n```{.r .cell-code}\n# Création des échelles\nech_service <- rowMeans(factor[,c(\"x4\",\"x8\",\"x11\")])\nech_produit <- rowMeans(factor[,c(\"x3\",\"x6\",\"x9\",\"x12\")])\nech_paiement <- rowMeans(factor[,c(\"x2\",\"x7\",\"x10\")])\nech_prix <- rowMeans(factor[,c(\"x1\",\"x5\")])\n\n# Cohérence interne (alpha de Cronbach)\nalphaC(factor[,c(\"x4\",\"x8\",\"x11\")])\nalphaC(factor[,c(\"x3\",\"x6\",\"x9\",\"x12\")])\nalphaC(factor[,c(\"x2\",\"x7\",\"x10\")])\nalphaC(factor[,c(\"x1\",\"x5\")])\n```\n:::\n\n::: {#tbl-alphaCronbach .cell layout-align=\"center\" tbl-cap='Coefficient alpha de Cronbach pour les quatre échelles formées.' hash='02-analysefactorielle_cache/html/tbl-alphaCronbach_81f72d5b19f5b290e9348391f4de6732'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> service </th>\n   <th style=\"text-align:right;\"> produit </th>\n   <th style=\"text-align:right;\"> paiement </th>\n   <th style=\"text-align:right;\"> prix </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 0.781 </td>\n   <td style=\"text-align:right;\"> 0.718 </td>\n   <td style=\"text-align:right;\"> 0.727 </td>\n   <td style=\"text-align:right;\"> 0.546 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nAinsi, les $\\alpha$ de Cronbach sont tous satisfaisants (plus grand que 0.6) sauf pour le facteur _prix_ (0.546). Tout est donc cohérent. Les échelles provenant des facteurs _service_, _produits_ et _paiement_, sont satisfaisantes. Ces facteurs sont identifiés à la fois dans la solution à quatre, mais aussi dans la solution à trois facteurs. Le facteur _prix_ est celui qui apparaît en plus dans la solution à quatre facteurs. Il a une interprétation claire (c'est essentiellement `x1`), mais son faible $\\alpha$ ferait en sorte qu’il serait discutable de travailler avec l’échelle _prix_ dans d’autres analyses (du moins avec selon l’usage habituel du $\\alpha$) plutôt que d'utiliser directement la variable `x1`.\n\n## Compléments d'information\n\n### Variables ordinales\n\nThéoriquement, une analyse factorielle ne devrait être faite qu’avec des variables continues. Par contre, en pratique, on l’utilise souvent aussi avec des variables ordinales (comme pour l’exemple portant sur le questionnaire) et même avec des variables binaires (0-1).\n\nDans ce genre de situation, on peut aussi utiliser d’autres mesures d’associations au lieu du coefficient de corrélation linéaire de Pearson. Par exemple, on peut utiliser la corrélation polychorique, qui est une mesure de corrélation entre deux variables ordinales. La corrélation tétrachorique correspond au cas spécial de deux variables binaires.\n\nMa suggestion est d’utiliser la corrélation linéaire ordinaire avec des variables ordinales (même binaires). Si les résultats ne sont pas satisfaisants, on peut alors essayer avec d’autres mesures d’associations.\n\n\n### Autres méthodes de rotation des facteurs\n\nJusqu’à présent, nous avons utilisé la méthode de rotation orthogonale varimax. Il existe de nombreuses autres méthodes de rotations orthogonales fournies dans le paquet `psych`. Rappelez-vous que le modèle d’analyse factorielle de base suppose que les facteurs sont non corrélés. Les rotations de type obliques permettent d’introduire de la corrélation entre les facteurs: quelquefois, une telle rotation facilitera davantage l’interprétation des facteurs qu’une rotation orthogonale. Notez qu'il faut être prudent lorsqu’on utilise une méthode de rotation oblique car il y aura trois matrices de chargements après rotation (coefficients de régression normalisés, corrélations semi-partielles ou corrélations). On suggère l'utilisation de la première, soit la représentation avec **coefficients de régression normalisés**. Il s’agit des coefficients de régression si on voulait prédire les variables à l’aide des facteurs. Ils indiquent donc à quel point chaque facteur est associé à chaque variable. Dans le cas d’une rotation orthogonale, ces trois matrices sont les mêmes et il s’agit de trois interprétations valides des chargements.\n\n### Scores factoriels\n\nAvec les données de l’exemple, en nous basant sur les résultats de l’analyse factorielle, nous avons créé quatre nouvelles échelles (une par facteur) que l’on peut calculer pour chaque individu: \n\n- `service` = $(X_4+X_8+X_{11})/3$, \n- `produit` = $(X_3+X_6+X_9+X_{12})/4$, \n- `paiement` = $(X_2+X_7+X_{10})/3$, \n- `prix` = $(X_1+X_5)/2$.\n\nPar exemple, la variable _prix_ peut donc être vu comme une combinaison linéaire des 12\nvariables où seulement $X_1$ et $X_5$ reçoivent un poids (égal) différent de zéro. Une autre façon de créer de nouvelles variables consiste à calculer des scores factoriels (un pour chaque facteur) pour chaque individu à partir de la matrice de données centrées et réduite $\\mathbf{Z}$ (de telle sorte que la moyenne de chaque colonne soit 0 et la variance 1). Les score factoriel \n\\begin{align*}\n\\widehat{F}_{i, k} &= \\left[\\mathbf{Z}\\mathbf{R}^{-1}\\widehat{\\boldsymbol{\\Gamma}}\\right]_{ik}\\\\&=\n\\widehat{\\beta}_{1, k} z_{i, 1} + \\cdots + \\widehat{\\beta}_{12, k}z_{i, 12}\n\\end{align*}\noù $\\widehat{\\boldsymbol{\\Gamma}}$ est la matrice $p \\times m$ des chargements, $\\mathbf{R}$ la matrice $p \\times p$ des corrélation empirique et où $z_{i, 1}, \\ldots, z_{i, 12}$ est la $i$e ligne (observation) de $\\mathbf{Z}$. La matrice $p \\times m$ de coefficients $\\boldsymbol{\\beta} = \\mathbf{R}^{-1}\\widehat{\\boldsymbol{\\Gamma}}$.\n\n\nAinsi, chacune des 12 variables originales contribue au calcul du score\nfactoriel. Les variables ayant des chargements plus élevés sur ce facteur auront tendance à avoir des poids ($\\widehat{\\gamma}$) plus élevés. Par contre, les scores factoriels ne sont pas uniques car ils dépendent des chargements utilisés (et donc à la fois de la méthode d’estimation et de la méthode de rotation).\nOn peut également utiliser les scores factoriels au lieu des 12 variables\noriginales dans des analyses subséquentes. Il est suggéré d'utiliser les nouvelles variables (échelles) obtenues en faisant les moyennes des variables identifiées comme faisant partie de chaque facteur pour les raisons suivantes:\n\n- l’interprétation des scores factoriels est moins claire (chaque facteur dépend de toutes les variables)\n- les scores factoriels ne sont pas uniques (ils dépendent de la méthode d’estimation et de rotation).\n- les coefficients servant au calcul seront différents d’une étude à l’autre.\n\n\n::: {#tbl-scores .cell layout-align=\"center\" tbl-cap='Coefficients du score (modèle de régression, maximum de vraisemblance) pour le modèle d\\'analyse factorielle à quatre facteurs.' hash='02-analysefactorielle_cache/html/tbl-scores_974eb22b96421403e41439111443d9bd'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> facteur 1 </th>\n   <th style=\"text-align:right;\"> facteur 2 </th>\n   <th style=\"text-align:right;\"> facteur 3 </th>\n   <th style=\"text-align:right;\"> facteur 4 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> x1 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 1.01 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x2 </td>\n   <td style=\"text-align:right;\"> -0.05 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.31 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x3 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.45 </td>\n   <td style=\"text-align:right;\"> -0.02 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x4 </td>\n   <td style=\"text-align:right;\"> 0.30 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x5 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> -0.01 </td>\n   <td style=\"text-align:right;\"> -0.01 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x6 </td>\n   <td style=\"text-align:right;\"> -0.01 </td>\n   <td style=\"text-align:right;\"> 0.17 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x7 </td>\n   <td style=\"text-align:right;\"> -0.01 </td>\n   <td style=\"text-align:right;\"> -0.02 </td>\n   <td style=\"text-align:right;\"> 0.44 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x8 </td>\n   <td style=\"text-align:right;\"> 0.45 </td>\n   <td style=\"text-align:right;\"> -0.05 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x9 </td>\n   <td style=\"text-align:right;\"> -0.03 </td>\n   <td style=\"text-align:right;\"> 0.27 </td>\n   <td style=\"text-align:right;\"> -0.02 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x10 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.30 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x11 </td>\n   <td style=\"text-align:right;\"> 0.30 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> -0.07 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> x12 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.24 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nLes scores factoriels sont obtenus en spécifiant `scores = \"regression\"` dans les options de la fonction `factanal`. Les poids avec le modèle à quatre facteurs sont rapportés dans le @tbl-scores. On remarque que\n\n- pour le premier facteur, trois variables ont des poids importants ($X_4$, $X_8$ et $X_{11}$). Il s’agit donc d’un facteur très proche du facteur _service_.\n- pour le deuxième facteur, les variables $X_3$, $X_6$, $X_9$ et $X_{12}$ ont des poids importants. Il s’agit donc d’un facteur très proche du facteur _produits_. \n- pour le troisième facteur, les variables $X_2$, $X_7$, $X_{10}$ ont des poids importants. Il s’agit donc d’un facteur très proche du facteur _paiement_.\n- pour le quatrième facteur, seule la variable $X_1$ a un poids important.\nOn aurait pu s’attendre à ce que ce soit également le cas pour $X_5$, en lien avec le facteur _prix_  --- ce facteur était moins clair selon le alpha de Cronbach.\n\nLes corrélations entre les échelles (construites avec les moyennes) et les scores factoriels sont données dans le @tbl-corr-echelles-scores. On remarque la forte corrélation entre le score factoriel et les échelles construites avec les moyennes pour les facteurs _service_, _produits_ et _paiement_. Cela veut dire qu’utiliser les échelles ou les scores factoriels ne devrait pas faire de différence dans des analyses subséquentes. Par contre, cette corrélation est plus faible (0.82) pour le facteur _prix_.\n\n\n::: {#tbl-corr-echelles-scores .cell layout-align=\"center\" tbl-cap='Corrélation entre quatre premiers scores (modèle d\\'analyse factorielle à quatre facteurs) et échelles.' hash='02-analysefactorielle_cache/html/tbl-corr-echelles-scores_35043a323b8a6cdd165d6381e0ea6846'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> score 1 </th>\n   <th style=\"text-align:right;\"> score 2 </th>\n   <th style=\"text-align:right;\"> score 3 </th>\n   <th style=\"text-align:right;\"> score 4 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> échelle 1 </td>\n   <td style=\"text-align:right;\"> 0.99 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n   <td style=\"text-align:right;\"> -0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> échelle 2 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.98 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n   <td style=\"text-align:right;\"> -0.04 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> échelle 3 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.99 </td>\n   <td style=\"text-align:right;\"> -0.07 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> échelle 4 </td>\n   <td style=\"text-align:right;\"> -0.07 </td>\n   <td style=\"text-align:right;\"> -0.04 </td>\n   <td style=\"text-align:right;\"> -0.08 </td>\n   <td style=\"text-align:right;\"> 0.82 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n:::{.callout-tip}\n## Étapes de l'analyse factorielle exploratoire\n\n- Déterminer les variables à utiliser dans l'analyse\n- Vérifier les prérequis\n- Sélectionner une méthode d'estimation et extraire les facteurs\n- Déterminer le nombre de facteurs \n- Effectuer une rotation des facteurs\n- Interpréter les facteurs\n- Évaluer la validité du modèle\n:::\n\n\n::: {.callout-note}\n\n## En résumé\n\n- L'analyse factorielle exploratoire fournit un modèle pour la matrice de corrélation\n    - La solution du problème n'est pas unique: on choisit celle qui permet de mieux séparer les variables.\n    - Seules les variables numériques pour lesquelles on suspecte une dimension commune sont incluses dans l'analyse.\n    - On doit avoir beaucoup d'observations (au moins 100, 10 fois plus que de variables) pour estimer le modèle.\n    - On estime le modèle à l'aide de la méthode des composantes principales (modèle toujours valide et moins coûteux en calcul, mais critères pour la sélection du nombre de facteurs arbitraires) ou du maximum de vraisemblance (optimisation numérique avec solutions fréquemment problématique, critères d'information pour choix du nombre de facteurs).\n    - Le nombre de facteurs retenu doit donner des regroupements logiques (facteur *wow*).\n    - On utilise toujours une rotation orthogonale pour faciliter l'interprétation (varimax par défaut).\n    - L'interprétation se fait à partir des chargements (corrélation entre variables et facteurs).\n    - On crée des échelles en prenant la moyenne des variables qui ont un chargement élevés en lien avec un facteur donné (de même signe).\n    - Les échelles sont cohérentes si le $\\alpha$ de Cronbach est supérieur à 0.6, faute de quoi elles sont rejetées.\n    \n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}