{
  "hash": "a93701cee2582703741b4f236fca67aa",
  "result": {
    "markdown": "# Données manquantes {#donnees-manquantes}\n\n\n::: {.cell file='_common.R' hash='07-donneesmanquantes_cache/html/setup_74ad590636090c699ce27dfa9acbef2e'}\n\n:::\n\n\n\nIl arrive fréquemment d'avoir des valeurs manquantes dans notre échantillon. Ces valeurs peuvent être manquantes pour diverses raisons. Si on prélève nous-mêmes nos données, un répondant peut refuser de répondre à certaines questions. Si on acquiert nos données d'une source externe, les valeurs de certaines variables peuvent être manquantes directement dans le fichier obtenu.  Si on ne prend pas en compte le méchanisme générant les valeurs manquantes, ces dernières peuvent également biaiser nos analyses. Le but de ce chapitre est de faire un bref survol de ce sujet.\n\n## Principes de base\n\n\nSoit $X$ une variable pour laquelle des données sont manquantes. Voici la définition de trois processus de génération de données manquantes.\n\n1) Les données manquantes de $X$ sont dites **manquantes de façon complètement aléatoire** (MCAR, de l'anglais _missing completely at random_) si la probabilité que la valeur de $X$ soit manquante ne dépend ni de la valeur de $X$ (qui n'est pas observée), ni des valeurs des autres variables. \n\nLe fait qu'une variable est manquante peut être relié au fait qu'une autre soit manquante. Des gens peuvent refuser systématiquement de répondre à deux questions dans un sondage. Dans ce cas, si la probabilité qu'une personne ne réponde pas ne dépend pas des valeurs de ces variables (et de toutes les autres), nous sommes encore dans le cas MCAR. Si par contre, la probabilité que les gens ne répondent pas à une question sur leur revenu augmente avec la valeur de ce revenu, alors nous ne sommes plus dans le cas MCAR.\n\nLe cas MCAR peut se présenter par exemple si des questionnaires, ou des pages ont été égarés ou détruits par inadvertance (effacées du disque rigide, etc.) Si les questionnaires manquants constituent un sous-ensemble choisi au hasard de tous les questionnaires, alors le processus est MCAR. L'hypothèse que les données manquantes sont complètement aléatoires est en général considérée comme trop restrictive.\n\n2) Les données manquantes de $X$ sont dites **données manquantes de façon aléatoire** (MAR, de l'anglais _missing at random_) si la probabilité que la valeur de $X$ soit manquante ne dépend pas de la valeur de $X$ (qui n'est pas observée) une fois qu'on a contrôlé pour les autres variables. \n\n\nIl est possible par exemple que les femmes refusent plus souvent que les hommes de répondre à une question, par exemple de donner leur âge (et donc, le processus n'est pas MCAR). Si pour les femmes et les hommes, la probabilité que $X$ est manquante ne dépend pas de la valeur de $X$, alors le processus est MAR. Les probabilités d'avoir une valeur manquante sont différentes pour les hommes et les femmes mais cette probabilité ne dépend pas de la valeur de $X$ elle-même. L'hypothèse MAR est donc plus faible que l'hypothèse MCAR.\n\n3) Les données manquantes de $X$ sont dites **manquantes de façon non-aléatoire** (MNAR, de l'anglais _missing not at random_) si la probabilité que la valeur de $X$ soit manquante dépend de la valeur de $X$ elle-même.\n\nPar exemple, les gens qui ont un revenu élevé pourraient avoir plus de réticences à répondre à une question sur leur revenu. Un autre exemple est si une personne transgenre ne répond pas à la question genre (si on offre seulement deux choix, homme/femme) et aucune autre question ne se rattache au genre ou à l’identité sexuelle. La méthode de traitement que nous allons voir dans ce chapitre, l'imputation multiple, est très générale et est valide dans le cas MAR (et donc aussi dans le cas MCAR). Le cas MNAR est beaucoup plus difficile à traiter et ne sera pas considéré ici. \n\nIl n'est pas possible de tester l'hypothèse que le données sont manquantes de façon aléatoire ou complètement aléatoire; ce postulat doit donc être déterminé à partir du contexte et des variables auxiliaires disponibles.\n\n\n## Méthodes d'imputation\n\n\nIl est important de noter que, dans bien des cas, les données manquantes ont une valeur logique: un client qui n’a pas de carte de crédit a un solde de 0! Tous ces cas devraient être traités en amon, d'où l’importance des validations d'usage et du nettoyage préliminaire\nde la base de données.\n\n### Cas complets\n\nLa première idée naïve pour une analyse est de retirer les observations avec données manquantes pour conserver les cas complets (*listwise deletion*, ou _complete case analysis_).\n\nCette méthode consiste à garder seulement les observations qui n'ont aucune valeur manquante pour les variables utilisées dans l'analyse demandée. Dès qu'une variable est manquante, on enlève le sujet au complet. C'est la méthode utilisée par défaut dans la plupart des logiciels, dont **R**. \n\n- Si le processus est MCAR, cette méthode est valide car l'échantillon utilisé est vraiment un sous-échantillon aléatoire de l'échantillon original. Par contre, ce n'est pas nécessairement la meilleure solution car on perd de la précision en utilisant moins d'observations.\n- Si le processus est seulement MAR ou MNAR, cette méthode produit généralement des estimations biaisées des paramètres.\n\nEn général, l'approche des cas complet est la première étape d'une analyse afin d'obtenir des estimés initiaux que nous corrigerons pas d'autre méthode. Elle n'est vraiment utile que si la proportion d'observations manquantes est très faible et le processus est MCAR. Évidemment, la présence de valeurs manquantes mène à une diminution de la précision des estimateurs (caractérisée par une augmentation des erreurs-types) et à une plus faible puissance pour les tests d'hypothèse et donc ignorer l'information partielle (si seulement certaines valeurs des variables explicatives sont manquantes) est sous-optimal.\n\n### Imputation simple \n\nL'**imputation** consiste à remplacer les valeurs manquantes pour boucher le trous. Pour paraphraser Dempster et Rubin (1983),\n\n> Le concept d’imputation est à la fois séduisant et dangereux.\n\nAvec l'**imputation simple**, on remplace les valeurs manquantes par des ersatz raisonnables. Par exemple, on peut remplacer les valeurs manquantes d'une variable par la moyenne de cette variable dans notre échantillon. On peut aussi ajuster un modèle de régression avec cette variable comme variable dépendante et d'autres variables explicatives comme variables indépendantes et utiliser les valeurs prédites comme remplacement. Une fois que les valeurs manquantes ont été remplacées, on fait l'analyse avec toutes les observations.\n\nL'imputation par le mode ou la moyenne n'est pas recommandée parce qu'elle dilue la corrélation entre les variables explicatives et elle réduit la variabilité. Les modèles de régression mènent également à une-sous estimation de l'incertitude en raison cette fois-ci de l'augmentation de la corrélation, ce qui augmente mécaniquement la significativité des tests, contrairement à l'imputation aléatoire (droite).\nLe @fig-imputation montre clairement cet état de fait.\n\n\n\n::: {.cell layout-align=\"center\" hash='07-donneesmanquantes_cache/html/fig-imputation_550ac9b18251d54b3204881c8eacca2b'}\n::: {.cell-output-display}\n![Différences entre méthodes d'imputation, avec imputation par la moyenne, par le biais d'une régression linéaire et par un modèle aléatoire de régression, de gauche à droite.](07-donneesmanquantes_files/figure-html/fig-imputation-1.png){#fig-imputation fig-align='center' width=100%}\n:::\n:::\n\n\nEn quoi constitue l'imputation aléatoire recommandée ci-dessus? Considérons le cas d'une régression logistique pour une variable explicative binaire. Plutôt que d'assigner à la classe la plus probable, une prédiction aléatoire simule une variable 0/1 avec probabilité $(1-\\widehat{p}_i, \\widehat{p}_i)$. Pour un modèle de régression linéaire, la prédiction\n\n\n\nIl existe d'autres façons d'imputer les valeurs manquantes mais le problème de toutes ces approches est que l'on ne tient pas compte du fait que des valeurs ont été remplacées et on fait comme si c'était de vraies observations. Cela va en général sous-évaluer la variabilité dans les données. Par conséquent, les écarts-type des paramètres estimés seront en général sous-estimés et l'inférence (tests et intervalles de confiance) ne sera pas valide.\nCette approche n'est donc **pas recommandée**.\n\nUne manière de tenter de reproduire correctement la variabilité dans les données consiste à ajouter un terme aléatoire dans l'imputation. C'est ce que fait la méthode suivante, qui possédera l'avantage de corriger automatiquement les écarts-type des paramètres estimés.\n\n### Imputation multiple\n\nCette méthode peut être appliquée dans à peu près n'importe quelle situation et permet d'ajuster les écarts-type des paramètres estimés. Elle peut être appliquée lorsque le processus est MAR (et donc aussi MCAR).\n\nL'idée consiste à procéder à une imputation aléatoire, selon une certaine technique, pour obtenir un échantillon complet et à ajuster le modèle d'intérêt avec cet échantillon. On répète ce processus plusieurs fois et on combine les résultats obtenus. \n\n\n\n::: {.cell layout-align=\"center\" hash='07-donneesmanquantes_cache/html/unnamed-chunk-3_22419718e91619cc27b35e5a01edff28'}\n::: {.cell-output-display}\n![](figures/donnees_manquantes_workflow.png){fig-align='center' width=70%}\n:::\n:::\n\n\nL'estimation finale des paramètres du modèle est alors simplement la moyenne des estimations pour les différentes répétitions et on peut également obtenir une estimation des écarts-type des paramètres qui tient compte du processus d'imputation.\n\nPlus précisément, supposons qu'on s'intéresse à un seul paramètre $\\theta$ dans un modèle donné. Ce modèle pourrait être un modèle de régression linéaire, de régression logistique, etc. Le paramètre $\\theta$ serait alors un des $\\boldsymbol{\\beta}$ du modèle.\n\nSupposons qu'on procède à $K$ imputations, c'est-à-dire, qu'on construit $K$ ensemble de données complets à partir de l'ensemble de données initial contenant des valeurs manquantes. On estime alors les paramètres du modèle séparément pour chacun des ensembles de données imputés. Soit  $\\widehat{\\theta}_k$, l'estimé du paramètre $\\theta$ pour l'échantillon $k \\in \\{1, \\ldots, K\\}$ et $\\widehat{\\sigma}_k^2=\\mathsf{Va}(\\widehat{\\theta}_k)$ l'estimé de la variance de $\\widehat{\\theta}_k$ produite par le modèle estimé. \n\nL'estimation finale de $\\theta$, dénotée $\\widehat{\\theta}$, est obtenue tout simplement en faisant la moyenne des estimations de tous les modèles, c'est-à-dire,\n\\begin{align*}\n\\widehat{\\theta} = \\frac{\\widehat{\\theta}_1 + \\cdots + \\widehat{\\theta}_K}{K}.\n\\end{align*}\nUne estimation ajustée de la variance de $\\widehat{\\theta}$ est \n\\begin{align*}\n\\mathsf{Va}(\\hat{\\theta}) &= W+ \\frac{K+1}{K}B, \n\\\\ W &= \\frac{1}{K} \\sum_{k=1}^K \\widehat{\\sigma}^2_k = \\frac{\\widehat{\\sigma}_1^2 + \\cdots + \\widehat{\\sigma}_K^2}{K},\\\\\nB &= \\frac{1}{K-1} \\sum_{k=1}^K (\\widehat{\\theta}_k - \\widehat{\\theta})^2.\n\\end{align*}\nAinsi, le terme $W$ est la moyenne des variances et $B$ est la variance entre les imputations. Le terme $(1+1/K)B$ est celui qui vient corriger le fait qu'on travaille avec des données imputées et non pas des vraies données en augmentant la variance estimée du paramètre. \n\nC'est ici qu'on voit l'intérêt à procéder à de l'imputation multiple. Si on procédait à une seule imputation (même en ajoutant une part d'aléatoire pour essayer de reproduire la variabilité des données), on ne serait pas en mesure d'estimer la variance inter-groupe de l'estimateur. Notez que la formule présentée n'est valide que pour le cas unidimensionnel; l'estimation de la variance dans le cas multidimensionnel est différente [@Little.Rubin:2019].\n\nIl faut également ajuster les formules pour le calcul des intervalles de confiance, valeurs-$p$ et degrés de liberté. Le logiciel s'en chargera pour nous.\n\nLa méthode d'imputation multiple possède l'avantage d'être applicable avec n'importe quel modèle sous-jacent. Une fois qu'on a des échantillons complets (imputés), on ajuste le modèle comme d'habitude. Mais une observation imputée ne remplacera jamais une vraie observation. Il faut donc faire tout ce qu'on peut pour limiter le plus possible les données manquantes. \n\nIl faut utiliser son jugement. Par exemple, si la proportion d'observations perdues est petite (moins de 5\\%), ça ne vaut peut-être pas la peine de prendre des mesures particulières et on peut faire une analyse avec les données complètes seulement. S'il y a un doute, on peut faire une analyse avec les données complètes seulement et une autre avec imputations multiples afin de valider la première. \n \nSi, à l'inverse, une variable secondaire cause à elle seule une grande proportion de valeurs manquantes, on peut alors considérer l'éliminer afin de récupérer des observations. Par exemple, si vous avez une proportion de 30\\% de valeurs manquantes en utilisant toutes vos variables et que cette proportion baisse à 3\\% lorsque vous éliminez quelques variables peu importantes pour votre étude (ou qui peuvent être remplacées par d'autres jouant à peu près le même rôle qui elles sont disponibles), alors vous pourriez considérer la possibilité de les éliminer. Il est donc nécessaire d'examiner la configuration des valeurs manquantes avant de faire quoi que ce soit. \n\nPour l'imputation, nous utiliserons l'algorithme d'imputation multiple par équations chaînées (MICE).\n\nAvec $p$ variables $X_1, \\ldots, X_p$, spécifier un ensemble de modèles **conditionnels** pour chaque variable $X_j$ en fonction de toutes les autres variables, $\\boldsymbol{X}_{-j}$ et les valeurs observées pour cette variable, $X_{j, \\text{obs}}$.\n\nL'idée est de remplir aléatoire tous les trous et ensuite d'utiliser des modèles d'imputation aléatoire pour chaque variable à tour de rôle. Après plusieurs cycles où chacune des variables explicatives (au plus le nombre de colonnes $p$) est imputée, l'impact de l'initialisation devrait être faible. On retourne alors une copie de la base de données. \n\n1. Initialisation: remplir les trous avec des données au hasard parmi $X_{j, \\text{obs}}$ pour $X_{j, \\text{man}}$\n2. À l'itération $t$, pour chaque variable $j=1, \\ldots, p$, à tour de rôle:\n   a) tirage aléatoire des paramètres $\\phi_j^{(t)}$ du modèle pour $X_{j,\\text{man}}$ conditionnel à $\\boldsymbol{X}_{-j}^{(t-1)}$ et  $X_{j, \\text{obs}}$\n   b) échantillonnage de nouvelles observations $X^{(t)}_{j,\\text{man}}$ du modèle avec paramètres $\\phi_j^{(t)}$ conditionnel à $\\boldsymbol{X}_{-j}^{(t-1)}$ et  $X_{j, \\text{obs}}$\n3. Répéter le cycle\n\n\n## Example d'application de l'imputation \n\nOn examine l'exemple de recommandations de l'association professionnelle des vachers de la section @sec-cowboy.\n\n\nLe but est d'examiner les effets des variables $X_1$ à $X_6$ sur les intentions d'achat; la base de données `manquantes` contient les observations. Il s'agit des mêmes données que celles du fichier `logit1` mais avec des valeurs manquantes.\n\n\n::: {#tbl-missing1r .cell layout-align=\"center\" tbl-cap='Tableau de la configuration des données manquantes.' hash='07-donneesmanquantes_cache/html/tbl-missing1r_cabaea69bd832b796f15956e8e8259c9'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> \\(X_1\\) </th>\n   <th style=\"text-align:right;\"> \\(X_2\\) </th>\n   <th style=\"text-align:right;\"> \\(X_3\\) </th>\n   <th style=\"text-align:right;\"> \\(X_4\\) </th>\n   <th style=\"text-align:right;\"> \\(X_5\\) </th>\n   <th style=\"text-align:right;\"> \\(X_6\\) </th>\n   <th style=\"text-align:right;\"> \\(y\\) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 35 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> . </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> . </td>\n   <td style=\"text-align:right;\"> 33 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> . </td>\n   <td style=\"text-align:right;\"> 46 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> . </td>\n   <td style=\"text-align:right;\"> 32 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> . </td>\n   <td style=\"text-align:right;\"> 38 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> . </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 36 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> . </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> . </td>\n   <td style=\"text-align:right;\"> 35 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> . </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 26 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> . </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 39 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> . </td>\n   <td style=\"text-align:right;\"> 38 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nLes points (`.`) indiquent des valeurs manquantes. Le premier sujet n'a pas de valeur manquante. Le deuxième a une valeur manquante pour $X_1$ (emploi) et $X_4$ (éducation), etc.\n\nUne première façon de voir combien il y a de valeurs manquantes consiste à faire sortir les statistiques descriptives avec `summary`.\nAinsi, il y 192 valeurs manquantes pour $X_1$, 48 pour $X_2$ et 184 pour $X_4$. Les autres variables n'ont pas de valeurs manquantes, incluant la variable dépendante $Y$. La procédure unidimensionnelle nous permet seulement de voir combien il y a de valeurs manquantes variable par variable. \n\n\n::: {#tbl-manquantes-univ .cell layout-align=\"center\" tbl-cap='Pourcentage de valeurs manquantes par variable.' hash='07-donneesmanquantes_cache/html/tbl-manquantes-univ_966ee10a13ecb69d3e5356a2113524a2'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:left;\"> x1 </th>\n   <th style=\"text-align:left;\"> x2 </th>\n   <th style=\"text-align:left;\"> x3 </th>\n   <th style=\"text-align:left;\"> x4 </th>\n   <th style=\"text-align:left;\"> x5 </th>\n   <th style=\"text-align:left;\"> x6 </th>\n   <th style=\"text-align:left;\"> y </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> nombre </td>\n   <td style=\"text-align:left;\"> 192 </td>\n   <td style=\"text-align:left;\"> 49 </td>\n   <td style=\"text-align:left;\"> 0 </td>\n   <td style=\"text-align:left;\"> 184 </td>\n   <td style=\"text-align:left;\"> 0 </td>\n   <td style=\"text-align:left;\"> 0 </td>\n   <td style=\"text-align:left;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> pourcentage </td>\n   <td style=\"text-align:left;\"> 0.384 </td>\n   <td style=\"text-align:left;\"> 0.098 </td>\n   <td style=\"text-align:left;\"> 0 </td>\n   <td style=\"text-align:left;\"> 0.368 </td>\n   <td style=\"text-align:left;\"> 0 </td>\n   <td style=\"text-align:left;\"> 0 </td>\n   <td style=\"text-align:left;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='07-donneesmanquantes_cache/html/manquantes-summary-uni_3f57c11ed8256d993775af009812b2e8'}\n\n```{.r .cell-code}\ndata(manquantes, package = 'hecmulti')\nsummary(manquantes)\n# Pourcentage de valeurs manquantes\napply(manquantes, 2, function(x){mean(is.na(x))})\n# Voir les configurations de valeurs manquantes\nmd.pattern(manquantes)\n\n```\n:::\n\n\n\n\nNous utiliserons le paquet **R** `mice` pour faire l'imputation.\n\n1. Procéder à plusieurs imputations **aléatoires** pour obtenir un échantillon complet (`mice`)\n2. Ajuster le modèle d'intérêt avec chaque échantillon (`with`). 3. Combiner les résultats obtenus (`pool` et `summary`)\n\n\n\n::: {.cell layout-align=\"center\" hash='07-donneesmanquantes_cache/html/fig-manquantes2_60b3cab3188a3418f84427e858f59652'}\n::: {.cell-output-display}\n![Configurations des valeurs manquantes pour la base de données `manquantes`.](07-donneesmanquantes_files/figure-html/fig-manquantes2-1.png){#fig-manquantes2 fig-align='center' width=70%}\n:::\n:::\n\nLa @fig-manquantes2 donne une indication sur les différentes combinaisons de données complètes (cases bleues) et les observations manquantes (cases roses) avec leur fréquence. Les variables sont indiquées au dessus, les effectifs manquants en dessous, le nombre de cas de chaque combinaisons à gauche et le nombre de variables avec des valeurs manquantes à droite. Ainsi, il y a 180 sujets (36\\% de l'échantillon) avec aucune observation manquante. Il y en a 99 avec seulement $X_4$ manquante et ainsi de suite. On voit donc, par exemple, que pour 14 sujets, à la fois $X_1$ et $X_2$ sont manquantes.  \n\nLa recommandation d'usage est d'imputer au moins le pourcentage de cas incomplet, ici 64\\% donc 64 imputations. Si la procédure est trop coûteuse en calcul, on peut diminuer le nombre d'imputations, mais il faut au minimum 10 réplications pour avoir une bonne idée de la variabilité.\n\nOn peut comparer l'inférence avec toutes les variables explicatives pour les données sans valeurs manquantes ($n=500$ observations), avec les cas complets uniquement ($n=180$ observations). \nLe @tbl-missing3r présente les estimations des paramètres du modèle de régression logistique s'il n'y avait pas eu de valeurs manquantes, avec les cas complets et les résultats de l'imputation multiple.\n  \n  \n\n\nSi on ajuste un modèle à une base de données qui contient des valeurs manquantes, le comportement par défaut est de retirer les observations qui ont au moins une valeur manquante pour une des variables nécessaires à l'analyse (voir la sortie de `glm(y ~ ., data = manquantes)`). Il ne serait pas raisonnable de faire l'analyse avec seulement 180 observations et de laisser tomber les 320 autres. De plus, comme nous l'avons vu plus haut, ce n'est pas valide à moins que le processus ne soit MCAR. La partie du milieu du @tbl-missing3r présente les estimations obtenues. Plusieurs variables significatives à niveau $\\alpha=0.05$ ne le sont plus (puisqu'il y a moins d'information quand on réduit le nombre d'observations). Il y a même pire: non seulement la variable $\\mathsf{I}(X_2=1)$ est passée de significative à non significative, mais en plus l'estimé de son paramètre a changé de signe.  \n\nNous allons donc faire l'analyse avec l'imputation multiple, en prenant la méthode d'imputation par défaut\n\n\n::: {.cell layout-align=\"center\" hash='07-donneesmanquantes_cache/html/manquante2_4f557554e5c5980efd2fec6084f4a186'}\n\n```{.r .cell-code}\nlibrary(mice)\n# Imputation multiple avec équations enchaînées\n# Intensif en calcul, réduire `m` si nécessaire\nimpdata <- mice(data = manquantes,\n                m = 50,\n                seed = 2021,\n                method = \"pmm\",\n                printFlag = FALSE)\n# Chaque copie est disponible (1, ..., 50)\ncomplete(impdata, action = 1)\n# ajuste les modèles avec les données imputées\n\nadj_im <- with(data = impdata,\n               expr = glm(y ~ x1 + x2 + x3 + x4 + x5 + x6,\n                          family = binomial(link = 'logit')))\n\n# combinaison des résultats \nfit <- pool(adj_im)\nsummary(fit)\n```\n:::\n\n\n\nLa procédure `mice` du paquet éponyme crée les copies complètes du jeu de données. On peut ensuite appliquer une procédure quelconque et combiner les estimations avec `pool`.\n\n\n::: {#tbl-missing3r .cell layout-align=\"center\" tbl-cap='Estimés, erreurs-type et valeurs-p des paramètres avec les 500 données complètes (gauche), avec les 180 cas complets (milieu) et avec l\\'imputation multiple (droite).' hash='07-donneesmanquantes_cache/html/tbl-missing3r_ea9e398efd3ea341cd27ddb8d19f6711'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Données complètes</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Cas complets</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Imputation multiple</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> \\(\\widehat{\\boldsymbol{\\beta}}\\) </th>\n   <th style=\"text-align:center;\"> \\(\\mathrm{se}(\\widehat{\\boldsymbol{\\beta}})\\) </th>\n   <th style=\"text-align:center;\"> valeur-\\(p\\) </th>\n   <th style=\"text-align:right;\"> \\(\\widehat{\\boldsymbol{\\beta}}\\) </th>\n   <th style=\"text-align:center;\"> \\(\\mathrm{se}(\\widehat{\\boldsymbol{\\beta}})\\) </th>\n   <th style=\"text-align:center;\"> valeur-\\(p\\) </th>\n   <th style=\"text-align:right;\"> \\(\\widehat{\\boldsymbol{\\beta}}\\) </th>\n   <th style=\"text-align:center;\"> \\(\\mathrm{se}(\\widehat{\\boldsymbol{\\beta}})\\) </th>\n   <th style=\"text-align:center;\"> valeur-\\(p\\) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> cste </td>\n   <td style=\"text-align:right;\"> -6.89 </td>\n   <td style=\"text-align:center;\"> 1.02 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> -5.25 </td>\n   <td style=\"text-align:center;\"> 1.70 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> -6.57 </td>\n   <td style=\"text-align:center;\"> 1.04 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_1=1\\) </td>\n   <td style=\"text-align:right;\"> 0.36 </td>\n   <td style=\"text-align:center;\"> 0.48 </td>\n   <td style=\"text-align:center;\"> 0.46 </td>\n   <td style=\"text-align:right;\"> -0.09 </td>\n   <td style=\"text-align:center;\"> 0.85 </td>\n   <td style=\"text-align:center;\"> 0.92 </td>\n   <td style=\"text-align:right;\"> 0.55 </td>\n   <td style=\"text-align:center;\"> 0.54 </td>\n   <td style=\"text-align:center;\"> 0.31 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_1=2\\) </td>\n   <td style=\"text-align:right;\"> -0.47 </td>\n   <td style=\"text-align:center;\"> 0.37 </td>\n   <td style=\"text-align:center;\"> 0.21 </td>\n   <td style=\"text-align:right;\"> -0.57 </td>\n   <td style=\"text-align:center;\"> 0.66 </td>\n   <td style=\"text-align:center;\"> 0.39 </td>\n   <td style=\"text-align:right;\"> -0.13 </td>\n   <td style=\"text-align:center;\"> 0.45 </td>\n   <td style=\"text-align:center;\"> 0.78 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_1=3\\) </td>\n   <td style=\"text-align:right;\"> -0.31 </td>\n   <td style=\"text-align:center;\"> 0.35 </td>\n   <td style=\"text-align:center;\"> 0.37 </td>\n   <td style=\"text-align:right;\"> -0.47 </td>\n   <td style=\"text-align:center;\"> 0.66 </td>\n   <td style=\"text-align:center;\"> 0.47 </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n   <td style=\"text-align:center;\"> 0.44 </td>\n   <td style=\"text-align:center;\"> 0.87 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_1=4\\) </td>\n   <td style=\"text-align:right;\"> -0.32 </td>\n   <td style=\"text-align:center;\"> 0.40 </td>\n   <td style=\"text-align:center;\"> 0.43 </td>\n   <td style=\"text-align:right;\"> -0.93 </td>\n   <td style=\"text-align:center;\"> 0.74 </td>\n   <td style=\"text-align:center;\"> 0.21 </td>\n   <td style=\"text-align:right;\"> -0.04 </td>\n   <td style=\"text-align:center;\"> 0.48 </td>\n   <td style=\"text-align:center;\"> 0.93 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_2=1\\) </td>\n   <td style=\"text-align:right;\"> 1.33 </td>\n   <td style=\"text-align:center;\"> 0.60 </td>\n   <td style=\"text-align:center;\"> 0.03 </td>\n   <td style=\"text-align:right;\"> -0.74 </td>\n   <td style=\"text-align:center;\"> 1.14 </td>\n   <td style=\"text-align:center;\"> 0.52 </td>\n   <td style=\"text-align:right;\"> 1.10 </td>\n   <td style=\"text-align:center;\"> 0.65 </td>\n   <td style=\"text-align:center;\"> 0.09 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_2=2\\) </td>\n   <td style=\"text-align:right;\"> 1.15 </td>\n   <td style=\"text-align:center;\"> 0.50 </td>\n   <td style=\"text-align:center;\"> 0.02 </td>\n   <td style=\"text-align:right;\"> 0.46 </td>\n   <td style=\"text-align:center;\"> 0.91 </td>\n   <td style=\"text-align:center;\"> 0.61 </td>\n   <td style=\"text-align:right;\"> 1.03 </td>\n   <td style=\"text-align:center;\"> 0.55 </td>\n   <td style=\"text-align:center;\"> 0.06 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_2=3\\) </td>\n   <td style=\"text-align:right;\"> 0.77 </td>\n   <td style=\"text-align:center;\"> 0.48 </td>\n   <td style=\"text-align:center;\"> 0.11 </td>\n   <td style=\"text-align:right;\"> -0.41 </td>\n   <td style=\"text-align:center;\"> 0.89 </td>\n   <td style=\"text-align:center;\"> 0.64 </td>\n   <td style=\"text-align:right;\"> 0.52 </td>\n   <td style=\"text-align:center;\"> 0.52 </td>\n   <td style=\"text-align:center;\"> 0.31 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_2=4\\) </td>\n   <td style=\"text-align:right;\"> -1.11 </td>\n   <td style=\"text-align:center;\"> 0.54 </td>\n   <td style=\"text-align:center;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> -2.74 </td>\n   <td style=\"text-align:center;\"> 1.02 </td>\n   <td style=\"text-align:center;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> -1.04 </td>\n   <td style=\"text-align:center;\"> 0.57 </td>\n   <td style=\"text-align:center;\"> 0.07 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_3\\) </td>\n   <td style=\"text-align:right;\"> 1.35 </td>\n   <td style=\"text-align:center;\"> 0.26 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.80 </td>\n   <td style=\"text-align:center;\"> 0.44 </td>\n   <td style=\"text-align:center;\"> 0.07 </td>\n   <td style=\"text-align:right;\"> 1.19 </td>\n   <td style=\"text-align:center;\"> 0.27 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_4\\) </td>\n   <td style=\"text-align:right;\"> 1.83 </td>\n   <td style=\"text-align:center;\"> 0.30 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 2.25 </td>\n   <td style=\"text-align:center;\"> 0.58 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 1.52 </td>\n   <td style=\"text-align:center;\"> 0.37 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_5\\) </td>\n   <td style=\"text-align:right;\"> 0.11 </td>\n   <td style=\"text-align:center;\"> 0.02 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.11 </td>\n   <td style=\"text-align:center;\"> 0.03 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.10 </td>\n   <td style=\"text-align:center;\"> 0.02 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_6=1\\) </td>\n   <td style=\"text-align:right;\"> 2.41 </td>\n   <td style=\"text-align:center;\"> 0.38 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 2.23 </td>\n   <td style=\"text-align:center;\"> 0.66 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 2.26 </td>\n   <td style=\"text-align:center;\"> 0.38 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> \\(x_6=2\\) </td>\n   <td style=\"text-align:right;\"> 1.04 </td>\n   <td style=\"text-align:center;\"> 0.25 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n   <td style=\"text-align:center;\"> 0.44 </td>\n   <td style=\"text-align:center;\"> 0.06 </td>\n   <td style=\"text-align:right;\"> 1.00 </td>\n   <td style=\"text-align:center;\"> 0.25 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nOn peut remarquer que la précision est systématiquement meilleure avec l'imputation multiple; les erreurs-type pour l'imputation multiple sont plus petits que celle du modèle qui retire les données incomplètes. \n\nOn voit que la variable $X_3$ (sexe) est significative avec l'imputation multiple. Son paramètre estimé est 1.19, comparativement à 1.349 s'il n'y avait pas eu de valeurs manquantes. La précision dans l'estimation avec l'imputation multiple est seulement un peu moins bonne (erreur-type de 0.27) que celle s'il n'y avait pas eu de manquantes (erreur type de 0.26). Le paramètre de $\\mathsf{I}(X_6=2)$ redevient aussi significatif, alors qu'il ne l'était plus si on retirait les manquantes. Il est peu probable que les données soit $\\mathsf{MCAR}$ et donc les résultats de l'analyse des cas complets seraient biaisés.\n\n\n::: {.callout-note}\n\n## En résumé\n\n- Les données manquantes réduisent la quantité d'information disponible et augmentent l'incertitude.\n- On ne peut **pas** les ignorer (étude des cas complets) sans biaiser les interprétations et réduire la quantité d'information disponible.\n- Pour bien capturer l'incertitude et ne pas modifier les relations entre variables, il faut utiliser une méthode d'imputation aléatoire.\n- Avec l'algorithme MICE, on utilise un modèle conditionnel pour chaque variable à tour de rôle.\n- L'imputation multiple est préférée à l'imputation simple car elle permet d'estimer l'incertitude sous-jacente en raison des données manquantes.\n- Il faut un traitement spécial pour les erreurs-type, degrés de liberté, valeurs-$p$ et intervalles de confiance.\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}