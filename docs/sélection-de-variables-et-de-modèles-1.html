<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 3 Sélection de variables et de modèles | Analyse multidimensionnelle appliquée</title>
  <meta name="description" content="Ce recueil de notes pour MATH 60602 Analyse multidimensionnelle appliquée, avec des exemples d’applications en SAS et en R." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 3 Sélection de variables et de modèles | Analyse multidimensionnelle appliquée" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Ce recueil de notes pour MATH 60602 Analyse multidimensionnelle appliquée, avec des exemples d’applications en SAS et en R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 3 Sélection de variables et de modèles | Analyse multidimensionnelle appliquée" />
  
  <meta name="twitter:description" content="Ce recueil de notes pour MATH 60602 Analyse multidimensionnelle appliquée, avec des exemples d’applications en SAS et en R." />
  

<meta name="author" content="Denis Larocque, Léo Belzile" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="analyse-factorielle-exploratoire-1.html"/>
<link rel="next" href="régression-logistique-1.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MATH60602</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#survol-du-cours"><i class="fa fa-check"></i><b>1.1</b> Survol du cours</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#analyse-factorielle-exploratoire"><i class="fa fa-check"></i><b>1.1.1</b> Analyse factorielle exploratoire</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#sélection-de-variables-et-de-modèles"><i class="fa fa-check"></i><b>1.1.2</b> Sélection de variables et de modèles</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#régression-logistique"><i class="fa fa-check"></i><b>1.1.3</b> Régression logistique</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#analyse-de-regroupements"><i class="fa fa-check"></i><b>1.1.4</b> Analyse de regroupements</a></li>
<li class="chapter" data-level="1.1.5" data-path="index.html"><a href="index.html#analyse-de-survie"><i class="fa fa-check"></i><b>1.1.5</b> Analyse de survie</a></li>
<li class="chapter" data-level="1.1.6" data-path="index.html"><a href="index.html#données-manquantes"><i class="fa fa-check"></i><b>1.1.6</b> Données manquantes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html"><i class="fa fa-check"></i><b>2</b> Analyse factorielle exploratoire</a><ul>
<li class="chapter" data-level="2.1" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#rappels-sur-le-coefficient-de-corrélation-linéaire"><i class="fa fa-check"></i><b>2.2</b> Rappels sur le coefficient de corrélation linéaire</a></li>
<li class="chapter" data-level="2.3" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#exemple-de-questionnaire"><i class="fa fa-check"></i><b>2.3</b> Exemple de questionnaire</a></li>
<li class="chapter" data-level="2.4" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#description-du-modèle-danalyse-factorielle"><i class="fa fa-check"></i><b>2.4</b> Description du modèle d’analyse factorielle</a><ul>
<li class="chapter" data-level="2.4.1" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#rotation-des-facteurs"><i class="fa fa-check"></i><b>2.4.1</b> Rotation des facteurs</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#estimation-des-facteurs"><i class="fa fa-check"></i><b>2.5</b> Estimation des facteurs</a></li>
<li class="chapter" data-level="2.6" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#choix-du-nombre-de-facteurs"><i class="fa fa-check"></i><b>2.6</b> Choix du nombre de facteurs</a></li>
<li class="chapter" data-level="2.7" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#construction-déchelles-à-partir-des-facteurs"><i class="fa fa-check"></i><b>2.7</b> Construction d’échelles à partir des facteurs</a></li>
<li class="chapter" data-level="2.8" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#compléments-dinformation"><i class="fa fa-check"></i><b>2.8</b> Compléments d’information</a><ul>
<li class="chapter" data-level="2.8.1" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#variables-ordinales"><i class="fa fa-check"></i><b>2.8.1</b> Variables ordinales</a></li>
<li class="chapter" data-level="2.8.2" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#autres-méthodes-dextractions-de-facteurs"><i class="fa fa-check"></i><b>2.8.2</b> Autres méthodes d’extractions de facteurs</a></li>
<li class="chapter" data-level="2.8.3" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#autres-méthodes-de-rotation-des-facteurs"><i class="fa fa-check"></i><b>2.8.3</b> Autres méthodes de rotation des facteurs</a></li>
<li class="chapter" data-level="2.8.4" data-path="analyse-factorielle-exploratoire-1.html"><a href="analyse-factorielle-exploratoire-1.html#scores-factoriels"><i class="fa fa-check"></i><b>2.8.4</b> Scores factoriels</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html"><i class="fa fa-check"></i><b>3</b> Sélection de variables et de modèles</a><ul>
<li class="chapter" data-level="3.1" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#introduction-2"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#sélection-de-variables-et-de-modèles-selon-les-buts-de-létude"><i class="fa fa-check"></i><b>3.2</b> Sélection de variables et de modèles selon les buts de l’étude</a></li>
<li class="chapter" data-level="3.3" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#mieux-vaut-plus-que-moins"><i class="fa fa-check"></i><b>3.3</b> Mieux vaut plus que moins</a></li>
<li class="chapter" data-level="3.4" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#trop-beau-pour-être-vrai"><i class="fa fa-check"></i><b>3.4</b> Trop beau pour être vrai</a></li>
<li class="chapter" data-level="3.5" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#principes-généraux"><i class="fa fa-check"></i><b>3.5</b> Principes généraux</a><ul>
<li class="chapter" data-level="3.5.1" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#choix-dun-modèle-polynomial-en-régression-linéaire"><i class="fa fa-check"></i><b>3.5.1</b> Choix d’un modèle polynomial en régression linéaire</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#critères-dinformation"><i class="fa fa-check"></i><b>3.6</b> Critères d’information</a></li>
<li class="chapter" data-level="3.7" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#division-de-léchantillon-et-validation-croisée"><i class="fa fa-check"></i><b>3.7</b> Division de l’échantillon et validation croisée</a><ul>
<li class="chapter" data-level="3.7.1" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#division-de-léchantillon"><i class="fa fa-check"></i><b>3.7.1</b> Division de l’échantillon</a></li>
<li class="chapter" data-level="3.7.2" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#validation-croisée"><i class="fa fa-check"></i><b>3.7.2</b> Validation croisée</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#cibler-les-clients-pour-lenvoi-dun-catalogue"><i class="fa fa-check"></i><b>3.8</b> Cibler les clients pour l’envoi d’un catalogue</a></li>
<li class="chapter" data-level="3.9" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#recherche-automatique-du-meilleur-modèle"><i class="fa fa-check"></i><b>3.9</b> Recherche automatique du meilleur modèle</a></li>
<li class="chapter" data-level="3.10" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#recherche-automatique-de-tous-les-sous-ensembles"><i class="fa fa-check"></i><b>3.10</b> Recherche automatique de tous les sous-ensembles</a></li>
<li class="chapter" data-level="3.11" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#méthodes-classiques-de-sélection-ascendante-descendante-et-séquentielle"><i class="fa fa-check"></i><b>3.11</b> Méthodes classiques de sélection ascendante, descendante et séquentielle</a><ul>
<li class="chapter" data-level="3.11.1" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#sélection-ascendante"><i class="fa fa-check"></i><b>3.11.1</b> Sélection ascendante</a></li>
<li class="chapter" data-level="3.11.2" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#sélection-descendante"><i class="fa fa-check"></i><b>3.11.2</b> Sélection descendante</a></li>
<li class="chapter" data-level="3.11.3" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#méthode-séquentielle"><i class="fa fa-check"></i><b>3.11.3</b> Méthode séquentielle</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#recherche-séquentielle-automatique-limitée"><i class="fa fa-check"></i><b>3.12</b> Recherche séquentielle automatique limitée</a></li>
<li class="chapter" data-level="3.13" data-path="sélection-de-variables-et-de-modèles-1.html"><a href="sélection-de-variables-et-de-modèles-1.html#moyenne-de-modèles"><i class="fa fa-check"></i><b>3.13</b> Moyenne de modèles</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html"><i class="fa fa-check"></i><b>4</b> Régression logistique</a><ul>
<li class="chapter" data-level="4.1" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#introduction-3"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#modèle-de-régression-logistique"><i class="fa fa-check"></i><b>4.2</b> Modèle de régression logistique</a></li>
<li class="chapter" data-level="4.3" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#estimation-des-paramètres"><i class="fa fa-check"></i><b>4.3</b> Estimation des paramètres</a><ul>
<li class="chapter" data-level="4.3.1" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#principes-de-base"><i class="fa fa-check"></i><b>4.3.1</b> Principes de base</a></li>
<li class="chapter" data-level="4.3.2" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#méthode-du-maximum-de-vraisemblance"><i class="fa fa-check"></i><b>4.3.2</b> Méthode du maximum de vraisemblance</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#exemple-du-professional-rodeo-cowboys-association"><i class="fa fa-check"></i><b>4.4</b> Exemple du <em>Professional Rodeo Cowboys Association</em></a><ul>
<li class="chapter" data-level="4.4.1" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#modèle-avec-une-seule-variable-explicative"><i class="fa fa-check"></i><b>4.4.1</b> Modèle avec une seule variable explicative</a></li>
<li class="chapter" data-level="4.4.2" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#interprétation-du-paramètre"><i class="fa fa-check"></i><b>4.4.2</b> Interprétation du paramètre</a></li>
<li class="chapter" data-level="4.4.3" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#modèle-avec-toutes-les-variables-explicatives"><i class="fa fa-check"></i><b>4.4.3</b> Modèle avec toutes les variables explicatives</a></li>
<li class="chapter" data-level="4.4.4" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#test-du-rapport-de-vraisemblance"><i class="fa fa-check"></i><b>4.4.4</b> Test du rapport de vraisemblance</a></li>
<li class="chapter" data-level="4.4.5" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#multicolinéarité"><i class="fa fa-check"></i><b>4.4.5</b> Multicolinéarité</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#classification-et-prédiction-à-laide-de-la-régression-logistique"><i class="fa fa-check"></i><b>4.5</b> Classification et prédiction à l’aide de la régression logistique</a></li>
<li class="chapter" data-level="4.6" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#classification-avec-une-matrice-de-gain"><i class="fa fa-check"></i><b>4.6</b> Classification avec une matrice de gain</a></li>
<li class="chapter" data-level="4.7" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#sélection-de-variables-en-régression-logistique"><i class="fa fa-check"></i><b>4.7</b> Sélection de variables en régression logistique</a><ul>
<li class="chapter" data-level="4.7.1" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#recherche-exhaustive-de-tous-les-sous-modèles"><i class="fa fa-check"></i><b>4.7.1</b> Recherche exhaustive de tous les sous-modèles</a></li>
<li class="chapter" data-level="4.7.2" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#recherche-séquentielle"><i class="fa fa-check"></i><b>4.7.2</b> Recherche séquentielle</a></li>
<li class="chapter" data-level="4.7.3" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#algorithme-glouton-et-critères-alternatifs-avec-hpgenselect"><i class="fa fa-check"></i><b>4.7.3</b> Algorithme glouton et critères alternatifs avec <code>hpgenselect</code></a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#performance-des-différents-modèles-pour-lexemple-des-clients-cibles"><i class="fa fa-check"></i><b>4.8</b> Performance des différents modèles pour l’exemple des clients cibles</a><ul>
<li class="chapter" data-level="4.8.1" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#stratégies-en-utilisant-seulement-la-régression-logistique"><i class="fa fa-check"></i><b>4.8.1</b> Stratégies en utilisant seulement la régression logistique</a></li>
<li class="chapter" data-level="4.8.2" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#stratégies-alternatives"><i class="fa fa-check"></i><b>4.8.2</b> Stratégies alternatives</a></li>
<li class="chapter" data-level="4.8.3" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#tobit2"><i class="fa fa-check"></i><b>4.8.3</b> Modèle Tobit de type 2</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#extensions-du-modèle-de-régression-logistique-à-plus-de-deux-catégories"><i class="fa fa-check"></i><b>4.9</b> Extensions du modèle de régression logistique à plus de deux catégories</a><ul>
<li class="chapter" data-level="4.9.1" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#régression-logistique-multinomiale"><i class="fa fa-check"></i><b>4.9.1</b> Régression logistique multinomiale</a></li>
<li class="chapter" data-level="4.9.2" data-path="régression-logistique-1.html"><a href="régression-logistique-1.html#régression-logistique-cumulative-à-cotes-proportionnelles"><i class="fa fa-check"></i><b>4.9.2</b> Régression logistique cumulative à cotes proportionnelles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html"><i class="fa fa-check"></i><b>5</b> Analyse de regroupements</a><ul>
<li class="chapter" data-level="5.1" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#introduction-4"><i class="fa fa-check"></i><b>5.1</b> Introduction</a><ul>
<li class="chapter" data-level="5.1.1" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#mesures-de-dissemblance"><i class="fa fa-check"></i><b>5.1.1</b> Mesures de dissemblance</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#segmentation-de-seniors-en-voyage-organisé"><i class="fa fa-check"></i><b>5.2</b> Segmentation de seniors en voyage organisé</a></li>
<li class="chapter" data-level="5.3" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#méthodes-hiérarchiques"><i class="fa fa-check"></i><b>5.3</b> Méthodes hiérarchiques</a><ul>
<li class="chapter" data-level="5.3.1" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#méthode-de-ward"><i class="fa fa-check"></i><b>5.3.1</b> Méthode de Ward</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#méthodes-non-hiérarchiques"><i class="fa fa-check"></i><b>5.4</b> Méthodes non hiérarchiques</a></li>
<li class="chapter" data-level="5.5" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#standardisation-des-variables"><i class="fa fa-check"></i><b>5.5</b> Standardisation des variables</a></li>
<li class="chapter" data-level="5.6" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#considérations-pratiques"><i class="fa fa-check"></i><b>5.6</b> Considérations pratiques</a></li>
<li class="chapter" data-level="5.7" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#exploration-graphique-préalable-et-analyse-en-composantes-principales"><i class="fa fa-check"></i><b>5.7</b> Exploration graphique préalable et analyse en composantes principales</a><ul>
<li class="chapter" data-level="5.7.1" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#analyse-en-composantes-principales"><i class="fa fa-check"></i><b>5.7.1</b> Analyse en composantes principales</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#calcul-alternatif-des-distances-pour-le-regroupement-hiérarchique"><i class="fa fa-check"></i><b>5.8</b> Calcul alternatif des distances pour le regroupement hiérarchique</a></li>
<li class="chapter" data-level="5.9" data-path="analyse-de-regroupements-1.html"><a href="analyse-de-regroupements-1.html#autres-mesures-de-dissemblance"><i class="fa fa-check"></i><b>5.9</b> Autres mesures de dissemblance</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publié avec bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analyse multidimensionnelle appliquée</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sélection-de-variables-et-de-modèles-1" class="section level1">
<h1><span class="header-section-number">Chapitre 3</span> Sélection de variables et de modèles</h1>
<div id="introduction-2" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>Ce chapitre présente des principes, outils et méthodes très généraux pour choisir un « bon » modèle. Nous allons principalement utiliser la régression linéaire pour illustrer les méthodes en supposant que tout le monde connaît ce modèle de base. Les méthodes présentées sont en revanche très générales et peuvent être appliquées avec n’importe quel autre modèle (régression logistique, arbres de classification et régression, réseaux de neurones, analyse de survie, etc.)</p>
<p>L’expression « sélection de variables » fait référence à la situation où l’on cherche à sélectionner un sous-ensemble de variables à inclure dans notre modèle à partir d’un ensemble de variables <span class="math inline">\(X_1, \ldots, X_p\)</span>. Le terme variable ici inclut autant des variables distinctes que des transformations d’une ou plusieurs variables.</p>
<p>Par exemple, supposons que les variables <code>age</code>, <code>sexe</code> et <code>revenu</code> sont trois variables explicatives disponibles. Nous pourrions alors considérer choisir entre ces trois variables. Mais aussi, nous pourrions considérer inclure <span class="math inline">\(\mathrm{age}^2\)</span>, <span class="math inline">\(\mathrm{age}^3\)</span>, <span class="math inline">\(\log(\mathrm{age})\)</span>, etc. Nous pourrions aussi considérer des termes d’interactions entre les variables, comme <span class="math inline">\(\mathrm{age} \cdot \mathrm{revenu}\)</span> ou <span class="math inline">\(\mathrm{age}\cdot\mathrm{revenu}\cdot\mathrm{sexe}\)</span>. Le problème est alors de trouver un bon sous-ensemble de variables parmi toutes celles considérées.</p>
<p>L’expression « sélection de modèle » est un peu plus générale. D’une part, elle inclut la sélection de variables car, pour une famille de modèles spécifiques (régression linéaire par exemple), choisir un sous-ensemble de variables revient à choisir un modèle. D’autre part, elle est plus générale car elle peut aussi faire référence à la situation où l’on cherche à trouver le meilleur modèle parmi des modèles de natures différentes. Par exemple, on pourrait choisir entre une régression linéaire, un arbre de régression, une forêt aléatoire, un réseau de neurones, etc.</p>
</div>
<div id="sélection-de-variables-et-de-modèles-selon-les-buts-de-létude" class="section level2">
<h2><span class="header-section-number">3.2</span> Sélection de variables et de modèles selon les buts de l’étude</h2>
<p>Nous disposons d’une variable réponse <span class="math inline">\(Y\)</span> et d’un ensemble de variables explicatives <span class="math inline">\(X_1, \ldots, X_p\)</span>. L’attitude à adopter dépend des buts de l’étude.</p>
<p>1e situation : On veut développer un modèle pour faire des prédictions sans qu’il soit important de tester formellement les effets des paramètres individuels.</p>
<p>Dans ce cas, on désire seulement que notre modèle soit performant pour prédire des valeurs futures de <span class="math inline">\(Y\)</span>. On peut alors baser notre choix de variable (et de modèle) en utilisant des outils qui nous guiderons quant aux performances prédictives futures du modèle (voir <span class="math inline">\(\mathsf{AIC}\)</span>, <span class="math inline">\(\mathsf{BIC}\)</span> et validation croisée plus loin). On pourra enlever ou rajouter des variables et des transformations de variables au besoin afin d’améliorer les performances prédictives. Les méthodes que nous allons voir concernent essentiellement ce contexte.</p>
<p>2e situation : On veut développer un modèle pour estimer les effets de certaines variables sur notre <span class="math inline">\(Y\)</span> et tester des hypothèses de recherche spécifiques concernant certaines variables.</p>
<p>Dans ce cas, il est préférable de spécifier le modèle dès le départ selon des considérations scientifiques et de s’en tenir à lui. Faire une sélection de variables dans ce cas est dangereux car on ne peut pas utiliser directement les valeurs-<em>p</em> des tests d’hypothèses (ou les intervalles de confiance sur les paramètres) concernant les paramètres du modèle final car elles ne tiennent pas compte de la variabilité due au processus de sélection de variables.</p>
<p>Une bonne planification de l’étude est alors cruciale afin de collecter les bonnes variables, de spécifier le ou les bons modèles, et de s’assurer d’avoir suffisamment d’observations pour ajuster le ou les modèles désirés.</p>
<p>Si procéder à une sélection de variables est quand même nécessaire dans ce contexte, il est quand même possible de le faire en divisant l’échantillon en deux. La sélection de variables pourrait être alors effectuée avec le premier échantillon. Une fois qu’un modèle est retenu, on pourrait alors réajuster ce modèle avec le deuxième échantillon (sans faire de sélection de variables cette fois-ci). L’inférence sur les paramètres (valeurs-<em>p</em>, etc.) sera alors valide. Le désavantage ici qu’il faut avoir une très grande taille d’échantillon au départ afin d’être en mesure de le diviser en deux.</p>
</div>
<div id="mieux-vaut-plus-que-moins" class="section level2">
<h2><span class="header-section-number">3.3</span> Mieux vaut plus que moins</h2>
<p>Il est préférable d’avoir un modèle un peu trop complexe qu’un modèle trop simple. Plaçons-nous dans le contexte de la régression linéaire et supposons que le vrai modèle est inclus dans le modèle qui a été ajusté. Il y a donc des variables en trop dans le modèle qui a été ajusté. Le modèle ajusté est surspécifié.</p>
<p>Par exemple, supposons que le vrai modèle est <span class="math inline">\(Y=\beta_0+\beta_1X_1+\varepsilon\)</span> mais que c’est le modèle <span class="math inline">\(Y=\beta_0+\beta_1X_1+\beta_2X_2+\varepsilon\)</span> qui a été ajusté. Dans ce cas, règle générale, les estimateurs des paramètres et les prédictions provenant du modèle sont sans biais. Mais leurs variances estimées seront un peu plus élevées car on estime des paramètres pour des variables superflues.</p>
<p>Supposons à l’inverse qu’il manque des variables dans le modèle ajusté et que le modèle ajusté est sous-spécifié. Par exemple, supposons que le vrai modèle est <span class="math inline">\(Y=\beta_0+\beta_1X_1+\beta_2X_2+\varepsilon\)</span>, mais que c’est le modèle <span class="math inline">\(Y=\beta_0+\beta_1X_1+\varepsilon\)</span> qui a été ajusté. Dans ce cas, généralement, les estimateurs des paramètres et les prédictions sont biaisés.</p>
<p>Ainsi, il est généralement préférable d’avoir un modèle légèrement surspécifié qu’un modèle sous-spécifié. Plus généralement, il est préférable d’avoir un peu trop de variables dans le modèle que de prendre le risque d’omettre une ou plusieurs variables importantes. Encore plus généralement, il est préférable d’avoir un modèle un peu trop complexe que d’avoir un modèle trop simple.</p>
<p>Il faut faire attention et ne pas tomber dans l’excès et avoir un modèle trop complexe (avec trop de variables inutiles) car il pourrait souffrir de surajustement (<em>over-fitting</em>). Les exemples qui suivent illustreront ce fait.</p>
</div>
<div id="trop-beau-pour-être-vrai" class="section level2">
<h2><span class="header-section-number">3.4</span> Trop beau pour être vrai</h2>
<p>Cette section traite de l’optimisme de l’évaluation d’un modèle lorsqu’on utilise les mêmes données qui ont servies à l’ajuster pour évaluer sa performance. Un principe fondamental lorsque vient le temps d’évaluer la performance prédictive d’un modèle est le suivant : si on utilise les mêmes observations pour évaluer la performance d’un modèle que celles qui ont servi à l’ajuster (à estimer le modèle et ses paramètres), on va surestimer sa performance. Autrement dit, notre estimation de l’erreur que fera le modèle pour prédire des observations futures sera biaisée à la baisse. Ainsi, il aura l’air meilleur que ce qu’il est en réalité. C’est comme si on demandait à un cinéaste d’évaluer son dernier film. Comme c’est son film, il n’aura généralement pas un regard objectif. C’est pourquoi on aura tendance à se fier à l’opinion d’un critique.</p>
<p>On cherchera donc à utiliser des outils et méthodes qui nous donneront l’heure juste (une évaluation objective) quant à la performance prédictive d’un modèle.</p>
</div>
<div id="principes-généraux" class="section level2">
<h2><span class="header-section-number">3.5</span> Principes généraux</h2>
<p>Les idées présentées ici seront illustrées à l’aide de la régression linéaire. Par contre, elles sont valides dans à peu près n’importe quel contexte de modélisation.</p>
<p>Plaçons-nous d’abord dans un contexte plus général que celui de la régression linéaire. Supposons que l’on dispose de <span class="math inline">\(n\)</span> observations indépendantes sur (<span class="math inline">\(Y, X_1, \ldots, Xp\)</span>) et que l’on a ajusté un modèle <span class="math inline">\(\widehat{f}(X_1, \ldots, X_p)\)</span>, avec ces données, pour prédire une variable continue <span class="math inline">\(Y\)</span>.</p>
<p>Ce modèle peut être un modèle de régression linéaire,
<span class="math display">\[\begin{align*}
\widehat{f}(X_1, \ldots, X_p) = \widehat{\beta}_0 + \widehat{\beta}_1X_1 + \cdots + \widehat{\beta}_pX_p
\end{align*}\]</span>
mais il pourrait aussi avoir été construit selon d’autres méthodes (réseau de neurones, arbre de régression, forêt aléatoire, etc.) Une manière de quantifier la performance prédictive du modèle est l’erreur quadratique moyenne de généralisation (<em>generalization mean squared error</em>),
<span class="math display">\[\begin{align*}
\mathsf{EMQ}=\mathsf{E}\left[\left\{(Y-\widehat{f}(X_1, \ldots, X_p)\right\}^2\right]
\end{align*}\]</span>
lorsque (<span class="math inline">\(Y, X_1, \ldots, X_p\)</span>) est choisi au hasard dans la population. Cette quantité mesure l’erreur (la différence au carré entre la vraie valeur de <span class="math inline">\(Y\)</span> et la valeur prédite par le modèle) que fait le modèle en moyenne pour l’ensemble de la population. Plus cette quantité est petite, meilleur est le modèle. Le problème est que l’on ne peut pas la calculer, car on ne connaît pas toute la population. Tout au plus peut-on essayer de l’estimer ou bien d’estimer une fonction qui, sans l’estimer directement, classifiera les modèles dans le même ordre qu’elle.</p>
<p>Une première idée est d’estimer <span class="math inline">\(\mathsf{EMQ}\)</span> avec l’erreur quadratique moyenne de l’échantillon d’apprentissage (<em>training mean squared error</em>),
<span class="math display">\[\begin{align*}
\widehat{\mathsf{EMQ}}_a= \frac{1}{n}\sum_{i=1}^n \left\{Y_i-\widehat{f}(X_{i1}, \ldots, X_{ip})\right\}^2.
\end{align*}\]</span>
Cette quantité est tout simplement l’équivalent du <span class="math inline">\(\mathsf{EMQ}\)</span>, mais est calculée en utilisant seulement notre échantillon.</p>
<p>Malheureusement, selon le principe fondamental de la section précédente, cette quantité n’est pas un bon estimateur de l’<span class="math inline">\(\mathsf{EMQ}\)</span>. En effet, comme on utilise les mêmes observations que celles qui ont estimé le modèle, l’<span class="math inline">\(\widehat{\mathsf{EMQ}}_a\)</span> aura tendance à toujours diminuer lorsqu’on augmente la complexité du modèle (par exemple, lorsqu’on augmente le nombre de paramètres). L’<span class="math inline">\(\widehat{\mathsf{EMQ}}_a\)</span> tend à surestimer la qualité du modèle en sous-estimant l’<span class="math inline">\(\mathsf{EMQ}\)</span>. C’est-à-dire, le modèle a l’air meilleur qu’il ne l’est en réalité.</p>
<div id="choix-dun-modèle-polynomial-en-régression-linéaire" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Choix d’un modèle polynomial en régression linéaire</h3>
<p>Cet exemple simple servira à illustrer le fait qu’on ne peut utiliser directement les mêmes données qui ont servi à ajuster un modèle pour évaluer sa performance.</p>
<p>Nous disposons de 100 observations sur une variable cible <span class="math inline">\(Y\)</span> et d’une seule variable explicative <span class="math inline">\(X\)</span>. Le fichier <code>selection1_train.xls</code> contient les données. Nous voulons considérer des modèles polynomiaux (en <span class="math inline">\(X\)</span>) afin d’en trouver un bon pour prédire <span class="math inline">\(Y\)</span>. Un modèle polynomial est un modèle de la forme <span class="math inline">\(Y=\beta_0 + \beta_1X+\cdots+\beta_kX^k+\varepsilon\)</span>. Le cas <span class="math inline">\(k=1\)</span> correspond à un modèle linéaire simple, <span class="math inline">\(k=2\)</span> à un modèle cubique, <span class="math inline">\(k=3\)</span> à un modèle cubique, etc. Notre but est de déterminer l’ordre (<span class="math inline">\(k\)</span>) du polynôme qui nous donnera un bon modèle. Voici d’abord le graphe de ces 100 observations.</p>
<p><img src="MATH60602_files/figure-html/02-graphedonneestest-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Il s’agit de l’échantillon d’apprentissage. Ces données ont été obtenues par simulation et le vrai modèle sous-jacent (celui qui a généré les données) est le modèle cubique, c’est-à-dire le modèle d’ordre <span class="math inline">\(k=3\)</span>.</p>
<p>Afin de simuler une population, j’ai généré selon le même modèle 100 000 observations supplémentaires. Ces observations ne vont pas servir à estimer les modèles mais seulement à évaluer leur performance afin d’avoir une estimation sans biais. Ces données se trouvent dans <code>selection1_test.xls</code></p>
<p>J’ai ajusté tour à tour à tour les modèles polynomiaux jusqu’à l’ordre 10, avec l’échantillon d’apprentissage de taille 100. C’est-à-dire, le modèle linéaire avec un polynôme d’ordre <span class="math inline">\(k=1\)</span> (linéaire), <span class="math inline">\(k=2\)</span> (quadratique), etc., jusqu’à <span class="math inline">\(k=10\)</span>. J’ai ensuite obtenu la valeur de l’erreur moyenne quadratique d’apprentissage pour chacun de ces modèles. J’ai ensuite utilisé ces modèles afin de prédire les 100 000 autres observations (la population) et calculé les 100 000 observations de l’échantillon test pour obtenir une très bonne approximation de l’erreur quadratique moyenne de généralisation.</p>
<p>Voici le graphe de l’<span class="math inline">\(\widehat{\mathsf{EMQ}}_a\)</span> et de l’<span class="math inline">\(\mathsf{EMQ}\)</span> de généralisation en fonction de l’ordre (<span class="math inline">\(k\)</span>) du modèle utilisé.</p>
<pre><code>## Loading required package: lattice</code></pre>
<p><img src="MATH60602_files/figure-html/02-plotEMQa-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>On voit clairement que l’<span class="math inline">\(\widehat{\mathsf{EMQ}}_a\)</span> diminue en fonction de l’ordre sur l’échantillon d’apprentissage. C’est-à-dire, plus le modèle est complexe, plus l’erreur observée sur l’échantillon d’apprentissage est petite. Mais cela est trompeur. La courbe <span class="math inline">\(\mathsf{EMQ}\)</span> donne l’heure juste. Il s’agit d’une estimation de la performance réelle des modèles sur de nouvelles données. On voit que le meilleur modèle est donc le modèle cubique (<span class="math inline">\(k=3\)</span>). Ce qui n’est pas surprenant car il s’agit du modèle que j’ai utilisé pour générer les données. On peut aussi remarquer d’autres éléments intéressants. Premièrement, on obtient un bon gain en performance (<span class="math inline">\(\mathsf{EMQ}\)</span>) en passant de l’ordre <span class="math inline">\(2\)</span> à l’ordre <span class="math inline">\(3\)</span>. Ensuite, la perte de performance en passant de l’ordre <span class="math inline">\(3\)</span> à <span class="math inline">\(4\)</span>, et ensuite à des ordres supérieurs n’est pas si sévère, même si elle est présente. Cela illustre empiriquement qu’il est préférable d’avoir un modèle un peu trop complexe que d’avoir un modèle trop simple. Il serait beaucoup plus grave pour la performance de choisir le modèle avec <span class="math inline">\(k=2\)</span> que celui avec <span class="math inline">\(k=4\)</span>.</p>
<p>En pratique par contre, on n’a pas accès à la population : les 100 000 observations qui ont servi à estimer l’<span class="math inline">\(\mathsf{EMQ}\)</span> théorique ne seront pas disponible. Si on a seulement l’échantillon d’apprentissage, soit 100 observations dans notre exemple, comment faire alors pour choisir le bon modèle? C’est ce que nous verrons à partir de la section suivante.</p>
<p>Mais avant cela, nous allons discuter un peu plus en détail au sujet de la régression linéaire et d’une mesure très connue, le coefficient de détermination (<span class="math inline">\(R^2\)</span>). Supposons que l’on a ajusté un modèle de régression linéaire
<span class="math display">\[\begin{align*}
\widehat{f}(X_1, \ldots, X_p) = \widehat{Y}=\widehat{\beta}_0 + \widehat{\beta}_1X_1+ \cdots + \widehat{\beta}_p X_p.
\end{align*}\]</span>
La somme du carré des erreurs (<span class="math inline">\(\mathsf{SCE}\)</span>) pour notre échantillon est
<span class="math display">\[\begin{align*}
\mathsf{SCE}=\sum_{i=1}^n (Y_i - \widehat{\beta}_0 + \widehat{\beta}_1X_1+ \cdots + \widehat{\beta}_p X_p)^2 = \sum_{i=1}^n (Y_i-\widehat{Y}_i)^2.
 \end{align*}\]</span>
On peut démontrer que si on ajoute une variable quelconque au modèle, la valeur de la somme du carré des erreurs va nécessairement baisser. Il est facile de se convaincre de cela. En régression linéaire, les estimations sont obtenues par la méthode des moindres carrés qui consiste justement à minimiser la <span class="math inline">\(\mathsf{SCE}\)</span>. Ainsi, en ajoutant une variable <span class="math inline">\(X_{p+1}\)</span> au modèle, la <span class="math inline">\(\mathsf{SCE}\)</span> ne peut que baisser car, dans le pire des cas, le paramètre de la nouvelle variable sera <span class="math inline">\(\widehat{\beta}_{p+1}=0\)</span> et on retombera sur le modèle sans cette variable. C’est pourquoi, la quantité <span class="math inline">\(\widehat{\mathsf{EMQ}}_a=\mathsf{SCE}/n\)</span> ne peut être utilisée comme outil de sélection de modèles en régression linéaire.</p>
<p>Nous venons d’ailleurs d’illustrer cela avec notre exemple sur les modèles polynomiaux. En effet, augmenter l’ordre du polynôme de <span class="math inline">\(1\)</span> revient à ajouter une variable. Le coefficient de détermination (<span class="math inline">\(R^2\)</span>) est souvent utilisé comme mesure de qualité du modèle. Il peut s’interpréter comme étant la proportion de la variance de <span class="math inline">\(Y\)</span> qui est expliquée par le modèle.</p>
<p>Le coefficient de détermination est
<span class="math display">\[\begin{align*}
R^2=\{\mathsf{cor}(\boldsymbol{y}, \widehat{\boldsymbol{y}})\}^2 = 1-\frac{\mathsf{SCE}}{\mathsf{SCT}},
\end{align*}\]</span>
où <span class="math inline">\(\mathsf{SCT}=\sum_{i=1}^n (Y_i-\overline{Y})^2\)</span> est la somme des carrés totale calculée en centrant les observations. La somme des carrés totale, <span class="math inline">\(\mathsf{SCT}\)</span>, ne varie pas en fonction du modèle.
Ainsi, on voit que le <span class="math inline">\(R^2\)</span> va nécessairement augmenter lorsqu’on ajoute une variable au modèle (car la <span class="math inline">\(\mathsf{SCE}\)</span> diminue). C’est pourquoi on ne peut pas l’utiliser comme outil de sélection de variables.</p>
<p>Le problème principal que nous avons identifié jusqu’à présent afin d’être en mesure de bien estimer la performance d’un modèle est le suivant : si on utilise les mêmes observations pour évaluer la performance d’un modèle que celles qui ont servi à l’ajuster on va surestimer sa performance.</p>
<p>Il existe deux grandes approches pour contourner ce problème lorsque le but est de faire de la sélection de variables ou de modèle :</p>
<ul>
<li>utiliser les données de l’échantillon d’apprentissage (en échantillon) et pénaliser <span class="math inline">\(\widehat{\mathsf{EMQ}}_a\)</span> pour tenir compte de la complexité du modèle (<span class="math inline">\(\mathsf{AIC}\)</span>, <span class="math inline">\(\mathsf{BIC}\)</span>).</li>
<li>tenter d’estimer l’<span class="math inline">\(\mathsf{EMQ}\)</span> directement sur d’autres données (hors échantillon) en utilisant des méthodes de rééchantillonnage, notamment la validation croisée et la division de l’échantillon.</li>
</ul>
</div>
</div>
<div id="critères-dinformation" class="section level2">
<h2><span class="header-section-number">3.6</span> Critères d’information</h2>
<p>Plaçons-nous dans le contexte de la régression linéaire pour l’instant.
Nous avons déjà utilisé les critères <span class="math inline">\(\mathsf{AIC}\)</span> et <span class="math inline">\(\mathsf{BIC}\)</span> en analyse factorielle. Il s’agit de mesures qui découlent d’une méthode d’estimation des paramètres, la méthode du maximum de vraisemblance (<em>maximum likelihood</em>).</p>
<p>Il s’avère que les estimateurs des paramètres obtenus par la méthode des moindres carrés en régression linéaire sont équivalents à ceux provenant de la méthode du maximum de vraisemblance si on suppose la normalité des termes d’erreurs du modèle. Ainsi, dans ce cas, nous avons accès aux <span class="math inline">\(\mathsf{AIC}\)</span> et <span class="math inline">\(\mathsf{BIC}\)</span>, deux critères d’information définis pour les modèles dont la fonction objective est la vraisemblance (qui mesure la probabilité des observations sous le modèle postulé suivant une loi choisie par l’utilisateur). La fonction de vraisemblance <span class="math inline">\(\mathcal{L}\)</span> et la log-vraisemblance <span class="math inline">\(\ell\)</span> mesurent l’adéquation du modèle.</p>
<p>Supposons que nous avons ajusté un modèle avec <span class="math inline">\(p\)</span> paramètres en tout (<strong>incluant</strong> l’ordonnée à l’origine). En régression linéaire, le critère d’information d’Akaike, <span class="math inline">\(\mathsf{AIC}\)</span>, est
<span class="math display">\[\begin{align*}
\mathsf{AIC} &amp;=-2 \ell(\widehat{\boldsymbol{\beta}}, \widehat{\sigma}^2) +2p=n \ln (\mathsf{SCE}) - n\ln(n) + 2p,
\end{align*}\]</span>
tandis que le critère d’information bayésien de Schwartz, <span class="math inline">\(\mathsf{BIC}\)</span>, est défini par
<span class="math display">\[\begin{align*}
\mathsf{BIC} &amp;=-2 \ell(\widehat{\boldsymbol{\beta}}, \widehat{\sigma}^2) + p\ln(n)=n \ln (\mathsf{SCE}) - n\ln(n) + p\ln(n)
\end{align*}\]</span>
Plus la valeur du <span class="math inline">\(\mathsf{AIC}\)</span> (ou du <span class="math inline">\(\mathsf{BIC}\)</span>) est petite, meilleur est l’adéquation. Que se passE-t-il lorsqu’on ajoute un paramètre à un modèle? D’une part, la somme du carré des erreurs va méchaniquement diminuer, et donc la quantité <span class="math inline">\(n \ln (\mathsf{SCE}/n)\)</span> va diminuer. D’autre part, la valeur de <span class="math inline">\(p\)</span> augmente de <span class="math inline">\(1\)</span>. Ainsi, le <span class="math inline">\(\mathsf{AIC}\)</span> peut soit augmenter, soit diminuer, lorsqu’on ajoute un paramètre; idem pour le <span class="math inline">\(\mathsf{BIC}\)</span>. Par exemple, le <span class="math inline">\(\mathsf{AIC}\)</span> va diminuer seulement si la baisse de la somme du carré des erreurs est suffisante pour compenser le fait que le terme <span class="math inline">\(2p\)</span> augmente à <span class="math inline">\(2 (p+1)\)</span>.</p>
<p>Ces critères pénalisent l’ajout de variables afin de se prémunir contre le surajustement. De plus, le <span class="math inline">\(\mathsf{BIC}\)</span> pénalise plus que le <span class="math inline">\(\mathsf{AIC}\)</span>. Par conséquent, le critère <span class="math inline">\(\mathsf{BIC}\)</span> va choisir des modèles contenant soit le même nombre, soit moins de paramètres que le <span class="math inline">\(\mathsf{AIC}\)</span>.</p>
<p>Les critères <span class="math inline">\(\mathsf{AIC}\)</span> et <span class="math inline">\(\mathsf{BIC}\)</span> peuvent être utilisés comme outils de sélection de variables en régression linéaire mais aussi beaucoup plus généralement avec d’autres méthodes basées sur la vraisemblance (analyse factorielle, régression logistique, etc.) En fait, n’importe quel modèle dont les estimateurs proviennent de la méthode du maximum de vraisemblance produira ces quantités. Nous donnerons des formules générales pour le <span class="math inline">\(\mathsf{AIC}\)</span> et le <span class="math inline">\(\mathsf{BIC}\)</span> dans le chapitre sur la régression logistique.</p>
<p>Le critère <span class="math inline">\(\mathsf{BIC}\)</span> est le seul de ces critères qui est convergent. Cela veut dire que si l’ensemble des modèles que l’on considère contient le vrai modèle, alors la probabilité que le critère <span class="math inline">\(\mathsf{BIC}\)</span> choisissent le bon model tend vers 1 lorsque <span class="math inline">\(n\)</span> tend vers l’infini. Il faut mettre cela en perspective : il est peu vraisemblable que <span class="math inline">\(Y\)</span> ait été généré exactement selon un modèle de régression linéaire, car le modèle de régression n’est qu’une approximation de la réalité. Certains auteurs trouvent que le <span class="math inline">\(\mathsf{BIC}\)</span> est quelquefois trop sévère (il choisit des modèles trop simples) pour les tailles d’échantillons finies. Dans certaines applications, cette parsimonie est utile, mais il n’est pas possible de savoir d’avance lequel de ces deux critères (<span class="math inline">\(\mathsf{AIC}\)</span> et <span class="math inline">\(\mathsf{BIC}\)</span>) sera préférable pour un problème donné.</p>
<p>Avant de revenir à l’exemple, voici la description d’une modification du coefficient de détermination, le <span class="math inline">\(R^2\)</span> ajusté, qui permet (contrairement au <span class="math inline">\(R^2\)</span>) de faire de la sélection de variables. En régression linéaire, le <span class="math inline">\(R^2\)</span> ajusté est
<span class="math display">\[\begin{align*}
R^2_a=1-\frac{\mathsf{SCE}/(n-p)}{\mathsf{SCT}/(n-1)}.
\end{align*}\]</span>
Lorsqu’on ajoute une variable, la somme du carré des erreurs (<span class="math inline">\(\mathsf{SCE}\)</span>) diminue mais c’est aussi le cas de la quantité <span class="math inline">\((n-p)\)</span>. Ainsi, le <span class="math inline">\(R^2\)</span> ajusté peut soit augmenter, soit diminuer lorsqu’on ajoute une variable. On peut donc l’utiliser pour choisir le modèle. Plus <span class="math inline">\(R^2_a\)</span> est élevé, mieux c’est. Ce critère est moins sévère que le <span class="math inline">\(\mathsf{AIC}\)</span>, Ainsi, en général, il va choisir un modèle avec le même nombre ou bien avec plus de paramètres que le <span class="math inline">\(\mathsf{AIC}\)</span>. Pour résumer, on aura la situation suivante :
<span class="math display">\[ \#(\mathsf{BIC}) \leq \#(\mathsf{AIC}) \leq \#(R^2_a),\]</span>
où <span class="math inline">\(\#\)</span> représente le nombre de paramètres du modèle linéaire.</p>
<p>Il est facile d’obtenir les quantités <span class="math inline">\(R^2_a\)</span>, <span class="math inline">\(\mathsf{AIC}\)</span> et <span class="math inline">\(\mathsf{BIC}\)</span> avec la procédure <code>glmselect</code> dans <strong>SAS</strong>. Le fichier <code>selection1_intro.sas</code> contient les programmes. La sortie qui suit provient des commandes :</p>
<pre class="sas"><code>proc glmselect data=multi.selection1_train;
model y=x x*x x*x*x /selection=none;
run;</code></pre>
<p>Il s’agit du modèle cubique (d’ordre 3) en <span class="math inline">\(x\)</span>.</p>
<p><img src="figures/02-select-e1.png" width="70%" style="display: block; margin: auto;" />
<img src="figures/02-select-e2.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Le tableau qui suit résume ces quantités pour tous les modèles de l’ordre 1 à l’ordre 10.</p>
<table>
<caption><span id="tab:02-table1">Tableau 3.1: </span>Mesures d’adéquation du modèle linéaire et estimés de l’erreur</caption>
<thead>
<tr class="header">
<th></th>
<th align="right"><span class="math inline">\(\mathsf{EMQ}\)</span></th>
<th align="right"><span class="math inline">\(\widehat{\mathsf{EMQ}}_a\)</span></th>
<th align="right"><span class="math inline">\(R^2\)</span></th>
<th align="right"><span class="math inline">\(R^2_a\)</span></th>
<th align="right"><span class="math inline">\(\mathsf{AIC}\)</span></th>
<th align="right"><span class="math inline">\(\mathsf{BIC}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td align="right">3191.29</td>
<td align="right">3674.20</td>
<td align="right">0.65</td>
<td align="right">0.65</td>
<td align="right">1110.70</td>
<td align="right">1118.51</td>
</tr>
<tr class="even">
<td>2</td>
<td align="right">3132.67</td>
<td align="right">2879.24</td>
<td align="right">0.73</td>
<td align="right">0.72</td>
<td align="right">1088.32</td>
<td align="right">1098.74</td>
</tr>
<tr class="odd">
<td>3</td>
<td align="right">2697.40</td>
<td align="right">2620.05</td>
<td align="right">0.75</td>
<td align="right">0.74</td>
<td align="right">1080.88</td>
<td align="right">1093.91</td>
</tr>
<tr class="even">
<td>4</td>
<td align="right">2766.68</td>
<td align="right">2581.70</td>
<td align="right">0.75</td>
<td align="right">0.74</td>
<td align="right">1081.41</td>
<td align="right">1097.04</td>
</tr>
<tr class="odd">
<td>5</td>
<td align="right">2771.05</td>
<td align="right">2580.86</td>
<td align="right">0.75</td>
<td align="right">0.74</td>
<td align="right">1083.38</td>
<td align="right">1101.61</td>
</tr>
<tr class="even">
<td>6</td>
<td align="right">2779.66</td>
<td align="right">2577.60</td>
<td align="right">0.75</td>
<td align="right">0.74</td>
<td align="right">1085.25</td>
<td align="right">1106.09</td>
</tr>
<tr class="odd">
<td>7</td>
<td align="right">2780.21</td>
<td align="right">2577.49</td>
<td align="right">0.75</td>
<td align="right">0.74</td>
<td align="right">1087.24</td>
<td align="right">1110.69</td>
</tr>
<tr class="even">
<td>8</td>
<td align="right">2797.35</td>
<td align="right">2531.00</td>
<td align="right">0.76</td>
<td align="right">0.74</td>
<td align="right">1087.42</td>
<td align="right">1113.48</td>
</tr>
<tr class="odd">
<td>9</td>
<td align="right">2811.07</td>
<td align="right">2527.85</td>
<td align="right">0.76</td>
<td align="right">0.73</td>
<td align="right">1089.30</td>
<td align="right">1117.96</td>
</tr>
<tr class="even">
<td>10</td>
<td align="right">2848.81</td>
<td align="right">2519.14</td>
<td align="right">0.76</td>
<td align="right">0.73</td>
<td align="right">1090.95</td>
<td align="right">1122.22</td>
</tr>
</tbody>
</table>
<p>Les colonnes <span class="math inline">\(\mathsf{EMQ}\)</span> et <span class="math inline">\(\widehat{\mathsf{EMQ}}_a\)</span> ont déjà été expliquées à la section précédente et ont été représentées graphiquement.
On voit que le augmente toujours au fur et à mesure qu’on ajoute une variable (augmente l’ordre du polynôme). Les critères <span class="math inline">\(\mathsf{AIC}\)</span> et <span class="math inline">\(\mathsf{BIC}\)</span> choisissent le modèle cubique (<span class="math inline">\(k=3\)</span>), c’est-à-dire le bon modèle. Le <span class="math inline">\(R^2\)</span> ajusté quant à lui choisit le modèle d’ordre <span class="math inline">\(4\)</span> (qui est le deuxième meilleur selon le <span class="math inline">\(\mathsf{EMQ}\)</span>). N’oubliez pas que ces trois critères sont calculés avec l’échantillon d’apprentissage (<span class="math inline">\(n=100\)</span>), mais en pénalisant l’ajout de variables. On est ainsi en mesure de contrecarrer le problème provenant du fait qu’on ne peut pas utiliser directement le <span class="math inline">\(\widehat{\mathsf{EMQ}}_a\)</span>.</p>
<p>Le <span class="math inline">\(\mathsf{AIC}\)</span> et le <span class="math inline">\(\mathsf{BIC}\)</span> sont des critères très utilisés et très généraux. Ils sont disponibles dès qu’on utilise la méthode du maximum de vraisemblance est utilisée comme méthode d’estimation. Le <span class="math inline">\(R^2\)</span> ajusté a une portée plus limitée car il est spécialisé à la régression linéaire.</p>
</div>
<div id="division-de-léchantillon-et-validation-croisée" class="section level2">
<h2><span class="header-section-number">3.7</span> Division de l’échantillon et validation croisée</h2>
<p>La deuxième grande approche après celle consistant à pénaliser le <span class="math inline">\(\widehat{\mathsf{EMQ}}_a\)</span> consiste à tenter d’estimer le <span class="math inline">\(\mathsf{EMQ}\)</span> directement. Nous allons voir deux telles méthodes ici, la division de l’échantillon et la validation croisée (<em>cross-validation</em>).</p>
<p>Ces deux méthodes s’attaquent directement au problème qu’on ne peut utiliser (sans ajustement) les mêmes données qui ont servi à estimer les paramètres d’un modèle pour estimer sa performance. Pour ce faire, l’échantillon de départ est divisé en deux, ou plusieurs parties, qui vont jouer des rôles différents.</p>
<div id="division-de-léchantillon" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Division de l’échantillon</h3>
<p>Cette idée est très simple. Nous avons un échantillon de taille n. Nous pouvons le diviser au hasard en deux parties de tailles respectives <span class="math inline">\(n_1\)</span> et <span class="math inline">\(n_2\)</span> (<span class="math inline">\(n_1+n_2=n\)</span>),</p>
<ul>
<li>un échantillon d’apprentissage (<em>training</em>) de taille <span class="math inline">\(n_1\)</span> et</li>
<li>un échantillon de validation de taille <span class="math inline">\(n_2\)</span>.</li>
</ul>
<p>L’échantillon d’apprentissage servira à estimer les paramètres du modèle. L’échantillon de validation servira à estimer la performance prédictive (par exemple estimer l’<span class="math inline">\(\mathsf{EMQ}\)</span>) du modèle. Comme cet échantillon n’a pas servi à estimer le modèle lui-même, il est formé de « nouvelles » observations qui permettent d’évaluer d’une manière réaliste la performance du modèle. Comme il s’agit de nouvelles observations, on n’a pas à pénaliser la complexité du modèle et on peut directement utiliser le critère de performance choisi, par exemple, l’erreur quadratique moyenne, c’est-à-dire, la moyenne des erreurs au carré pour l’échantillon de validation. Cette quantité est une estimation valable de l’<span class="math inline">\(\mathsf{EMQ}\)</span> de ce modèle. On peut faire la même chose pour tous les modèles en compétition et choisir celui qui a la meilleure performance sur l’échantillon de validation.</p>
<p>Cette approche possède plusieurs avantages. Elle est facile à implanter. Elle est encore plus générale que les critères <span class="math inline">\(\mathsf{AIC}\)</span> et <span class="math inline">\(\mathsf{BIC}\)</span>. En effet, ces critères découlent de la méthode d’estimation du maximum de vraisemblance. Plusieurs autres types de modèles ne sont pas estimés par la méthode du maximum de vraisemblance (par exemple, les arbres, les forêts aléatoires, les réseaux de neurones, etc.) La performance de ces modèles peut toujours être estimée en divisant l’échantillon. Cette méthode peut donc servir à comparer des modèles de familles différentes. Par exemple, choisit-on un modèle de régression linéaire, une forêt aléatoire ou bien un réseau de neurones?</p>
<p>Cette approche possède tout de même un désavantage. Elle nécessite une grande taille d’échantillon au départ. En effet, comme on divise l’échantillon, on doit en avoir assez pour bien estimer les paramètres du modèle (l’échantillon d’apprentissage) et assez pour bien estimer sa performance (l’échantillon de validation).</p>
<p>La méthode consistant à diviser l’échantillon en deux (apprentissage et validation) afin de sélectionner un modèle est valide. Par contre, si on veut une estimation sans biais de la performance du modèle choisi (celui qui est le meilleur sur l’échantillon de validation), on ne peut pas utiliser directement la valeur observée de l’erreur de ce modèle sur l’échantillon de validation. Elle risque de sous-évaluer l’erreur. En effet, supposons qu’on a 10 échantillons et qu’on ajuste 10 fois le même modèle séparément sur les 10 échantillons. Nous aurons alors 10 estimations différentes de l’erreur du modèle. Il est alors évident que de choisir la plus petite d’entre elles sous-estimerait la vraie erreur du modèle. C’est un peu ce qui se passe lorsqu’on choisit le modèle qui minimise l’erreur sur l’échantillon de validation. Le modèle lui-même est un bon choix, mais l’estimation de son erreur risque d’être sous-évaluée.</p>
<p>Une manière d’avoir une estimation de l’erreur du modèle retenu consiste à diviser l’échantillon de départ en trois (plutôt que deux). Aux échantillons d’apprentissage et de validation, s’ajoute un échantillon « test ». Cet échantillon est laissé de côté durant tout le processus de sélection du modèle qui est effectué avec les deux premiers échantillons tel qu’expliqué plus haut. Une fois un modèle retenu (par exemple celui qui minimise l’erreur sur l’échantillon de validation), on peut alors évaluer sa performance sur l’échantillon test qui n’a pas encore été utilisé jusque là. L’estimation de l’erreur du modèle retenu sera ainsi valide. Il est évident que pour procéder ainsi, on doit avoir une très grande taille d’échantillon au départ.</p>
</div>
<div id="validation-croisée" class="section level3">
<h3><span class="header-section-number">3.7.2</span> Validation croisée</h3>
<p>Si la taille d’échantillon n’est pas suffisante pour diviser l’échantillon en deux et procéder comme nous venons de l’expliquer, la validation croisée est une bonne alternative. Cette méthode permet d’imiter le processus de division de l’échantillon.</p>
<p>Voici les étapes à suivre pour faire une validation croisée à <span class="math inline">\(K\)</span> groupes (<em><span class="math inline">\(K\)</span>-fold cross-validation</em>) :</p>
<ol style="list-style-type: decimal">
<li>Diviser l’échantillon au hasard en <span class="math inline">\(K\)</span> parties <span class="math inline">\(P_1, P_2, \ldots, P_K\)</span> de taille contenant toutes à peu près le même nombre d’observations.</li>
<li>Pour <span class="math inline">\(j = 1\)</span> à <span class="math inline">\(K\)</span>,
<ol style="list-style-type: lower-roman">
<li>Enlever la partie <span class="math inline">\(j\)</span>.</li>
<li>Estimer les paramètres du modèle en utilisant les observations des <span class="math inline">\(K-1\)</span> autres parties combinées.</li>
<li>Calculer la mesure de performance (par exemple la somme du carré des erreurs) de ce modèle pour le groupe <span class="math inline">\(P_j\)</span>.</li>
</ol></li>
<li>Faire la somme des <span class="math inline">\(K\)</span> estimations de performance pour obtenir une mesure de performance finale et repondérer au besoin.</li>
</ol>
<p>On recommande habituellement de prendre entre <span class="math inline">\(K=5\)</span> et <span class="math inline">\(10\)</span> groupes (le choix de 10 groupes est celui qui revient le plus souvent en pratique). Si on prend <span class="math inline">\(K=10\)</span> groupes, alors chaque modèle est estimé avec 90% des données et on prédit ensuite le 10% restant. Comme on passe en boucle les 10 parties, chaque observation est prédite une et une seule fois à la fin. Il est important de souligner que les groupes sont formés de façon aléatoire et donc que l’estimé que l’on obtient peut être très variable, surtout si la taille de l’échantillon d’apprentissage est petite. Il arrive également que le modèle ajusté sur un groupe ne puisse pas être utilisé pour prédire les observations mises de côté, notamment si des varibles catégorielles sont présentes. Un échantillonage stratifié permet de pallier à cette lacune, mais ce problème se présente en pratique quand certaines classes ont peu d’observations.</p>
<p>Le cas particulier <span class="math inline">\(K=n\)</span> (en anglais <em>leave-one-out cross validation</em>, ou <span class="math inline">\(\mathsf{LOOCV}\)</span>) consiste à enlever une seule observation, à estimer le modèle avec les <span class="math inline">\(n-1\)</span> autres et à valider à l’aide de l’observation laissée de côté et on recommence pour chaque observation. Pour les modèles linéaires, il existe des formules explicites qui nous permettent d’éviter d’ajuster <span class="math inline">\(n\)</span> régressions par moindre carrés.</p>
<p>Le fichier <code>selection3_cv.sas</code> contient une macro SAS permettant de faire une validation croisée pour un modèle de régression linéaire.
Revenons à notre exemple où une seule variable explicative est disponible et où l’on cherche à déterminer un bon modèle polynomial. Le Tableau <a href="sélection-de-variables-et-de-modèles-1.html#tab:02-table2">3.2</a> est le même que le Tableau <a href="sélection-de-variables-et-de-modèles-1.html#tab:02-table1">3.1</a> mais avec une colonne en plus, la dernière, <span class="math inline">\(\mathsf{VC} (K=10)\)</span>. Il s’agit des estimations du <span class="math inline">\(\mathsf{EMQ}\)</span> obtenues avec la validation croisée à 10 groupes. Notez que si vous exécutez le programme, vous n’obtiendrez pas les mêmes valeurs car il y a un élément aléatoire dans ce processus. La colonne représente la moyenne de 100 réplications.</p>
<table>
<caption><span id="tab:02-table2">Tableau 3.2: </span>Mesures d’adéquation du modèle linéaire et estimés de l’erreur, incluant la validation croisée.</caption>
<thead>
<tr class="header">
<th></th>
<th align="right"><span class="math inline">\(\mathsf{EMQ}\)</span></th>
<th align="right"><span class="math inline">\(\widehat{\mathsf{EMQ}}_a\)</span></th>
<th align="right"><span class="math inline">\(R^2\)</span></th>
<th align="right"><span class="math inline">\(R^2_a\)</span></th>
<th align="right"><span class="math inline">\(\mathsf{AIC}\)</span></th>
<th align="right"><span class="math inline">\(\mathsf{BIC}\)</span></th>
<th align="right"><span class="math inline">\(\mathsf{VC} (K=10)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td align="right">3191.29</td>
<td align="right">3674.20</td>
<td align="right">0.65</td>
<td align="right">0.65</td>
<td align="right">1110.70</td>
<td align="right">1118.51</td>
<td align="right">3675.37</td>
</tr>
<tr class="even">
<td>2</td>
<td align="right">3132.67</td>
<td align="right">2879.24</td>
<td align="right">0.73</td>
<td align="right">0.72</td>
<td align="right">1088.32</td>
<td align="right">1098.74</td>
<td align="right">2897.94</td>
</tr>
<tr class="odd">
<td>3</td>
<td align="right">2697.40</td>
<td align="right">2620.05</td>
<td align="right">0.75</td>
<td align="right">0.74</td>
<td align="right">1080.88</td>
<td align="right">1093.91</td>
<td align="right">2675.51</td>
</tr>
<tr class="even">
<td>4</td>
<td align="right">2766.68</td>
<td align="right">2581.70</td>
<td align="right">0.75</td>
<td align="right">0.74</td>
<td align="right">1081.41</td>
<td align="right">1097.04</td>
<td align="right">2666.16</td>
</tr>
<tr class="odd">
<td>5</td>
<td align="right">2771.05</td>
<td align="right">2580.86</td>
<td align="right">0.75</td>
<td align="right">0.74</td>
<td align="right">1083.38</td>
<td align="right">1101.61</td>
<td align="right">2711.11</td>
</tr>
<tr class="even">
<td>6</td>
<td align="right">2779.66</td>
<td align="right">2577.60</td>
<td align="right">0.75</td>
<td align="right">0.74</td>
<td align="right">1085.25</td>
<td align="right">1106.09</td>
<td align="right">2757.13</td>
</tr>
<tr class="odd">
<td>7</td>
<td align="right">2780.21</td>
<td align="right">2577.49</td>
<td align="right">0.75</td>
<td align="right">0.74</td>
<td align="right">1087.24</td>
<td align="right">1110.69</td>
<td align="right">2787.95</td>
</tr>
<tr class="even">
<td>8</td>
<td align="right">2797.35</td>
<td align="right">2531.00</td>
<td align="right">0.76</td>
<td align="right">0.74</td>
<td align="right">1087.42</td>
<td align="right">1113.48</td>
<td align="right">2845.78</td>
</tr>
<tr class="odd">
<td>9</td>
<td align="right">2811.07</td>
<td align="right">2527.85</td>
<td align="right">0.76</td>
<td align="right">0.73</td>
<td align="right">1089.30</td>
<td align="right">1117.96</td>
<td align="right">2895.61</td>
</tr>
<tr class="even">
<td>10</td>
<td align="right">2848.81</td>
<td align="right">2519.14</td>
<td align="right">0.76</td>
<td align="right">0.73</td>
<td align="right">1090.95</td>
<td align="right">1122.22</td>
<td align="right">2976.04</td>
</tr>
</tbody>
</table>
<p>Le modèle cubique (ordre 3) est aussi choisi par la validation croisée, en moyenne (comme il l’était par le <span class="math inline">\(\mathsf{AIC}\)</span> et le <span class="math inline">\(\mathsf{BIC}\)</span>). Le graphe qui suit trace les valeurs de l’estimation par validation croisée (courbe de validation croisée) et aussi le <span class="math inline">\(\mathsf{EMQ}\)</span>. On voit que l’estimation par validation croisée suit assez bien la forme du <span class="math inline">\(\mathsf{EMQ}\)</span> (qu’il est supposé estimer). Les boîtes à moustache permettent d’apprécier la variabilité des estimés de l’erreur moyenne quadratique telles qu’estimée par validation croisée avec 10 groupes.</p>
<p><img src="MATH60602_files/figure-html/plotcv-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="cibler-les-clients-pour-lenvoi-dun-catalogue" class="section level2">
<h2><span class="header-section-number">3.8</span> Cibler les clients pour l’envoi d’un catalogue</h2>
<p>Nous allons présenter un exemple classique de commercialisation de bases de données qui nous servira à illustrer la sélection de modèles, la régression logistique et la gestion de données manquantes.</p>
<p>Le contexte est le suivant : une entreprise possède une grande base de données client. Elle désire envoyer un catalogue à ses clients mais souhaite maximiser les revenus d’une telle initiative. Il est évidemment possible d’envoyer le catalogue à tous les clients mais ce n’est possiblement pas optimal. La stratégie envisagée est la suivante :</p>
<ol style="list-style-type: decimal">
<li>Envoyer le catalogue à un échantillon de clients et attendre les réponses. Le coût de l’envoi d’un catalogue est de 10$.</li>
<li>Construire un modèle avec cet échantillon afin de décider à quels clients (parmi les autres) le catalogue devrait être envoyé, afin de maximiser les revenus.</li>
</ol>
<p>Plus précisément, on s’intéresse aux clients de 18 ans et plus qui ont au moins un an d’historique avec l’entreprise et qui ont fait au moins un achat au cours de la dernière année. Il y a 101 000 clients dans la base de données. La première étape de la stratégie consiste à envoyer le catalogue à un échantillon de 1000 clients. Par la suite, un modèle sera construit avec ces 1000 clients afin de cibler lesquels des 100 000 clients restants seront choisis pour recevoir le catalogue. Les 1000 clients forment l’échantillon d’apprentissage. Pour les 1000 clients de l’échantillon d’apprentissage, les deux variables cibles suivantes sont disponibles :</p>
<ul>
<li><code>yachat</code>, une variable binaire qui indique si le client a acheté quelque chose dans le catalogue égale à 1 si oui et 0 sinon.</li>
<li><code>ymontant</code>, le montant de l’achat si le client a acheté quelque chose.</li>
</ul>
<p>Les 10 variables suivantes sont disponibles pour tous les clients et serviront de variables explicatives pour les deux variables cibles. Il s’agit de :</p>
<ul>
<li><code>x1</code>: sexe de l’individu, soit homme (0) ou femme (1);</li>
<li><code>x2</code>: l’âge (en année);</li>
<li><code>x3</code>: variable catégorielle indiquant le revenu, soit moins de 35 000$ (1), entre 35 000$ et 75 000$ (2) ou plus de 75 000$ (3);</li>
<li><code>x4</code>: variable catégorielle indiquant la région où habite le client (de 1 à 5);</li>
<li><code>x5</code>: conjoint : le client a-t-il un conjoint (0=non, 1=oui);</li>
<li><code>x6</code>: nombre d’année depuis que le client est avec la compagnie;</li>
<li><code>x7</code>: nombre de semaines depuis le dernier achat;</li>
<li><code>x8</code>: montant (en dollars) du dernier achat;</li>
<li><code>x9</code>: montant total (en dollars) dépensé depuis un an;</li>
<li><code>x10</code>: nombre d’achats différents depuis un an.</li>
</ul>
<p>Les données se trouvent dans le fichier <code>DBM.sas7bdat</code>. Lors d’une vraie application, nous aurions seulement les valeurs des variables cibles <code>yachat</code> et <code>ymontant</code> pour l’échantillon d’apprentissage (car eux seuls ont reçu le catalogue). Dans notre exemple, elles sont fournies pour tous les clients afin de pouvoir évaluer la performance des différentes stratégies testées. Les modèles seront déterminés (sélectionnés et ajustés) en utilisant seulement l’échantillon d’apprentissage (1000 clients). Les 100 000 autres clients serviront d’échantillon test pour évaluer la performance des modèles et, plus précisément, afin d’évaluer les revenus (ou d’autres mesures de performance) si ces modèles avaient été utilisés. L’échantillon test nous donnera donc l’heure juste quant aux mérites des différentes approches que nous allons comparer.</p>
<p>Voici d’abord des statistiques descriptives pour l’échantillon d’apprentissage.</p>
<p><img src="figures/02-select-e3.png" width="60%" style="display: block; margin: auto;" />
Il y a donc <span class="math inline">\(46,6\)</span>% de femmes parmi les 1000 clients de l’échantillon. De plus, <span class="math inline">\(39,7\)</span>% ont un revenu de moins de 35 000$, <span class="math inline">\(33,7\)</span>% sont entre 35 000$ et 75 000$ et <span class="math inline">\(26,6\)</span>% ont plus de 75 000$. <span class="math inline">\(42,5\)</span>% de ces clients qui ont un conjoint.
<img src="figures/02-select-e4.png" width="90%" style="display: block; margin: auto;" />
Le nombre d’achats différents depuis un an par ces clients varie entre 1 et 14. Un peu plus de la moitié (<span class="math inline">\(51,4\)</span>%) ont fait 5 achats ou moins. Parmi les 1000 clients de l’échantillon d’apprentissage, 210 ont acheté quelque chose dans le catalogue. La variable yachat sera l’une des variables que nous allons chercher à modéliser en vue d’obtenir des prédictions.
<img src="figures/02-select-e5.png" width="90%" style="display: block; margin: auto;" /></p>
<p>L’âge des 1000 clients de l’échantillon d’apprentissage varie entre 20 et 70 avec une moyenne de <span class="math inline">\(37,1\)</span> ans. En moyenne, ces clients ont acheté pour <span class="math inline">\(229,3\)</span>$ depuis un an. Le dernier achat de ces clients remonte, en moyenne, à 10 semaines. Nous chercherons également à modéliser la variable <code>ymontant</code>. Seuls 210 clients ont acheté quelque chose dans le catalogue et les statistiques rapportées correspondent seulement à ces derniers, car la variable <code>ymontant</code> est manquante si le client n’a rien acheté dans le catalogue. On pourrait également remplacer ces valeurs par des zéros et les modéliser, mais nous aborderons cet aspect ultérieurement. Les clients qui ont acheté quelque chose ont dépensé en moyenne <span class="math inline">\(67,3\)</span>$, et au minimum <span class="math inline">\(25\)</span>$. Les histogrammes de quelques unes de ces variables permet de mieux visualiser la répartition des observations.
<img src="figures/02-select-e6.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Il y a plusieurs façons d’utiliser l’échantillon d’apprentissage afin de mieux cibler les clients à qui envoyer le catalogue et maximiser les revenus. En voici quelques unes.</p>
<ol style="list-style-type: lower-alpha">
<li>On pourrait développer un modèle afin d’estimer la probabilité qu’un client achète quelque chose si on lui envoie un catalogue. Plus précisément, on peut développer un modèle pour <span class="math inline">\(\Pr(\texttt{yachat}=1)\)</span>. Comme la variable <code>yachat</code> est binaire, un modèle possible est la régression logistique, que nous décrirons au chapitre suivant. Ainsi, en appliquant le modèle aux 100 000 clients restant, on pourra cibler les clients susceptibles d’acheter (ceux avec une probabilité élevée).</li>
<li>Une autre façon serait de tenter de prévoir le montant d’argent dépensé. Nous venons de voir la distribution de la variable <code>ymontant</code>. Il y a deux situations, ceux qui ont acheté et ceux qui n’ont pas achetés. En conditionnant sur le fait d’avoir acheté quelque chose, il est possible de décomposer le problème de la manière suivante :</li>
</ol>
<p><span class="math display">\[\begin{align*} 
{\mathsf E}\left(\texttt{ymontant}\right) &amp;= {\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right) {\mathsf P}\left(\texttt{yachat}=1\right) \\&amp; \qquad \qquad \qquad +
{\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=0\right) {\mathsf P}\left(\texttt{yachat}=0\right) \\
 &amp;= {\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right) {\mathsf P}\left(\texttt{yachat}=1\right)
\end{align*}\]</span>
En mots, la moyenne du montant dépensé est égale à la moyenne du montant dépensé étant donné qu’il y a eu achat, fois la probabilité qu’il ait eu achat.</p>
<p>On peut donc estimer <span class="math inline">\({\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right)\)</span> et <span class="math inline">\({\mathsf P}\left(\texttt{yachat}=1\right)\)</span>, pour ensuite les combiner et avoir une estimation de <span class="math inline">\({\mathsf E}\left(\texttt{ymontant}\right)\)</span>. Le développement du modèle pour <span class="math inline">\({\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right)\)</span> peut se faire avec la régression linéaire, en utilisant seulement les clients qui ont acheté dans l’échantillon d’apprentissage, car ymontant est une variable continue dans ce cas. Le développement du modèle pour <span class="math inline">\({\mathsf P}\left(\texttt{yachat}=1\right)\)</span> peut se faire avec la régression logistique, tel que mentionné plus haut, en utilisant tous les 1000 clients de l’échantillon d’apprentissage. En fait, nous verrons plus loin qu’il est possible d’estimer conjointement les deux modèles avec un modèle Tobit. En appliquant le modèle aux 100 000 clients restants, on pourra cibler les clients qui risquent de dépenser un assez grand montant.</p>
<p>Comme nous n’avons pas encore vu la régression logistique, nous allons nous limiter à illustrer les méthodes qui restent à voir dans ce chapitre avec la régression linéaire en cherchant à développer un modèle pour <span class="math inline">\({\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right)\)</span>, le montant d’argent dépensé par les clients qui ont acheté quelque chose.</p>
<p>Le fichier <code>prepare_DBM.sas</code> contient des commandes afin de préparer les données aux analyses qui seront présentées dans les sections qui suivent. En particulier, nous avons deux variables explicatives catégorielles. Il s’agit de revenu (<code>x3</code>) et région (<code>x4</code>). Il faut coder d’une manière appropriée afin de pouvoir les incorporer dans les modèles. La manière habituelle est de créer des variables indicatrices (binaires) qui indiquent si la variable prend ou non une valeur particulière. En général, si une variable catégorielle possède <span class="math inline">\(K\)</span> valeurs possibles, il est suffisant de créer <span class="math inline">\(K-1\)</span> indicatrices, en laissant une modalité comme référence. Par exemple, pour <code>X3</code>, nous allons créer deux variables,</p>
<ul>
<li><code>x31</code>: variable binaire égale à 1 si <code>x3</code> égale 1 et 0 sinon,</li>
<li><code>x32</code>: variable binaire égale à 1 si <code>x3</code> égale 2 et 0 sinon.</li>
</ul>
<p>Ainsi, la valeur 3 est celle de référence. Ces deux indicatrices sont suffisantes pour récupérer toute l’information comme le démontre le tableau @(tab:02-dummy).</p>
<table>
<caption><span id="tab:02-dummy">Tableau 3.3: </span> Valeur des indicateurs en fonction du niveau de la variable catégorique</caption>
<thead>
<tr class="header">
<th align="center"><code>x3</code></th>
<th align="center"><code>x31</code></th>
<th align="center"><code>x32</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<p>En pratique, il suffit d’incorporer les indicatrices (<code>x31</code> et <code>x32</code>) dans le modèle comme variables explicatives et de ne plus utiliser la variable originale <code>x3</code>. On peut aussi procéder ainsi pour la variable <code>x4</code>, en créant quatre indicatrices.</p>
</div>
<div id="recherche-automatique-du-meilleur-modèle" class="section level2">
<h2><span class="header-section-number">3.9</span> Recherche automatique du meilleur modèle</h2>
<p>Lorsque nous voulons comparer un petit nombre de modèles, il est relativement aisé d’obtenir les critères (<span class="math inline">\(\mathsf{AIC}\)</span>, <span class="math inline">\(\mathsf{BIC}\)</span> ou autre) pour tous les modèles et de choisir le meilleur. C’était le cas dans l’exemple du choix de l’ordre du polynôme où il y avait seulement 10 modèles en compétitions.
Mais lorsqu’il y a plusieurs variables en jeu, le nombre de modèles potentiel augmente très rapidement.</p>
<p>En fait, supposons qu’on a <span class="math inline">\(p\)</span> variables distinctes disponibles. Avant même de considérer les transformations des variables et les interactions entre elles, il y a déjà modèles possibles. En effet, chaque variable est soit incluse ou pas (deux possibilités) et donc il y a <span class="math inline">\(2^p=2\times 2 \times \cdots \times 2\)</span> (<span class="math inline">\(p\)</span> fois) modèles en tout à considérer. Ce nombre augmente très rapidement comme en témoigne le tableau <a href="sélection-de-variables-et-de-modèles-1.html#tab:02-table3">3.4</a>.</p>
<table>
<caption><span id="tab:02-table3">Tableau 3.4: </span>Nombres de modèles en fonction du nombre de paramètres <span class="math inline">\(p\)</span>.</caption>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(p\)</span></th>
<th align="right">nombre de paramètres</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">5</td>
<td align="right">32</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">1024</td>
</tr>
<tr class="odd">
<td align="right">15</td>
<td align="right">32768</td>
</tr>
<tr class="even">
<td align="right">20</td>
<td align="right">1048576</td>
</tr>
<tr class="odd">
<td align="right">25</td>
<td align="right">33554432</td>
</tr>
<tr class="even">
<td align="right">30</td>
<td align="right">1073741824</td>
</tr>
</tbody>
</table>
<p>Ainsi, si le nombre de variables est restreint, il est possible de comparer tous les modèles potentiels et de choisir le meilleur (selon un critère). II existe même des algorithmes très efficaces qui permettent de trouver le meilleur modèle sans devoir examiner tous les modèles possibles. Le nombre de variables qu’il est possible d’avoir dépend de la puissance de calcul et augmente d’année en année. Par contre, dans plusieurs applications, il ne sera pas possible de comparer tous les modèles et il faudra effectuer une recherche limitée.</p>
<p>Faire une recherche exhaustive parmi tous les modèles possibles s’appelle sélection de tous les sous-ensembles (<em>best subsets</em>). La procédure <code>reg</code> de <strong>SAS</strong> permet de faire cela pour la régression linéaire.</p>
</div>
<div id="recherche-automatique-de-tous-les-sous-ensembles" class="section level2">
<h2><span class="header-section-number">3.10</span> Recherche automatique de tous les sous-ensembles</h2>
<p>On veut trouver un bon modèle pour prévoir la valeur de <code>ymontant</code> des clients qui ont acheté quelque chose. On a vu qu’il y a 210 clients qui ont acheté dans l’échantillon d’apprentissage. Nous allons chercher à développer un « bon » modèle avec ces 210 clients. Dans ce premier exemple, nous allons seulement utiliser les 10 variables explicatives de base (14 variables avec les indicatrices). Le code suivant montre comment faire une sélection de variables selon le critère du <span class="math inline">\(R^2\)</span> et demande à <strong>SAS</strong> de présenter le modèle à <span class="math inline">\(k\)</span> variables (<span class="math inline">\(k=1, \ldots, 14\)</span>) qui a le plus grand <span class="math inline">\(R^2\)</span>; voir <code>selection2_all_subset.sas</code> pour plus de détails.</p>
<pre class="sas"><code>proc reg data=trainymontant;
model ymontant=x1 x2 x31 x32 x41 x42 x43 x44 x5 x6 
  x7 x8 x9 x10 / selection=rsquare best=1 aic bic;
run;</code></pre>
<p>Ainsi, le modèle linéaire simple qui a le plus grand <span class="math inline">\(R^2\)</span> est celui qui inclut le conjoint (<code>x5</code>). Le meilleur modèle (selon le <span class="math inline">\(R^2\)</span>) parmi tous les modèles avec deux variables est celui avec <code>x5</code> et <code>x6</code>.</p>
<p>Pour un nombre de variables fixé, le meilleur modèle selon le <span class="math inline">\(R^2\)</span> est aussi le meilleur selon les critères d’information <span class="math inline">\(\mathsf{AIC}\)</span> et <span class="math inline">\(\mathsf{BIC}\)</span>, pour ce nombre fixé de variables. Pour vous convaincre de cette affirmation, fixons le nombre de variables et restreignons-nous seulement aux modèles avec ce nombre de variables. Comme = <span class="math inline">\(1 - \mathsf{SCE}/\mathsf{SCT}\)</span> et que <span class="math inline">\(\mathsf{SCT}\)</span> est une constante indépendante du modèle, le modèle avec le plus grand coefficient de détermination, <span class="math inline">\(R^2\)</span>, est aussi celui avec la plus petite somme du carré des erreurs (<span class="math inline">\(\mathsf{SCE}\)</span>). Comme <span class="math inline">\(\mathsf{AIC}=n (\ln (\mathsf{SCE}/n)) + 2p\)</span>, ce sera aussi celui avec le plus petit <span class="math inline">\(\mathsf{AIC}\)</span> car la pénalité <span class="math inline">\(2p\)</span> est la même si on fixe le nombre de variables; la même remarque est valide pour le <span class="math inline">\(\mathsf{BIC}\)</span>.</p>
<p>Ainsi, pour trouver le meilleur modèle globalement (sans fixer le nombre de variables), il suffit de trouver le modèle à <span class="math inline">\(k\)</span> variables explicatives ayant le coefficient de détermination le plus élevé pour tous les nombres de variables fixés et d’ensuite de trouver celui qui minimise le <span class="math inline">\(\mathsf{AIC}\)</span> (ou le <span class="math inline">\(\mathsf{BIC}\)</span>) parmi ces modèles. Cette astuce est utile dans la mesure où <strong>SAS</strong> ne permet pas de faire cette même recherche avec les critères d’information.</p>
<p><img src="figures/02-select-e7.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Dans l’exemple, on voit que le modèle avec les variables <code>x1</code> <code>x2</code> <code>x31</code> <code>x44</code> <code>x5</code> <code>x6</code> <code>x7</code> <code>x8</code> <code>x9</code> et <code>x10</code> est celui qui minimise le <span class="math inline">\(\mathsf{AIC}\)</span> globalement (<span class="math inline">\(\mathsf{AIC}=660.15\)</span>). Le modèle choisi par le <span class="math inline">\(\mathsf{BIC}\)</span> contient seulement sept variables explicatives (plutôt que 10), soit <code>x1</code> <code>x31</code> <code>x5</code> <code>x6</code> <code>x7</code> <code>x8</code> <code>x10</code>.</p>
<p>Nous allons utiliser les 100 000 autres clients pour évaluer la performance réelle des modèles qui nous sont suggérés par nos différents critères. En pratique, nous ne pourrions pas faire cela car la valeur de la variable cible ne serait pas connue pour ces clients. En fait, dans une vraie application, nous utiliserions plutôt les modèles pour obtenir des prédictions pour les clients à « scorer ». Les valeurs des variables cibles pour les 100 000 clients nous permettront de voir à quel point différentes stratégies auraient été profitables si elles avaient été mises en place. Parmi, les 100 000 clients restants, il y en a 23 179 qui auraient acheté quelque chose si on leur avait envoyé le catalogue. Ces 23 179 observations vont nous servir pour estimer l’erreur moyenne quadratique (théorique) des modèles retenus par nos critères (voir le fichier <code>selection2_all_subset.sas</code> pour les manipulations).</p>
<p>Voici l’estimation de l’erreur moyenne quadratique (moyenne des carrés des erreurs) pour les deux modèles retenus par le <span class="math inline">\(\mathsf{AIC}\)</span> et le <span class="math inline">\(\mathsf{BIC}\)</span>. Le tableau <a href="sélection-de-variables-et-de-modèles-1.html#tab:02-gmse-base">3.5</a> contient aussi l’estimation de l’erreur moyenne quadratique si on utilise toutes les variables (14 en incluant les indicatrices) sans faire de sélection.</p>
<table>
<caption><span id="tab:02-gmse-base">Tableau 3.5: </span> Estimation de l’erreur moyenne quadratique sur l’échantillon test avec les variables de base. Les meilleurs modèles selon les critères d’informations découlent d’une recherche exhaustive de tous les sous-ensembles.</caption>
<thead>
<tr class="header">
<th align="center">nombre de variables</th>
<th align="center"><span class="math inline">\(\mathsf{EMQ}\)</span></th>
<th align="left">méthode</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">14</td>
<td align="center">25,69</td>
<td align="left">toutes les variables</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">24,72</td>
<td align="left">exhaustive - <span class="math inline">\(\mathsf{AIC}\)</span></td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">23,83</td>
<td align="left">exhaustive - <span class="math inline">\(\mathsf{BIC}\)</span></td>
</tr>
</tbody>
</table>
<p>On voit que le modèle choisi par le <span class="math inline">\(\mathsf{BIC}\)</span> est le meilleur des trois, car l’erreur moyenne quadratique sur l’échantillon test est de <span class="math inline">\(3,6\)</span>% inférieure à celle du modèle choisi par le <span class="math inline">\(\mathsf{AIC}\)</span>. Ces deux méthodes font mieux que le modèle qui inclut toutes les variables sans faire de sélection.</p>
<p>Nous avons seulement inclus les variables de base pour ce premier essai. Il est possible qu’ajouter des variables supplémentaires améliore la performance du modèle. Pour cet exemple, nous allons considérer les variables suivantes:</p>
<ul>
<li>les variables continues au carré, comme <span class="math inline">\(\texttt{age}^2\)</span>.</li>
<li>toutes les interactions d’ordre deux entre les variables de base, comme <span class="math inline">\(\texttt{sexe}\cdot\texttt{age}\)</span>.</li>
</ul>
<p>Toutes ces variables sont créées dans <code>prepare_DBM.sas</code>. Aux variables de base (10 variables explicatives, mais 14 avec les indicatrices pour les variables catégorielles), s’ajoutent ainsi 90 autres variables. Il y a donc 104 variables explicatives potentielles. Notez qu’il y a des interactions entre chacune des variables indicatrices et chacune des autres variables, mais il ne sert à rien de calculer une interaction entre deux indicatrices d’une même variable (car une telle variable est zéro pour tous les individus). De même, il ne sert à rien de calculer le carré d’une variable binaire.</p>
<p>Lancer une sélection exhaustive de tous les sous-modèles avec 104 variables risque de prendre un temps énorme. Que faire alors? Il y a plusieurs possibilités. Nous pourrions faire une recherche limitée avec les méthodes que nous allons voir à partir de la section suivante. Nous pourrions aussi combiner les deux approches. Supposons que notre ordinateur permet de faire une recherche exhaustive de tous les sous-modèles avec 40 variables. Nous pourrions alors commencer avec une recherche limitée pour trouver un sous-ensemble de 40 « bonnes » variables et faire une recherche exhaustive, mais en se restraignant à ces 40 variables.</p>
</div>
<div id="méthodes-classiques-de-sélection-ascendante-descendante-et-séquentielle" class="section level2">
<h2><span class="header-section-number">3.11</span> Méthodes classiques de sélection ascendante, descendante et séquentielle</h2>
<p>Les méthodes de sélection ascendante, descendante et séquentielle sont des algorithmes gloutons qui permettent de choisir des variables. Elles ont été développées à une époque où la puissance de calcul était bien moindre, et où il était impossible de faire une recherche exhaustive des sous-modèles. Avec l’approche classique, ces méthodes font une recherche séquentielle guidée parmi un nombre limité de modèles, à l’aide des valeurs-<em>p</em> du test-<em>t</em> pour la significativité des paramètres individuels du modèle avec <span class="math inline">\(p\)</span> prédicteurs potentiels <span class="math inline">\(X_1,\ldots, X_p\)</span>. Les procédures <code>glmselect</code> et <code>reg</code> permettent une sélection de modèle avec une approche séquentielle, ascendante ou descendante.</p>
<div id="sélection-ascendante" class="section level3">
<h3><span class="header-section-number">3.11.1</span> Sélection ascendante</h3>
<p>L’idée de la sélection ascendante est de tester l’ajout de chaque variable individuellement et d’ajouter celle qui est la plus significative selon le test-<em>t</em> si elle a une valeur-<em>p</em> assez petite.</p>
<ul>
<li><em>Initialisation</em>: le modèle linéaire de départ est celui qui n’inclut que l’ordonnée à l’origine, <span class="math inline">\(Y=\beta_0+\varepsilon\)</span>, où <span class="math inline">\(\varepsilon\)</span> est une erreur centrée.</li>
<li><em>Critère d’entrée</em>: <span class="math inline">\(c\)</span>, valeur-<em>p</em> minimale à partir de laquelle une variable peut être incluse dans le modèle (<code>proc reg</code> utilise par défaut 0.5).</li>
<li><em>Boucle</em> soit <span class="math inline">\(X_{(1)}, \ldots, X_{(k)}\)</span>, les variables explicatives à l’étape <span class="math inline">\(k&lt;p\)</span>.
<ul>
<li>pour chaque <span class="math inline">\(j\)</span> (<span class="math inline">\(j=\{1,\ldots, p\}\setminus \{(1), \ldots (k)\}\)</span>), on ajuste tour à tour le modèle <span class="math inline">\(Y=\beta_0+\sum_{i=1}^k \beta_i X_{(i)} + \beta_{k+1}X_{j}\)</span> et on calcule la valeur-<em>p</em> du test-<em>t</em> pour les hypothèses <span class="math inline">\(\mathcal{H}_0: \beta_{k+1}=0\)</span> contre l’alternative bilatérale <span class="math inline">\(\mathcal{H}_1: \beta_{k+1} \neq 0\)</span>.</li>
<li>Soit <span class="math inline">\(p_{\min}\)</span> la plus petite des <span class="math inline">\(p-k\)</span> valeurs-<em>p</em> qui correspond à <span class="math inline">\(X_{(k+1)}\)</span>, disons.
<ul>
<li>si <span class="math inline">\(p_{\min}&lt;c\)</span>, continuer la procédure.</li>
<li>si <span class="math inline">\(p_{\min} \geq c\)</span>, retourner le modèle <span class="math inline">\(Y=\beta_0 + \sum_{i=1}^k \beta_iX_{(i)}+\varepsilon\)</span>.</li>
</ul></li>
</ul></li>
</ul>
<p>On continue ainsi à ajouter des variables jusqu’à ce que le critère d’entrée ne soit pas satisfait. Si on se rend jusqu’au bout, on va terminer avec le modèle complet qui contient toutes les variables.</p>
</div>
<div id="sélection-descendante" class="section level3">
<h3><span class="header-section-number">3.11.2</span> Sélection descendante</h3>
<ul>
<li><em>Initialisation</em>: le modèle linéaire de départ est celui qui inclut toutes les variables explicatives, <span class="math inline">\(Y=\beta_0+\sum_{j=1}^p \beta_j X_{(j)}+\varepsilon\)</span>, où <span class="math inline">\(\varepsilon\)</span> est une erreur centrée.</li>
<li><em>Critère de sortie</em>: <span class="math inline">\(c\)</span>, valeur-<em>p</em> maximale à partir de laquelle une variable peut être excluse du modèle (<code>proc reg</code> utilise par défaut 0.1).</li>
<li><em>Boucle</em> soit <span class="math inline">\(X_{(1)}, \ldots, X_{(p-k)}\)</span>, les variables explicatives présentes dans le modèle à l’étape <span class="math inline">\(k&lt;p\)</span>.
<ul>
<li>pour chaque <span class="math inline">\(j\)</span> (<span class="math inline">\(j =1, \ldots, p-k\)</span>), on calcule la valeur-<em>p</em> du test-<em>t</em> <span class="math inline">\(\mathcal{H}_0: \beta_{j}=0\)</span> contre l’alternative bilatérale <span class="math inline">\(\mathcal{H}_1: \beta_{j} \neq 0\)</span>.</li>
<li>si toutes ces valeurs sont inférieures à <span class="math inline">\(c\)</span>, on retourne le modèle <span class="math inline">\(Y=\beta_0 + \sum_{j=1}^{p-k} \beta_j X_{(j)}\)</span>.</li>
<li>sinon, on enlève la variable qui a la plus grande valeur-<em>p</em> (disons <span class="math inline">\(X_{(p-k)}\)</span>), on réajuste le modèle sans cette variable et on recommence la procédure.</li>
</ul></li>
</ul>
<p>L’idée est l’inverse de la méthode ascendante. On va tester le retrait de chaque variable individuellement et retirer celle qui est la moins significative, si sa valeur-<em>p</em> est assez grande. Si la procédure se termine après <span class="math inline">\(p\)</span> itérations, aucune variable explicative n’est retenue.</p>
</div>
<div id="méthode-séquentielle" class="section level3">
<h3><span class="header-section-number">3.11.3</span> Méthode séquentielle</h3>
<p>Il s’agit d’une méthode hybride entre ascendante et descendante. On sélectionne un critère d’entrée et de sortie pour chacune des deux (0.15 dans <code>proc reg</code>) et on début la recherche à partir du modèle ne contenant que l’ordonnée à l’origine. À chaque étape, on fait une étape ascendante suivie de une (ou plusieurs) étapes descendantes. On continue ainsi tant que le modèle retourné par l’algorithme n’est pas identique à celui de l’étape précédente. Le dernier modèle est celui retenu.</p>
<p>Avec la méthode séquentielle, une fois qu’on entre une variable (étape ascendante), on fait autant d’étapes descendante afin de retirer toutes les variables qui satisfont le critère de sortie (il peut ne pas y en avoir). Une fois cela effectué, on refait une étape ascendante pour voir si on peut ajouter une nouvelle variable.</p>
<p>Remarques sur ces méthodes: avec la méthode ascendante, une fois qu’une variable est dans le modèle, elle y reste. Avec la méthode descendante, une fois qu’une variable est sortie du modèle, elle ne peut plus y entrer. Avec la méthode séquentielle, une variable peut entrer dans le modèle et sortir plus tard dans le processus. Par conséquent, parmi les trois, la méthode séquentielle est généralement préférable aux méthodes ascendante et descendante, car elle inspecte potentiellement un plus grand nombre de modèles.</p>
<p>On peut soi-même spécifier les critères d’entrée et de sortie. Plus le critère d’entrée est élevé, plus il y aura de variables dans le modèle final. De même, plus le critère de sortie est élevé, plus il y aura de variables dans le modèle.</p>
<p>Utilisons la méthode de sélection séquentielle classique avec des critères d’entrée et de sortie de 0.15 et les 104 variables. Le code suivant, extrait de <code>selection2_all_subset.sas</code>, donne la syntaxe <strong>SAS</strong>.</p>
<pre class="sas"><code>proc reg data=trainymontant;
model ymontant=
x1 x2 x31 x32 x41 x42 x43 x44 x5 x6 x7 x8 x9 x10
cx2 cx6 cx7 cx8 cx9 cx10
i_x2_x1 i_x2_x5 i_x2_x31 i_x2_x32 i_x2_x41 i_x2_x42 i_x2_x43 i_x2_x44
i_x2_x7 i_x2_x6 i_x2_x8 i_x2_x9 i_x2_x10
i_x1_x5 i_x1_x31 i_x1_x32 i_x1_x41 i_x1_x42 i_x1_x43 i_x1_x44
i_x1_x7 i_x1_x6 i_x1_x8 i_x1_x9 i_x1_x10
i_x5_x31 i_x5_x32 i_x5_x41 i_x5_x42 i_x5_x43 i_x5_x44
i_x5_x7 i_x5_x6 i_x5_x8 i_x5_x9 i_x5_x10
i_x31_x41 i_x31_x42 i_x31_x43 i_x31_x44
i_x31_x7 i_x31_x6 i_x31_x8 i_x31_x9 i_x31_x10
i_x32_x41 i_x32_x42 i_x32_x43 i_x32_x44
i_x32_x7 i_x32_x6 i_x32_x8 i_x32_x9 i_x32_x10
i_x41_x7 i_x41_x6 i_x41_x8 i_x41_x9 i_x41_x10
i_x42_x7 i_x42_x6 i_x42_x8 i_x42_x9 i_x42_x10
i_x43_x7 i_x43_x6 i_x43_x8 i_x43_x9 i_x43_x10
i_x44_x7 i_x44_x6 i_x44_x8 i_x44_x9 i_x44_x10
i_x7_x6 i_x7_x8 i_x7_x9 i_x7_x10
i_x6_x8 i_x6_x9 i_x6_x10
i_x8_x9 i_x8_x10
i_x9_x10 / selection=stepwise sle=.15 sls=.15 ;
run;</code></pre>
<p>Notez que les variables <code>cx2</code> à <code>cx10</code> sont les carrés des variables <code>x2</code> à <code>x10</code> que nous avons créées au préalable. De plus, les variables débutant par <em>i</em> sont les interactions entre les variables binaires et les variables continues. Par exemple, <code>i_x2_x1</code> est l’interaction entre <code>x1</code> et <code>x2</code>, c’est-à-dire le produit des deux.</p>
<p>La sortie <strong>SAS</strong> est assez volumineuse car elle retrace toutes étapes de la sélection séquentielle. L’historique montre qu’à l’étape 1, la variable <code>i_x5_x6</code> a été ajoutée, suivie de <code>i_x31_x10</code> à l’étape 2. Un peu plus loin, à l’étape 6, <code>i_x5_x6</code> est retirée et ainsi de suite. Il y a eu 40 étapes en tout et, à la fin, il reste 22 variables (parmi les 104) dans le modèle final. Le <span class="math inline">\(R^2\)</span> du modèle final est <span class="math inline">\(0,966\)</span>.</p>
<p><img src="figures/02-select-e8.png" width="90%" style="display: block; margin: auto;" />
<img src="figures/02-select-e9.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Voici les estimés des paramètres du modèle final retenu. On voit bien que toutes les valeurs-<em>p</em> (qui ne sont pas valides à cause de la sélection de modèles) sont toutes inférieures à <span class="math inline">\(0,15\)</span>.</p>
<p><img src="figures/02-select-e10.png" width="70%" style="display: block; margin: auto;" /><img src="figures/02-select-e11.png" width="70%" style="display: block; margin: auto;" /></p>
<p>La performance de ce modèle a, comme pour les modèles précédents, été évaluée avec l’échantillon test de 23 179 observations. Le tableau <a href="sélection-de-variables-et-de-modèles-1.html#tab:02-comparaisonseqclas">3.6</a> présente la performance de la méthode de sélection séquentielle classique et celle du modèle dans lequel les 104 variables sont incluses sans faire de sélection.</p>
<table>
<caption><span id="tab:02-comparaisonseqclas">Tableau 3.6: </span> Comparaison des méthodes selon l’erreur moyenne quadratique pour la méthode de sélection séquentielle classique et pour le modèle incluant toutes les variables, les termes quadratiques et les interactions.</caption>
<thead>
<tr class="header">
<th align="center">nombre de variables</th>
<th align="center"><span class="math inline">\(\mathsf{EMQ}\)</span></th>
<th align="left">méthode</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">104</td>
<td align="center">19,63</td>
<td align="left">toutes les variables</td>
</tr>
<tr class="even">
<td align="center">22</td>
<td align="center">12,25</td>
<td align="left">séquentielle classique</td>
</tr>
</tbody>
</table>
<p>On voit donc qu’utiliser toutes les 104 variables sans faire de sélection fait mieux (<span class="math inline">\(\mathsf{EMQ}=19,63\)</span>) que les modèles précédents basés sur les 10 variables originales. Mais faire une sélection séquentielle classique permet une amélioration très importante de la performance (<span class="math inline">\(\mathsf{EMQ}=12,25\)</span>). On voit que dans cet exemple, utiliser les 104 variables fait du surajustement (<em>over-fitting</em>).</p>
<p>Le choix de <span class="math inline">\(0,15\)</span> comme critère d’entrée et de sortie est assez arbitraire. Il est fort possible que d’autres valeurs donnent de meilleurs résultats. Mais il n’est pas évident de les choisir.</p>
<p>Une façon de contourner le problème de devoir spécifier les critères d’entrée et de sortie est de procéder en deux étapes. Supposons que notre ordinateur permet de faire une recherche exhaustive de tous les sous-modèles avec près de 60 variables. L’idée est alors de passer de 104 à un sous-ensemble d’environ 60 variables, avec une sélection séquentielle gloutonne, et d’ensuite utiliser une recherche exhaustive avec ce sous-ensemble de variables. Plus précisément:</p>
<ol style="list-style-type: decimal">
<li>On fait une sélection séquentielle classique avec des valeurs élevées pour les critères d’entrée et de sortie afin que le modèle retenu contienne le nombre voulu de variables (par exemple, 60).</li>
<li>En utilisant seulement ce sous-ensemble de variables, on choisit le meilleur modèle selon le <span class="math inline">\(\mathsf{AIC}\)</span> ou le <span class="math inline">\(\mathsf{BIC}\)</span> en faisant une recherche exhaustive de tous les sous-modèles.</li>
</ol>
<p>En fixant, les critères d’entrée et de sortie à <span class="math inline">\(0,6\)</span> pour la recherche séquentielle, le modèle retenu aura 56 variables. Il est possible de faire une recherche exhaustive avec 56 variables sur un ordinateur portable avec <strong>SAS</strong>. Le <span class="math inline">\(\mathsf{AIC}\)</span> est mène à un modèle avec 38 de ces 56 variables. Le <span class="math inline">\(\mathsf{BIC}\)</span> est quant à lui beaucoup plus parcimonieux et choisit 15 de ces variables pour le modèle final. Encore une fois, ces deux modèles sont testés sur les 23 179 clients restants. Les résultats sont présentés dans le tableau <a href="sélection-de-variables-et-de-modèles-1.html#tab:02-comparaisonseqexha">3.7</a>.</p>
<table style="width:100%;">
<caption><span id="tab:02-comparaisonseqexha">Tableau 3.7: </span> Comparaison des méthodes selon l’erreur moyenne quadratique pour la méthode de sélection séquentielle suivie d’une recherche exhaustive.</caption>
<colgroup>
<col width="31%" />
<col width="36%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">nombre de variables</th>
<th align="center"><span class="math inline">\(\mathsf{EMQ}\)</span></th>
<th align="left">méthode</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">38</td>
<td align="center">14,83</td>
<td align="left">séquentielle classique, recherche exhaustive avec 56 variables <span class="math inline">\((\mathsf{AIC})\)</span></td>
</tr>
<tr class="even">
<td align="center">15</td>
<td align="center">11,96</td>
<td align="left">séquentielle classique, recherche exhaustive avec 56 variables <span class="math inline">\((\mathsf{BIC})\)</span></td>
</tr>
</tbody>
</table>
<p>La stratégie consistant à sélectionner un sous-ensemble de 56 variables avec la méthode séquentielle classique pour ensuite faire une recherche exhaustive de tous les sous-modèles possibles avec ces 56 variables, selon le <span class="math inline">\(\mathsf{BIC}\)</span>, donne le meilleur résultat jusqu’à présent (<span class="math inline">\(\mathsf{EMQ}=11,96\)</span>). Le <span class="math inline">\(\mathsf{AIC}\)</span> fait moins bien dans ce cas, avec une erreur moyenne quadratique estimée de <span class="math inline">\(14,83\)</span>. Nous verrons à la section suivante qu’il est possible de faire une recherche séquentielle en utilisant d’autres critères que la valeur-<em>p</em> du test-<em>t</em> pour faire ajouter ou enlever des variables.</p>
</div>
</div>
<div id="recherche-séquentielle-automatique-limitée" class="section level2">
<h2><span class="header-section-number">3.12</span> Recherche séquentielle automatique limitée</h2>
<p>L’idée de la procédure séquentielle classique est d’inclure ou d’exclure une variable à la fois sur la base des valeurs-<em>p</em>. La procédure <code>glmselect</code> permet de faire une sélection séquentielle en utilisant d’autres critères, comme le <span class="math inline">\(\mathsf{AIC}\)</span> ou le <span class="math inline">\(\mathsf{BIC}\)</span>. Cette procédure permet de contrôler très finement le processus de sélection de variables. Le code qui suit fait une recherche séquentielle avec les particularités suivantes. À chaque étape ascendante de la procédure séquentielle, c’est la variable qui améliore le plus le <span class="math inline">\(\mathsf{AIC}\)</span> (<code>select=aic</code>) qui est entrée. De plus, à chaque étape descendante de la procédure séquenctielle, c’est la (ou les) variable(s) qui détériore(nt) le plus le <span class="math inline">\(\mathsf{AIC}\)</span> qui est (sont) retirée(s). À la toute fin du processus, c’est le modèle qui a le meilleur <span class="math inline">\(\mathsf{BIC}\)</span> (<code>choose=BIC</code>) qui est retenu.</p>
<pre class="sas"><code>proc glmselect data=trainymontant;
model ymontant= /*(mettre les 104 variables ici) */
/  selection=stepwise(select=aic choose=bic)  ; 
score data=testymontant out=predglmselectaicbic p=predymontant;
run;</code></pre>
<p>Voici l’historique de la procédure séquentielle avec cette combinaison.</p>
<p><img src="figures/02-select-e12.png" width="70%" style="display: block; margin: auto;" /><img src="figures/02-select-e13.png" width="70%" style="display: block; margin: auto;" /></p>
<p>À l’étape 1, la variable <code>i_x5_x6</code> est ajoutée au modèle de base car c’est celle qui fait diminuer le plus le <span class="math inline">\(\mathsf{AIC}\)</span>. À l’étape 2, la variable <code>i_x31_x10</code> est ajoutée, À l’étape 6, la variable <code>i_x5_x6</code> est retirée car cela fait baisser le <span class="math inline">\(\mathsf{AIC}\)</span>. Notez que le <span class="math inline">\(\mathsf{AIC}\)</span> décroit toujours d’une étape à l’autre. <strong>SAS</strong> garde aussi la trace du <span class="math inline">\(\mathsf{BIC}\)</span> car le modèle final sera choisi selon ce critère. Finalement le processus séquentiel se termine à l’étape 40, car il n’y a plus moyen de faire dimiuer le <span class="math inline">\(\mathsf{AIC}\)</span>. Le modèle final retenu est celui de l’étape 18, car c’est celui qui a le <span class="math inline">\(\mathsf{BIC}\)</span> le plus petit parmi tous ces modèles (<span class="math inline">\(\mathsf{BIC}=484.22\)</span>).</p>
<p>Voici différentes statistiques ainsi que les estimations des paramètres de ce modèle qui contient 10 variables.</p>
<p><img src="figures/02-select-e14.png" width="65%" style="display: block; margin: auto;" />
<img src="figures/02-select-e15.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Il s’avère que ce modèle performe très bien avec une erreur moyenne quadratique estimé à <span class="math inline">\(10,08\)</span> sur les 23 179 clients de l’échantillon test. Il s’agit du meilleur jusqu’à maintenant.</p>
</div>
<div id="moyenne-de-modèles" class="section level2">
<h2><span class="header-section-number">3.13</span> Moyenne de modèles</h2>
<p>Une idée importante et moderne en statistique est qu’il est souvent préférable de combiner plusieurs modèles plutôt que d’en choisir un seul. La technique des forêts aléatoires (<em>random forests</em>) est une des meilleures techniques de prédiction disponibles de nos jours. Elle est basée sur cette idée, en combinant plusieurs arbres de classification (ou de régression) individuels. C’est une des techniques de base en exploitation de données.</p>
<p>Ici, nous allons voir comment cette idée peut être appliquée à notre contexte. Toutes les méthodes que nous avons vues jusqu’à maintenant font une sélection « rigide » de variables, dans le sens que chaque variable est soit sélectionnée pour faire partie du modèle, soit elle ne l’est pas. C’est donc tout ou rien pour chaque variable. Il y a beaucoup de variabilité associée à une telle forme de sélection. Une variable peut avoir été très près d’être choisie, mais elle ne l’a pas été et est éliminée complètement. Construire plusieurs modèles et en faire la moyenne permet d’adoucir le processus de sélection car une variable peut alors être partiellement sélectionnée.</p>
<p>Supposons qu’on dispose de deux échantillons et qu’on fasse une sélection de variables séparément pour les deux échantillons, avec l’une des approches que nous avons vues jusqu’à maintenant. Il est alors très probable qu’on ne va pas avoir exactement les mêmes variables sélectionnées pour les deux échantillons. Supposons ensuite qu’on fasse la moyenne des coefficients pour les deux modèles. Si une variable, disons <span class="math inline">\(X_1\)</span>, a été choisie les deux fois, alors la moyenne des deux coefficients devrait estimer en quelque sorte un effet global pour cette variable. Si une autre variable, disons <span class="math inline">\(X_2\)</span>, n’a pas été choisie du tout pour les deux échantillons, alors la moyenne de ses deux coefficients est nulle. Mais si une variable, disons, <span class="math inline">\(X_3\)</span>, a été choisie pour seulement l’un des deux échantillons, alors la moyenne de ses deux coefficients est la moitié du coefficient pour le modèle dans lequel elle a été choisie (car l’autre est zéro). Ainsi, cette variable est donc représentée par une « moitié » d’effet dans la moyenne des modèles. Donc au lieu d’être totalement là ou totalement absente, elle est présente en fonction de sa probabilité d’être sélectionnée. Ceci diminue de beaucoup la variabilité engendrée par une sélection « rigide » de variables et permet souvent de produire un modèle fort raisonnable.</p>
<p>Le problème est que l’on n’a pas plusieurs échantillons mais un seul. Une solution possible est de générer nous-mêmes des échantillons différents à partir de l‘échantillon original. Cela peut être fait avec l’autoamorçage (<em>bootstrap</em>). Un échantillon d’autoamorçage est tout simplement un échantillon choisi au hasard et <strong>avec remise</strong> dans l’échantillon original. Ainsi, une même observation peut être sélectionnée plus d’une fois tandis qu’une autre peut ne pas être sélectionnée du tout.</p>
<p>L’idée est alors la suivante :</p>
<ol style="list-style-type: decimal">
<li>Générer plusieurs échantillons par autoamorçage nonparamétrique à partir de l‘échantillon original.</li>
<li>Faire une sélection de variables pour chaque échantillon.</li>
<li>Faire la moyenne des paramètres de ces modèles.</li>
</ol>
<p>La procédure <code>glmselect</code> a une commande expérimentale, <code>modelaverage</code>, qui permet de faire une moyenne de modèles. Comme elle est expérimentale, les particularités (options et sorties) de cette commande risquent de changer au cours des versions à venir. Le code suivant permet de faire une moyenne de modèles.</p>
<pre class="sas"><code>proc glmselect data=trainymontant seed=57484765;
model ymontant= 
  ... /* mettre les 104 variables ici */
/ selection=stepwise(select=bic choose=bic) ; 
score data=testymontant out=predaverage p=predymontant;
modelaverage nsamples=500 sampling=urs subset(best=500);
run;</code></pre>
<p>Chaque modèle est construit à l’aide d’un échantillon aléatoire avec remise (<code>sampling=urs</code>). Il y aura 500 échantillons, et donc modèles, en tout (<code>nsamples=500</code>). L’option <code>subset(best=500)</code> indique à <strong>SAS</strong> de faire la moyenne des paramètres des 500 modèles. Notez l’option <code>seed</code> qui permet de reproduire les résultats, car elle fixe une valeur pour le générateur de nombre aléatoire (qui sera utilisé pour générer les échantillons d’autoamorçage). Cette fois-ci la sélection se fait avec le critère <span class="math inline">\(\mathsf{BIC}\)</span> à tous les niveaux (<code>select=bic choose=bic</code>).</p>
<p><img src="figures/02-select-e16.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Ce tableau présente les variables qui ont été choisies dans an moins 20% des modèles, c’est-à-dire, dans au moins 100 des 500 modèles ici. Il y a deux variables qui ont été retenues dans tous les modèles, <code>i_x1_x6</code> et <code>i_x31_x8</code>. Le tableau rapporte aussi la moyenne des estimations pour ces paramètres.</p>
<p>Il s’avère que cette approche performe très bien sur l’échantillon test de 23 179 clients avec une erreur moyenne quadratique estimé de <span class="math inline">\(10,57\)</span>. Le tableau <a href="sélection-de-variables-et-de-modèles-1.html#tab:02-modelcomparaisonfull">3.8</a> résume la performance des différentes méthodes que nous avons utilisé sur notre échantillon test.</p>
<table>
<caption><span id="tab:02-modelcomparaisonfull">Tableau 3.8: </span> Comparaison des méthodes selon l’erreur moyenne quadratique.</caption>
<colgroup>
<col width="20%" />
<col width="25%" />
<col width="29%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">variables</th>
<th align="center">nombre de variables</th>
<th align="center"><span class="math inline">\(\mathsf{EMQ}\)</span></th>
<th align="left">méthode</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">de base</td>
<td align="center">14</td>
<td align="center">25,69</td>
<td align="left">toutes les variables</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">10</td>
<td align="center">24,72</td>
<td align="left">exhaustive - <span class="math inline">\(\mathsf{AIC}\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">7</td>
<td align="center">23,83</td>
<td align="left">exhaustive - <span class="math inline">\(\mathsf{BIC}\)</span></td>
</tr>
<tr class="even">
<td align="left">interactions et termes quadratiques</td>
<td align="center">104</td>
<td align="center">19,63</td>
<td align="left">toutes les variables</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">22</td>
<td align="center">12,25</td>
<td align="left">séquentielle classique</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">38</td>
<td align="center">14,83</td>
<td align="left">séquentielle classique, recherche exhaustive avec 56 variables <span class="math inline">\((\mathsf{AIC})\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">15</td>
<td align="center">11,96</td>
<td align="left">séquentielle classique, recherche exhaustive avec 56 variables <span class="math inline">\((\mathsf{BIC})\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">10</td>
<td align="center">10,08</td>
<td align="left">séquentielle avec critère <span class="math inline">\(\mathsf{AIC}\)</span> (choix selon le <span class="math inline">\(\mathsf{BIC}\)</span>)</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center"></td>
<td align="center">10,57</td>
<td align="left">moyenne de modèles</td>
</tr>
</tbody>
</table>
<p>Dans cet exemple, la méthode séquentielle de <code>glmselect</code> avec les options <code>select=aic</code> et <code>choose=bic</code> aurait donné le meilleur résultat pour prévoir le montant acheté des clients restants (de ceux qui auraient acheté quelque chose). Le deuxième meilleur aurait été la moyenne des modèles.</p>
<p>Il y aurait plusieurs autres approches/combinaisons qui pourraient être testées. Le but de ce chapitre était simplement de présenter les principes de base en sélection de modèles et de variables ainsi que certaines approches pratiques. Il y a d’autres approches intéressantes, tels le LASSO et LARS (<em>least-angle regression</em>) qui sont disponibles dans <code>glmselect</code>. Ces méthodes sont dans la même mouvance moderne que celle qui consiste à faire la moyenne de plusieurs modèles, en performant à la fois une sélection de variables et en permettant d’avoir des parties d’effet par le rétrécissement (<em>shrinkage</em>). De récents développements théoriques permettent de corriger les valeurs-<em>p</em> pour faire de l’inférence post-sélection.</p>
<p>Il faut bien comprendre qu’il ne s’agit que d’un seul exemple: il ne faut surtout pas conclure que la méthode séquentielle de <code>glmselect</code> avec les options <code>select=aic</code> et <code>choose=bic</code> sera toujours la meilleure. En fait, il est impossible de prévoir quelle méthode donnera les meilleurs résultats.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="analyse-factorielle-exploratoire-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="régression-logistique-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MATH60602.pdf", "MATH60602.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
