<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 5 Régression logistique | Analyse multidimensionnelle appliquée</title>
  <meta name="description" content="Recueil de notes pour MATH 60602 Analyse multidimensionnelle appliquée, avec des exemples d’applications en SAS et en R." />
  <meta name="generator" content="bookdown 0.21.6 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 5 Régression logistique | Analyse multidimensionnelle appliquée" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Recueil de notes pour MATH 60602 Analyse multidimensionnelle appliquée, avec des exemples d’applications en SAS et en R." />
  <meta name="github-repo" content="lbelzile/math60602" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 5 Régression logistique | Analyse multidimensionnelle appliquée" />
  
  <meta name="twitter:description" content="Recueil de notes pour MATH 60602 Analyse multidimensionnelle appliquée, avec des exemples d’applications en SAS et en R." />
  

<meta name="author" content="(c) Denis Larocque, Léo Belzile" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="selection-modele.html"/>
<link rel="next" href="analyse-survie.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />




<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Analyse multidimensionnelle appliquée</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#analyse-exploratoire"><i class="fa fa-check"></i><b>1.1</b> Analyse exploratoire de données</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="analyse-factorielle.html"><a href="analyse-factorielle.html"><i class="fa fa-check"></i><b>2</b> Analyse factorielle exploratoire</a>
<ul>
<li class="chapter" data-level="2.1" data-path="analyse-factorielle.html"><a href="analyse-factorielle.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="analyse-factorielle.html"><a href="analyse-factorielle.html#rappels-sur-le-coefficient-de-corrélation-linéaire"><i class="fa fa-check"></i><b>2.2</b> Rappels sur le coefficient de corrélation linéaire</a></li>
<li class="chapter" data-level="2.3" data-path="analyse-factorielle.html"><a href="analyse-factorielle.html#exemple-de-questionnaire"><i class="fa fa-check"></i><b>2.3</b> Exemple de questionnaire</a></li>
<li class="chapter" data-level="2.4" data-path="analyse-factorielle.html"><a href="analyse-factorielle.html#description-du-modèle-danalyse-factorielle"><i class="fa fa-check"></i><b>2.4</b> Description du modèle d’analyse factorielle</a></li>
<li class="chapter" data-level="2.5" data-path="analyse-factorielle.html"><a href="analyse-factorielle.html#estimation-des-facteurs"><i class="fa fa-check"></i><b>2.5</b> Estimation des facteurs</a></li>
<li class="chapter" data-level="2.6" data-path="analyse-factorielle.html"><a href="analyse-factorielle.html#choix-du-nombre-de-facteurs"><i class="fa fa-check"></i><b>2.6</b> Choix du nombre de facteurs</a></li>
<li class="chapter" data-level="2.7" data-path="analyse-factorielle.html"><a href="analyse-factorielle.html#construction-déchelles-à-partir-des-facteurs"><i class="fa fa-check"></i><b>2.7</b> Construction d’échelles à partir des facteurs</a></li>
<li class="chapter" data-level="2.8" data-path="analyse-factorielle.html"><a href="analyse-factorielle.html#compléments-dinformation"><i class="fa fa-check"></i><b>2.8</b> Compléments d’information</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analyse-regroupements.html"><a href="analyse-regroupements.html"><i class="fa fa-check"></i><b>3</b> Analyse de regroupements</a>
<ul>
<li class="chapter" data-level="3.1" data-path="analyse-regroupements.html"><a href="analyse-regroupements.html#introduction-2"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="analyse-regroupements.html"><a href="analyse-regroupements.html#segmentation-de-seniors-en-voyage-organisé"><i class="fa fa-check"></i><b>3.2</b> Segmentation de seniors en voyage organisé</a></li>
<li class="chapter" data-level="3.3" data-path="analyse-regroupements.html"><a href="analyse-regroupements.html#exploration-graphique-préalable-et-analyse-en-composantes-principales"><i class="fa fa-check"></i><b>3.3</b> Exploration graphique préalable et analyse en composantes principales</a></li>
<li class="chapter" data-level="3.4" data-path="analyse-regroupements.html"><a href="analyse-regroupements.html#méthodes-hiérarchiques"><i class="fa fa-check"></i><b>3.4</b> Méthodes hiérarchiques</a></li>
<li class="chapter" data-level="3.5" data-path="analyse-regroupements.html"><a href="analyse-regroupements.html#calcul-alternatif-des-distances-pour-le-regroupement-hiérarchique"><i class="fa fa-check"></i><b>3.5</b> Calcul alternatif des distances pour le regroupement hiérarchique</a></li>
<li class="chapter" data-level="3.6" data-path="analyse-regroupements.html"><a href="analyse-regroupements.html#standardisation-des-variables"><i class="fa fa-check"></i><b>3.6</b> Standardisation des variables</a></li>
<li class="chapter" data-level="3.7" data-path="analyse-regroupements.html"><a href="analyse-regroupements.html#autres-mesures-de-dissemblance"><i class="fa fa-check"></i><b>3.7</b> Autres mesures de dissemblance</a></li>
<li class="chapter" data-level="3.8" data-path="analyse-regroupements.html"><a href="analyse-regroupements.html#méthodes-non-hiérarchiques"><i class="fa fa-check"></i><b>3.8</b> Méthodes non hiérarchiques</a></li>
<li class="chapter" data-level="3.9" data-path="analyse-regroupements.html"><a href="analyse-regroupements.html#considérations-pratiques"><i class="fa fa-check"></i><b>3.9</b> Considérations pratiques</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="selection-modele.html"><a href="selection-modele.html"><i class="fa fa-check"></i><b>4</b> Sélection de variables et de modèles</a>
<ul>
<li class="chapter" data-level="4.1" data-path="selection-modele.html"><a href="selection-modele.html#introduction-3"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="selection-modele.html"><a href="selection-modele.html#sélection-de-variables-et-de-modèles-selon-les-buts-de-létude"><i class="fa fa-check"></i><b>4.2</b> Sélection de variables et de modèles selon les buts de l’étude</a></li>
<li class="chapter" data-level="4.3" data-path="selection-modele.html"><a href="selection-modele.html#mieux-vaut-plus-que-moins"><i class="fa fa-check"></i><b>4.3</b> Mieux vaut plus que moins</a></li>
<li class="chapter" data-level="4.4" data-path="selection-modele.html"><a href="selection-modele.html#trop-beau-pour-être-vrai"><i class="fa fa-check"></i><b>4.4</b> Trop beau pour être vrai</a></li>
<li class="chapter" data-level="4.5" data-path="selection-modele.html"><a href="selection-modele.html#principes-généraux"><i class="fa fa-check"></i><b>4.5</b> Principes généraux</a></li>
<li class="chapter" data-level="4.6" data-path="selection-modele.html"><a href="selection-modele.html#critères-dinformation"><i class="fa fa-check"></i><b>4.6</b> Critères d’information</a></li>
<li class="chapter" data-level="4.7" data-path="selection-modele.html"><a href="selection-modele.html#division-de-léchantillon-et-validation-croisée"><i class="fa fa-check"></i><b>4.7</b> Division de l’échantillon et validation croisée</a></li>
<li class="chapter" data-level="4.8" data-path="selection-modele.html"><a href="selection-modele.html#cibler-les-clients-pour-lenvoi-dun-catalogue"><i class="fa fa-check"></i><b>4.8</b> Cibler les clients pour l’envoi d’un catalogue</a></li>
<li class="chapter" data-level="4.9" data-path="selection-modele.html"><a href="selection-modele.html#recherche-automatique-du-meilleur-modèle"><i class="fa fa-check"></i><b>4.9</b> Recherche automatique du meilleur modèle</a></li>
<li class="chapter" data-level="4.10" data-path="selection-modele.html"><a href="selection-modele.html#recherche-automatique-de-tous-les-sous-ensembles"><i class="fa fa-check"></i><b>4.10</b> Recherche automatique de tous les sous-ensembles</a></li>
<li class="chapter" data-level="4.11" data-path="selection-modele.html"><a href="selection-modele.html#méthodes-classiques-de-sélection"><i class="fa fa-check"></i><b>4.11</b> Méthodes classiques de sélection</a></li>
<li class="chapter" data-level="4.12" data-path="selection-modele.html"><a href="selection-modele.html#recherche-séquentielle-automatique-limitée"><i class="fa fa-check"></i><b>4.12</b> Recherche séquentielle automatique limitée</a></li>
<li class="chapter" data-level="4.13" data-path="selection-modele.html"><a href="selection-modele.html#méthodes-de-régression-avec-régularisation"><i class="fa fa-check"></i><b>4.13</b> Méthodes de régression avec régularisation</a></li>
<li class="chapter" data-level="4.14" data-path="selection-modele.html"><a href="selection-modele.html#moyenne-de-modèles"><i class="fa fa-check"></i><b>4.14</b> Moyenne de modèles</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="regression-logistique.html"><a href="regression-logistique.html"><i class="fa fa-check"></i><b>5</b> Régression logistique</a>
<ul>
<li class="chapter" data-level="5.1" data-path="regression-logistique.html"><a href="regression-logistique.html#introduction-4"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="regression-logistique.html"><a href="regression-logistique.html#modèle-de-régression-logistique"><i class="fa fa-check"></i><b>5.2</b> Modèle de régression logistique</a></li>
<li class="chapter" data-level="5.3" data-path="regression-logistique.html"><a href="regression-logistique.html#estimation-des-paramètres"><i class="fa fa-check"></i><b>5.3</b> Estimation des paramètres</a></li>
<li class="chapter" data-level="5.4" data-path="regression-logistique.html"><a href="regression-logistique.html#cowboy"><i class="fa fa-check"></i><b>5.4</b> Exemple du <em>Professional Rodeo Cowboys Association</em></a></li>
<li class="chapter" data-level="5.5" data-path="regression-logistique.html"><a href="regression-logistique.html#classification-et-prédiction-à-laide-de-la-régression-logistique"><i class="fa fa-check"></i><b>5.5</b> Classification et prédiction à l’aide de la régression logistique</a></li>
<li class="chapter" data-level="5.6" data-path="regression-logistique.html"><a href="regression-logistique.html#classification-avec-une-matrice-de-gain"><i class="fa fa-check"></i><b>5.6</b> Classification avec une matrice de gain</a></li>
<li class="chapter" data-level="5.7" data-path="regression-logistique.html"><a href="regression-logistique.html#sélection-de-variables-en-régression-logistique"><i class="fa fa-check"></i><b>5.7</b> Sélection de variables en régression logistique</a></li>
<li class="chapter" data-level="5.8" data-path="regression-logistique.html"><a href="regression-logistique.html#performance-des-différents-modèles-pour-lexemple-des-clients-cibles"><i class="fa fa-check"></i><b>5.8</b> Performance des différents modèles pour l’exemple des clients cibles</a></li>
<li class="chapter" data-level="5.9" data-path="regression-logistique.html"><a href="regression-logistique.html#extensions-du-modèle-de-régression-logistique-à-plus-de-deux-catégories"><i class="fa fa-check"></i><b>5.9</b> Extensions du modèle de régression logistique à plus de deux catégories</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="analyse-survie.html"><a href="analyse-survie.html"><i class="fa fa-check"></i><b>6</b> Analyse de survie</a>
<ul>
<li class="chapter" data-level="6.1" data-path="analyse-survie.html"><a href="analyse-survie.html#introduction-5"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="analyse-survie.html"><a href="analyse-survie.html#fonctions-de-survie-et-de-risque"><i class="fa fa-check"></i><b>6.2</b> Fonctions de survie et de risque</a></li>
<li class="chapter" data-level="6.3" data-path="analyse-survie.html"><a href="analyse-survie.html#estimation-dune-courbe-de-survie-et-de-risque"><i class="fa fa-check"></i><b>6.3</b> Estimation d’une courbe de survie et de risque</a></li>
<li class="chapter" data-level="6.4" data-path="analyse-survie.html"><a href="analyse-survie.html#comparaison-de-deux-courbes-de-survie"><i class="fa fa-check"></i><b>6.4</b> Comparaison de deux courbes de survie</a></li>
<li class="chapter" data-level="6.5" data-path="analyse-survie.html"><a href="analyse-survie.html#modèle-à-risques-proportionnels-de-cox"><i class="fa fa-check"></i><b>6.5</b> Modèle à risques proportionnels de Cox</a></li>
<li class="chapter" data-level="6.6" data-path="analyse-survie.html"><a href="analyse-survie.html#extensions-du-modèle-de-cox"><i class="fa fa-check"></i><b>6.6</b> Extensions du modèle de Cox</a></li>
<li class="chapter" data-level="6.7" data-path="analyse-survie.html"><a href="analyse-survie.html#risques-non-proportionnels"><i class="fa fa-check"></i><b>6.7</b> Risques non proportionnels</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="données-manquantes-1.html"><a href="données-manquantes-1.html"><i class="fa fa-check"></i><b>7</b> Données manquantes</a>
<ul>
<li class="chapter" data-level="7.1" data-path="données-manquantes-1.html"><a href="données-manquantes-1.html#terminologie"><i class="fa fa-check"></i><b>7.1</b> Terminologie</a></li>
<li class="chapter" data-level="7.2" data-path="données-manquantes-1.html"><a href="données-manquantes-1.html#quelques-méthodes"><i class="fa fa-check"></i><b>7.2</b> Quelques méthodes</a></li>
<li class="chapter" data-level="7.3" data-path="données-manquantes-1.html"><a href="données-manquantes-1.html#example-dapplication-de-limputation"><i class="fa fa-check"></i><b>7.3</b> Example d’application de l’imputation</a></li>
<li class="chapter" data-level="7.4" data-path="données-manquantes-1.html"><a href="données-manquantes-1.html#valeurs-manquantes-dans-un-contexte-de-prédiction"><i class="fa fa-check"></i><b>7.4</b> Valeurs manquantes dans un contexte de prédiction</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publié avec bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analyse multidimensionnelle appliquée</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression-logistique" class="section level1" number="5">
<h1><span class="header-section-number">Chapitre 5</span> Régression logistique</h1>
<div id="introduction-4" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Introduction</h2>
<p>En régression linéaire, on cherche à expliquer le comportement d’une variable quantitative <span class="math inline">\(Y\)</span> que l’on peut traiter comme étant continue (elle peut prendre suffisamment de valeurs différentes).</p>
<p>Supposons à présent que l’on veut expliquer le comportement d’une variable <span class="math inline">\(Y\)</span> prenant seulement deux valeurs que l’on va noter 0 et 1.</p>
<p>Exemples :</p>
<ul>
<li>Est-ce qu’un client potentiel va répondre favorablement à une offre promotionnelle?</li>
<li>Est-ce qu’un client est satisfait du service après-vente?</li>
<li>Est-ce qu’un client va faire faillite ou non au cours des trois prochaines années.</li>
</ul>
<p>En général, on cherchera à expliquer le comportement d’une variable binaire <span class="math inline">\(Y\)</span> en utilisant un modèle basé sur p variables quelconques <span class="math inline">\(X_1, \ldots, X_p\)</span>.</p>
<p>Notre but sera de faire de l’inférence, de la prédiction, ou les deux à la fois, soit</p>
<ol style="list-style-type: decimal">
<li>Comprendre comment et dans quelles mesures les variables <span class="math inline">\(\boldsymbol{X}\)</span> influencent <span class="math inline">\(Y\)</span> (ou bien la probabilité que <span class="math inline">\(Y=1\)</span>).</li>
<li>Prédiction : développer un modèle pour prévoir des valeurs de <span class="math inline">\(Y\)</span> futures à partir des variables <span class="math inline">\(\boldsymbol{X}\)</span>.</li>
</ol>
</div>
<div id="modèle-de-régression-logistique" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Modèle de régression logistique</h2>
<p>Avec une variable réponse continue, le modèle de régression linéaire,
<span class="math display">\[\begin{align*}
 Y = \beta_0 + \beta_1X_1 + \cdots + \beta_p X_p + \varepsilon,
\end{align*}\]</span>
avec <span class="math inline">\({\mathsf E}\left(\varepsilon\mid \boldsymbol{X}\right)=0\)</span> et <span class="math inline">\({\mathsf{Var}}\left(\varepsilon\mid \boldsymbol{X}\right)=\sigma^2\)</span>, peut être écrit de manière équivalente comme <span class="math inline">\({\mathsf E}\left(Y \mid \boldsymbol{X}\right) = \beta_0 + \beta_1X_1 + \cdots + \beta_pX_p\)</span> et <span class="math inline">\({\mathsf{Var}}\left(Y \mid \boldsymbol{X}\right)=\sigma^2.\)</span></p>
<p>Si <span class="math inline">\(Y\)</span> est binaire (0/1), on peut facilement vérifier que
<span class="math display">\[\begin{align*}
{\mathsf E}\left(Y \mid \boldsymbol{X}\right) = {\mathsf P}\left(Y=1 \mid  \boldsymbol{X}\right),
\end{align*}\]</span>
soit la probabilité que <span class="math inline">\(Y\)</span> égale 1 étant donné les valeurs des variables explicatives. Pour simplifier la notation, posons <span class="math inline">\(p = {\mathsf P}\left(Y=1 \mid \boldsymbol{X}\right)\)</span> en se rappelant que <span class="math inline">\(p\)</span> est une fonction des variables explicatives.</p>
<p>À première vue, on peut se demander pourquoi ne pas utiliser le même modèle que la régression linéaire, c’est-à-dire
<span class="math display">\[\begin{align*}
\eta=\beta_0 + \beta_1X_1 + \cdots + \beta_p X_p.
\end{align*}\]</span></p>
<p>Le problème est que <span class="math inline">\(p\)</span> est une probabilité. Par conséquent <span class="math inline">\(p\)</span> prend seulement des valeurs entre 0 et 1 alors que rien n’empêche <span class="math inline">\(\eta\)</span> de prendre des valeurs dans <span class="math inline">\(\mathbb{R}=(-\infty, \infty)\)</span>. Une façon de résoudre ce problème consiste à appliquer une transformation à <span class="math inline">\(p\)</span> de telle sorte que la quantité transformée puisse prendre toutes les valeurs entre <span class="math inline">\(-\infty\)</span> et <span class="math inline">\(\infty\)</span>.
Le modèle de régression logistique est défini à l’aide de la transformation <span class="math inline">\(\mathrm{logit}\)</span>,
<span class="math display">\[\mathrm{logit}(p) = \ln\left( \frac{p}{1-p}\right)=\eta=\beta_0 + \beta_1X_1 + \cdots + \beta_p X_p,\]</span>
où <span class="math inline">\(\ln\)</span> est le logarithme naturel.</p>
<p>En régression linéaire, on suppose que l’espérance de <span class="math inline">\(Y\)</span> étant donné les valeurs des variables explicatives est une combinaison linéaire de ces dernières. En régression logistique, on suppose que le logit de la probabilité que <span class="math inline">\(Y=1\)</span> étant donné les valeurs des variables explicatives est une combinaison linéaire de ces dernières.</p>
<p>Une simple manipulation algébrique permet d’exprimer ce modèle en terme de la probabilité <span class="math inline">\(p\)</span>,
<span class="math display">\[\begin{align*}
 p &amp;= \mathrm{expit}(\eta) = \frac{\exp(\eta)}{1+\exp(\eta)}
= \frac{1}{1+\exp(-\eta)}.
\end{align*}\]</span>
On peut voir qu’à mesure que le prédicteur linéaire <span class="math inline">\(\eta=\beta_0+\beta_1X_1 + \cdots + \beta_pX_p\)</span> augmente, la probabilité augmente.
Si le coefficient <span class="math inline">\(\beta_j\)</span> est négatif, <span class="math inline">\(p\)</span> diminuera à mesure que <span class="math inline">\(X_j\)</span> augmente.</p>
<p><img src="MATH60602_files/figure-html/logitplot-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Pour une variable binaire <span class="math inline">\(Y\)</span>, le quotient <span class="math inline">\(p/(1-p)\)</span> est appelé <strong>cote</strong> et représente le ratio de la probabilité de succès (<span class="math inline">\(Y=1\)</span>) sur la probabilité d’échec (<span class="math inline">\(Y=0\)</span>),
<span class="math display">\[\begin{align*}
 \mathsf{cote}(p) = \frac{p}{1-p} = \frac{{\mathsf P}\left(Y=1 \mid \boldsymbol{X}\right)}{{\mathsf P}\left(Y=0 \mid \boldsymbol{X}\right)}.
\end{align*}\]</span></p>
<p>Par exemple, une cote de 4 veut dire qu’il y a 4 fois plus de chance que <span class="math inline">\(Y\)</span> soit égale à <span class="math inline">\(1\)</span> par rapport à <span class="math inline">\(0\)</span>. Une cote de 0,25 veut dire le contraire, il y a 4 fois moins de chance que <span class="math inline">\(Y=1\)</span> par rapport à <span class="math inline">\(0\)</span> ou bien, de manière équivalente, il y a 4 fois plus de chance que <span class="math inline">\(Y=0\)</span> par rapport à <span class="math inline">\(1\)</span>. Le Tableau <a href="regression-logistique.html#tab:03-cotes">5.1</a> donne un aperçu de cotes pour quelques probabilités <span class="math inline">\(p\)</span>.</p>
<table>
<caption>
<span id="tab:03-cotes">Tableau 5.1: </span>Cote et probabilité de succès
</caption>
<thead>
<tr>
<th style="text-align:left;">
<span class="math inline">\({\mathsf P}\left(Y=1\right)\)</span>
</th>
<th style="text-align:center;">
0.1
</th>
<th style="text-align:center;">
0.2
</th>
<th style="text-align:center;">
0.3
</th>
<th style="text-align:center;">
0.4
</th>
<th style="text-align:center;">
0.5
</th>
<th style="text-align:center;">
0.6
</th>
<th style="text-align:center;">
0.7
</th>
<th style="text-align:center;">
0.8
</th>
<th style="text-align:center;">
0.9
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
cote
</td>
<td style="text-align:center;">
0.11
</td>
<td style="text-align:center;">
0.25
</td>
<td style="text-align:center;">
0.43
</td>
<td style="text-align:center;">
0.67
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1.5
</td>
<td style="text-align:center;">
2.3
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
9
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{1}{9}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{1}{4}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{3}{7}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{2}{3}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{3}{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{7}{3}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(4\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(9\)</span>
</td>
</tr>
</tbody>
</table>
</div>
<div id="estimation-des-paramètres" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Estimation des paramètres</h2>
<div id="principes-de-base" class="section level3" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Principes de base</h3>
<p>On dispose d’un échantillon de taille <span class="math inline">\(n\)</span> sur les variables <span class="math inline">\((Y, X_1, \ldots, X_p)\)</span>, dans le tableau
<span class="math display">\[\begin{align*}
 \begin{pmatrix}
 x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} &amp; y_1 \\
 x_{21} &amp; \ddots &amp; \cdots &amp; x_{2p} &amp; y_2 \\
 \vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \vdots \\
 x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} &amp; y_n \\
 \end{pmatrix}
\end{align*}\]</span>
À l’aide de ces observations, on peut estimer les paramètres <span class="math inline">\(\boldsymbol{\beta} = (\beta_0, \beta_1 ,\ldots, \beta_p)\)</span> du modèle de régression logistique
<span class="math display">\[\begin{align*}
\mathrm{logit}(p) = \ln \left( \frac{p}{1-p}\right) = \beta_0 + \beta_1 X_1 + \cdots + \beta_pX_p.
\end{align*}\]</span>
On obtient ainsi les estimés des paramètres <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>, desquels découle une estimation de <span class="math inline">\({\mathsf P}\left(Y=1\right)\)</span> pour les valeurs <span class="math inline">\(X_1=x_1, \ldots, X_p=x_p\)</span> d’un individu donné,
<span class="math display">\[\begin{align*}
 \widehat{p} = \mathrm{expit}(\widehat{\beta}_0 + \cdots + \widehat{\beta}_pX_p).
\end{align*}\]</span></p>
<p>Un modèle ajusté peut ensuite être utilisé pour faire de la classification (prédiction) pour de nouveaux individus pour lesquels la variable réponse <span class="math inline">\(Y\)</span> n’est pas observée. Pour ce faire, on choisit un point de coupure <span class="math inline">\(c\)</span> (souvent $c=$0,5 mais pas toujours) et on classifie les observations en deux groupes:</p>
<ul>
<li>Si <span class="math inline">\(\widehat{p}&lt; c\)</span>, alors <span class="math inline">\(\widehat{Y}=0\)</span> (c’est-à-dire, on assigne cette observation à la catégorie 0).</li>
<li>Si <span class="math inline">\(\widehat{p} \geq c\)</span>, alors <span class="math inline">\(\widehat{Y}=1\)</span> (c’est-à-dire, on assigne cette observation à la catégorie 1).</li>
</ul>
<p>On reviendra en détail sur cet aspect dans une section suivante.</p>
<p>La méthode d’estimation des paramètres habituellement utilisée est la méthode du maximum de vraisemblance. Pour les applications, il est suffisant de savoir manipuler trois quantités importantes: la log-vraisemblance, le <span class="math inline">\(\mathsf{AIC}\)</span> et le <span class="math inline">\(\mathsf{BIC}\)</span>. Les deux critères d’information, que nous avons couvert dans les chapitres précédents, servent à la sélection de modèles tandis que la log-vraisemblance <span class="math inline">\(\ell\)</span> servira à construire un test d’hypothèse.</p>
</div>
<div id="méthode-du-maximum-de-vraisemblance" class="section level3" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Méthode du maximum de vraisemblance</h3>
<p>Cette sous-section est facultative. Elle donne plus de détails sur la méthode du maximum de vraisemblance et les quantités en découlant (soit <span class="math inline">\(\mathsf{AIC}\)</span>, <span class="math inline">\(\mathsf{BIC}\)</span> et <span class="math inline">\(\ell(\widehat{\boldsymbol{\beta}})\)</span>).</p>
<p>La méthode du maximum de vraisemblance (<em>maximum likelihood</em>) est possiblement la méthode d’estimation la plus utilisée en statistique. En général, pour un échantillon donné et un modèle avec des paramètres inconnus <span class="math inline">\(\boldsymbol{\theta}\)</span>, on peut calculer la « probabilité » d’avoir obtenu les observations de notre échantillon selon les paramètre. Si on traite cette « probabilité » comme étant une fonction des paramètres du modèle, <span class="math inline">\(\boldsymbol{\theta}\)</span>, on l’appelle alors la vraisemblance (<em>likelihood</em>). La méthode du maximum de vraisemblance consiste à trouver les valeurs des paramètres qui maximisent la vraisemblance. On cherche donc les estimations qui sont les plus vraisemblables étant donné nos observations.</p>
<p>En pratique, il est habituellement plus simple de chercher à maximiser le log de la vraisemblance (ce qui revient au même car le log est une fonction croissante) et on nomme cette fonction la log-vraisemblance (<em>log-likelihood</em>).</p>
<p>Vous connaissez déjà des exemples d’estimateurs du maximum de vraisemblance. La moyenne d’un échantillon est l’estimateur du maximum de vraisemblance pour la moyenne de la population <span class="math inline">\(\mu\)</span> si les observations représentent un échantillon aléatoire simple tiré d’une loi normale.</p>
<p>Dans le cas d’un modèle de régression linéaire multiple <span class="math inline">\(Y = \beta_0 + \sum_{j=1}^p \beta_jX_j + \varepsilon\)</span> avec les erreurs <span class="math inline">\(\varepsilon\sim \mathcal{N}(0, \sigma^2)\)</span> des termes indépendants et identiquement distributions, la log-vraisemblance du modèle pour un échantillon de taille <span class="math inline">\(n\)</span> est
<span class="math display">\[\begin{align*}
 \ell(\boldsymbol{\beta}, \sigma^2) =- \frac{n}{2} \ln(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (Y_i- \beta_0 - \beta_1 X_{1i} - \cdots - \beta_pX_{ip})^2.
\end{align*}\]</span>
Puisque le premier terme ne dépend pas des paramètres <span class="math inline">\(\boldsymbol{\beta}\)</span>, il est clair que maximiser cette fonction de <span class="math inline">\(\boldsymbol{\beta}\)</span> revient à minimiser <span class="math inline">\(\sum_{i=1}^n (Y_i- \beta_0 - \beta_1 X_{1i} - \cdots - \beta_pX_{ip})^2\)</span>, et ce critère est exactement le même que celui des moindres carrés. Par conséquent, les estimations des paramètres <span class="math inline">\(\boldsymbol{\beta}\)</span> provenant de la méthode des moindres carrés peuvent être vues comme étant des estimateurs du maximum de vraisemblance sous l’hypothèse de normalité des observations; il est même possible d’écrire une formule explicite pour ces estimations.</p>
<p>Dans le cas de la régression logistique, la fonction de log-vraisemblance s’écrit
<span class="math display">\[\begin{align*}
 \ell(\boldsymbol{\beta}) &amp;= \sum_{i=1}^n Y_i ( \beta_0 + \beta_1 X_{i1} + \cdots + \beta_p X_{ip}) \\&amp;- \sum_{i=1}^n \ln\left\{1+\exp(\beta_0 + \cdots + \beta_pX_{ip})\right\}
\end{align*}\]</span></p>
<p>Contrairement au cas de la régression linéaire, on ne peut trouver une fonction explicite pour les valeurs des paramètres qui maximisent cette fonction. Des méthodes numériques doivent alors être utilisées pour l’optimisation. Une fois la maximisation accomplie, on obtient les estimés du maximum de vraisemblance, <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>. On peut alors calculer la valeur maximale (numérique) de la log-vraisemblance, <span class="math inline">\(\ell(\widehat{\boldsymbol{\beta}})\)</span>. La quantité <span class="math inline">\(-2\ell(\widehat{\boldsymbol{\beta}})\)</span> (<code>-2 Log L</code>) est rapportée dans les sorties <strong>SAS</strong>. Par analogie avec la régression linéaire la valeur de la log-vraisemblance évaluée à <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>, <span class="math inline">\(\ell(\widehat{\boldsymbol{\beta}})\)</span>, augmente toujours lorsqu’on ajoute des régresseurs et c’est pourquoi on ne pourra pas l’utiliser comme outil de sélection de variables.</p>
<p>Les critères d’information sont des fonctions de la log-vraisemblance, mais incluent une pénalité pour le nombre de coefficients <span class="math inline">\(\boldsymbol{\beta}\)</span>,
<span class="math display">\[\begin{align*}
 \mathsf{AIC} &amp; = -2 \ell(\widehat{\boldsymbol{\beta}}) + 2(p+1)\\
 \mathsf{BIC} &amp; = -2 \ell(\widehat{\boldsymbol{\beta}}) + \ln(n)(p+1)
\end{align*}\]</span></p>
<p>Ces définitions sont utilisables dans plusieurs situations lorsque le modèle est ajusté par la méthode du maximum de vraisemblance. En particulier, elles sont utilisées par <strong>SAS</strong> en régression logistique. Tout comme en régression linéaire et en analyse factorielle, ces deux critères pourront être utilisés pour faire de la sélection de modèles si on calcule les estimateurs du maximum de vraisemblance.</p>
</div>
</div>
<div id="cowboy" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Exemple du <em>Professional Rodeo Cowboys Association</em></h2>
<p>L’exemple suivant est inspiré de l’article</p>
<blockquote>
<p>Daneshvary, R. et Schwer, R. K. (2000) The Association Endorsement and Consumers’ Intention to Purchase. <em>Journal of Consumer Marketing</em> <strong>17</strong>, 203-213.</p>
</blockquote>
<p>Dans cet article, les auteurs cherchent à voir si le fait qu’un produit soit recommandé par le <em>Professional Rodeo Cowboys Association</em> (PRCA) a un effet sur les intentions d’achats. On dispose de 500 observations sur les variables suivantes:</p>
<ul>
<li><span class="math inline">\(Y\)</span>: seriez-vous intéressé à acheter un produit recommandé par le PRCA
<ul>
<li><span class="math inline">\(\texttt{0}\)</span>: non</li>
<li><span class="math inline">\(\texttt{1}\)</span>: oui</li>
</ul></li>
<li><span class="math inline">\(X_1\)</span>: quel genre d’emploi occupez-vous?
<ul>
<li><span class="math inline">\(\texttt{1}\)</span>: à la maison</li>
<li><span class="math inline">\(\texttt{2}\)</span>: employé</li>
<li><span class="math inline">\(\texttt{3}\)</span>: ventes/services</li>
<li><span class="math inline">\(\texttt{4}\)</span>: professionnel</li>
<li><span class="math inline">\(\texttt{5}\)</span>: agriculture/ferme</li>
</ul></li>
<li><span class="math inline">\(X_2\)</span>: revenu familial annuel
<ul>
<li><span class="math inline">\(\texttt{1}\)</span>: moins de 25 000</li>
<li><span class="math inline">\(\texttt{2}\)</span>: 25 000 à 39 999</li>
<li><span class="math inline">\(\texttt{3}\)</span>: 40 000 à 59 999</li>
<li><span class="math inline">\(\texttt{4}\)</span>: 60 000 à 79 999</li>
<li><span class="math inline">\(\texttt{5}\)</span>: 80 000 et plus</li>
</ul></li>
<li><span class="math inline">\(X_3\)</span>: sexe
<ul>
<li><span class="math inline">\(\texttt{0}\)</span>: homme</li>
<li><span class="math inline">\(\texttt{1}\)</span>: femme</li>
</ul></li>
<li><span class="math inline">\(X_4\)</span>: avez-vous déjà fréquenté une université?
<ul>
<li><span class="math inline">\(\texttt{0}\)</span>: non</li>
<li><span class="math inline">\(\texttt{1}\)</span>: oui</li>
</ul></li>
<li><span class="math inline">\(X_5\)</span>: âge (en années)</li>
<li><span class="math inline">\(X_6\)</span>: combien de fois avez-vous assisté à un rodéo au cours de la dernière année?
<ul>
<li><span class="math inline">\(\texttt{1}\)</span>: 10 fois ou plus</li>
<li><span class="math inline">\(\texttt{2}\)</span>: entre six et neuf fois</li>
<li><span class="math inline">\(\texttt{3}\)</span>: cinq fois ou moins</li>
</ul></li>
</ul>
<p>Le but est d’examiner les effets de ces variables sur l’intentions d’achat (<span class="math inline">\(Y\)</span>). Les données se trouvent dans le fichier <code>logit1.sas7bdat</code>.</p>
<div id="modèle-avec-une-seule-variable-explicative" class="section level3" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Modèle avec une seule variable explicative</h3>
<p>Faisons tout d’abord une analyse en utilisant seulement <span class="math inline">\(X_5\)</span> (âge) comme variable explicative. L’ajustement du modèle de régression incluant uniquement <span class="math inline">\(X_5\)</span> sera effectuée en exécutant le programme</p>
<pre class="sas"><code>proc logistic data=multi.logit1 ;
model y(ref=&#39;0&#39;) = x5 / clparm=pl clodds=pl expb;
run;</code></pre>
<p>La syntaxe <code>y(ref='0')</code> sert à spécifier la catégorie de référence, zéro, de la variable réponse <span class="math inline">\(Y\)</span>: le modèle décrit donc <span class="math inline">\({\mathsf P}\left(y=1 \mid X_5\right)\)</span>.</p>
<p>Voici une partie de la sortie</p>
<p><img src="figures/03-logistic-e1.png" width="63%" style="display: block; margin: auto;" /></p>
<p><img src="figures/03-logistic-e2.png" width="80%" style="display: block; margin: auto;" /></p>
<p><img src="figures/03-logistic-e3.png" width="80%" style="display: block; margin: auto;" /></p>
<p><img src="figures/03-logistic-e4.png" width="80%" style="display: block; margin: auto;" /></p>
<ul>
<li><p>On voit qu’il y a 272 personnes (<span class="math inline">\(\texttt{0}\)</span>) qui ne sont pas intéressées à acheter un produit recommandé par le PRCA et 228 personnes (<span class="math inline">\(\texttt{1}\)</span>) qui le sont.</p></li>
<li><p>Les estimés des paramètres sont <span class="math inline">\(\widehat{\beta}_0 = -3.05\)</span> et <span class="math inline">\(\widehat{\beta}_{\texttt{age}}=0.0749\)</span>.</p></li>
<li><p>Un intervalle de confiance de niveau 95% pour l’effet de l’âge est [<span class="math inline">\(0.0465; 0.1043\)</span>].</p></li>
<li><p>Le modèle ajusté est <span class="math inline">\(\mathrm{logit}\{{\mathsf P}\left(Y=1 \mid X_5=x_5\right)\} = -3.05 + 0.0749 x_5\)</span>. On peut également exprimer ce modèle directement en terme de la probabilité de succès,
<span class="math display">\[\begin{align*}
{\mathsf P}\left(Y=1 \mid X_5=x_5\right) &amp;= \mathrm{expit}(-3.05 + 0.0749 x_5) \\&amp;= \frac{1}{1+\exp(-3.05 - 0.0749 x_5)}
\end{align*}\]</span>
Le graphe de cette fonction pour <span class="math inline">\(X_5\)</span> allant de 18 à 59 ans, respectivement les valeurs minimales et maximales observées dans l’échantillon, montre que le lien entre l’âge et <span class="math inline">\(p\)</span> est presque linéaire entre 20 et 60 ans. On décèle tout de même la forme sigmoide de la fonction <span class="math inline">\(\mathrm{logit}\)</span> aux deux extrémités.
<img src="MATH60602_files/figure-html/logitplot2-1.png" width="70%" style="display: block; margin: auto;" /></p></li>
<li><p>La valeur-<span class="math inline">\(p\)</span> pour <span class="math inline">\(\widehat{\beta}_{\texttt{age}}\)</span> (<code>Pr &gt; khi-2</code>), correspondant aux test des hypothèses <span class="math inline">\(\mathcal{H}_0: \beta_{\texttt{age}}=0\)</span> versus <span class="math inline">\(\mathcal{H}_1: \beta_{\texttt{age}} \neq 0\)</span>, est plus petite que <span class="math inline">\(10^{-4}\)</span> et donc l’effet de la variable âge est statistiquement différent de zéro. Plus l’âge augmente, plus la probabilité d’être intéressé à acheter un produit recommandé par le PRCA augmente.</p></li>
<li><p>Le tableau <code>Test de l'hypothèse nulle globale : BETA=0</code> contient les résultats de trois tests pour l’hypothèse nulle que tous les paramètres sont nuls, contre l’alternative qu’au moins un des paramètres est différent de zéro. Comme il y a un seul paramètre ici, ces tests reviennent à tester l’effet de la variable âge. Le test de Wald est le même que celui que nous venons de voir dans le tableau des coefficients.</p></li>
</ul>
</div>
<div id="interprétation-du-paramètre" class="section level3" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Interprétation du paramètre</h3>
<p>Si une variable est modélisée à l’aide d’un seul paramètre (pas de terme quadratique et pas d’interaction avec d’autre covariables), une valeur positive du paramètre indique une association positive avec <span class="math inline">\(p\)</span> alors qu’une valeur négative indique le contraire.</p>
<p>Ainsi, le signe du paramètre donne le sens de l’association. Si le coefficient <span class="math inline">\(\beta_j\)</span> de la variable <span class="math inline">\(X_j\)</span> est positif, alors plus la variable augmente, plus <span class="math inline">\({\mathsf P}\left(Y=1\right)\)</span> augmente. Inversement, Si le coefficient <span class="math inline">\(\beta_j\)</span> est négatif, plus la variable augmente, plus <span class="math inline">\({\mathsf P}\left(Y=1\right)\)</span> diminue.</p>
<p>En régression linéaire, l’interprétation de coefficient <span class="math inline">\(\beta_j\)</span> est simple: lorsque la variable <span class="math inline">\(X_j\)</span> augmente de un, la variable <span class="math inline">\(Y\)</span> augmente en moyenne de <span class="math inline">\(\beta_j\)</span>, toute chose étant égale par ailleurs. Cette interprétation ne dépend pas de la valeur de <span class="math inline">\(X_j\)</span>. En régression logistique, comme le modèle est nonlinéaire en fonction de <span class="math inline">\({\mathsf P}\left(Y=1\right)\)</span> (courbe sigmoide), l’augmentation ou la dimininution de <span class="math inline">\({\mathsf P}\left(Y=1\mid \boldsymbol{X}\right)\)</span> pour un changement d’une unité de <span class="math inline">\(X_j\)</span> dépend de la valeur de cette dernière. C’est pourquoi il est parfois plus utile d’utiliser la cote pour interpréter globalement l’effet d’une variable.</p>
<p>Dans notre exemple, on peut exprimer le modèle ajusté en termes de cote,
<span class="math display">\[\begin{align*}
 \frac{{\mathsf P}\left(Y=1 \mid X_5=x_5\right)}{{\mathsf P}\left(Y=0 \mid X_5=x_5\right)} = \exp(-3.05)\exp(0.0749x_5).
\end{align*}\]</span>
Ainsi, lorsque <span class="math inline">\(X_5\)</span> augmente d’une année, la cote est multipliée par <span class="math inline">\(\exp(0.0749) = 1.078\)</span> peut importe la valeur de <span class="math inline">\(x_5\)</span>. Pour deux personnes dont la différence d’âge est un an, la cote de la personne plus âgée est 7.8% plus élevée. On peut aussi quantifier l’effet d’une augmentation d’un nombre d’unités quelconque. Par exemple, pour chaque augmentation de 10 ans de <span class="math inline">\(X_5\)</span>, la cote est multiplié par <span class="math inline">\(1.078^{10} = 2.12\)</span>, soit une augmentation de 112%.</p>
<p>La cote est rapportée à la dernière colonne du tableau des coefficients. En général, si on veut une interprétation globale de l’effet d’une variable, il faudra baser l’interprétation sur l’exponentielle du coefficient, <span class="math inline">\(\exp(\widehat{\beta})\)</span>. <strong>SAS</strong> dénomme cette quantité rapport de cote (<em>odds ratio</em>).</p>
<p>Un des avantages d’utiliser la vraisemblance comme fonction objective est que les intervalles de confiance et les estimateurs basés sur la vraisemblance (profilée) sont invariant aux reparametrisations. Ainsi, l’intervalle de confiance à niveau 95% pour <span class="math inline">\(\exp(\beta_{\texttt{age}})\)</span> est obtenu en prenant l’exponentielle des bornes de l’intervalle pour <span class="math inline">\(\beta_{\texttt{age}}\)</span>, [<span class="math inline">\(\exp(0.0465); \exp(0.1043)\)</span>], soit [<span class="math inline">\(1.048; 1.110\)</span>] tel que rapporté dans la sortie. Ce n’est <strong>pas</strong> le cas des intervalles de Wald qui ont la forme <span class="math inline">\(\widehat{\beta} \pm 1.96 \mathrm{se}(\widehat{\beta})\)</span>.
Comme l’exponentielle est une transformation monotone croissante, on a <span class="math inline">\(\beta&gt;0\)</span> si et seulement si <span class="math inline">\(\exp(\beta)&gt;1\)</span>, etc. On peut ainsi utiliser les intervalles de confiance pour tester l’hypothèse <span class="math inline">\(\mathcal{H}_0: \beta_j=0\)</span> ou de façon équivalente <span class="math inline">\(\mathcal{H}_0: \exp(\beta_j)=1\)</span> à niveau 95%.</p>
</div>
<div id="modèle-avec-toutes-les-variables-explicatives" class="section level3" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Modèle avec toutes les variables explicatives</h3>
<p>Ajustons à présent le modèle avec toutes les variables explicatives. Rappelez-vous que la variable <span class="math inline">\(X_1\)</span> (quel genre d’emploi occupez-vous) a cinq catégories, <span class="math inline">\(X_2\)</span> (revenu familial annuel) a cinq catégories, et <span class="math inline">\(X_6\)</span> (combien de fois avez-vous assisté à un rodéo au cours de la dernière année) a trois catégories. Il faut donc spécifier à <strong>SAS</strong> de les traiter comme des variables catégorielles dans le modèle. Notez qu’on pourrait aussi traiter <span class="math inline">\(X_2\)</span> comme continue car elle est ordinale et possède tout de même cinq modalités, mais on la traitera comme variable nominale.</p>
<pre class="sas"><code>proc logistic data=multi.logit1 ;
class x1(ref=last) x2(ref=last) x6 / param=ref;
model y(ref=&#39;0&#39;) =x1-x6 / clparm=pl clodds=pl expb;
run;</code></pre>
<p>Dans <strong>SAS</strong>, les variables incluses dans la commande <code>class</code> sont modélisées à l’aide d’un ensemble de variables indicatrices. Cette commande nous évite de créer nous-même les indicatrices; cette option est disponible dans la plupart des procédures <strong>SAS</strong>, bien que la procédure <code>reg</code> est une exception notable.</p>
<p>On peut changer la catégorie de référence (<code>ref=</code>) qui est par défaut la dernière modalité (en ordre alphanumérique). L’option <code>param=ref</code> pour <code>class</code> permet d’imprimer un tableau indiquant le code pour les variables indicatrices.
Les variables incluses dans la commande <code>class</code> sont modélisées à l’aide d’un ensemble de variables indicatrices. Prenons l’exemple de la variable <span class="math inline">\(X_1\)</span>: la modalité de référence est (), soit agriculture est spécifiée dans le tableau <code>Informations sur les niveaux de classe</code>.</p>
<p><img src="figures/03-logistic-e9.png" width="75%" style="display: block; margin: auto;" /></p>
<p>Le fichier <code>logit1_intro.sas</code> contient le code pour ajuster le même modèle sans la commande <code>class</code>, c’est-à-dire en créant nous-mêmes les variables indicatrices pour inclure les variables explicatives catégorielles. Vous pouvez l’exécuter afin de vous convaincre qu’il s’agit du même modèle. Les estimés seront les mêmes.</p>
<p><img src="figures/03-logistic-e5.png" width="65%" style="display: block; margin: auto;" />
<img src="figures/03-logistic-e6.png" width="75%" style="display: block; margin: auto;" />
<img src="figures/03-logistic-e7.png" width="90%" style="display: block; margin: auto;" />
<img src="figures/03-logistic-e8.png" width="100%" style="display: block; margin: auto;" />
Le modèle ajusté est
<span class="math display">\[\begin{align*}
 \mathrm{logit}\{{\mathsf P}\left(Y=1 \mid \boldsymbol{X}=\boldsymbol{x}\right)\} &amp;= -6.89 + 0.36{\mathbf 1}_{X_1=1} - 0.47{\mathbf 1}_{X_1=2} - 0.31{\mathbf 1}_{X_1=3} - 0.32{\mathbf 1}_{X_1=4} \\&amp; \qquad 
+ 1.33{\mathbf 1}_{X_2=1} + 1.15{\mathbf 1}_{X_2=2} + 0.77{\mathbf 1}_{X_2=3} - 1.11{\mathbf 1}_{X_2=4} \\&amp;\qquad 
+ 1.35X_3+ 1.83X_4
+ 0.11X_5
+ 2.41{\mathbf 1}_{X_6=1} + 1.04{\mathbf 1}_{X_6=2}
\end{align*}\]</span></p>
<p>Notez que les variables <span class="math inline">\({\mathbf 1}_{X_1=1}\)</span> (<code>x11</code>), <span class="math inline">\({\mathbf 1}_{X_1=21}\)</span> (<code>x12</code>), <span class="math inline">\({\mathbf 1}_{X_1=3}\)</span> (<code>x13</code>) et <span class="math inline">\({\mathbf 1}_{X_1=4}\)</span> (<code>x14</code>) représentent les quatre indicatrices pour la variable <span class="math inline">\(X_1\)</span> (et de même pour <span class="math inline">\(X_2\)</span> et <span class="math inline">\(X_6\)</span>). L’interprétation se fait comme en régression linéaire multiple. Ici, il n’y a pas de terme quadratique, ni d’interaction. Les paramètres estimés représentent donc l’effet de la variable correspondante sur le logit une fois que les autres variables sont dans le modèle, et demeurent fixes.</p>
<p>Prenons le coefficient associé à l’âge (<span class="math inline">\(X_5\)</span>) comme exmple. Le paramètre estimé est <span class="math inline">\(\widehat{\beta}_{\texttt{age}}=0.1095\)</span> et il est significativement différent de zéro. Ainsi, plus l’âge augmente, plus <span class="math inline">\({\mathsf P}\left(Y=1\mid \boldsymbol{X}\right)\)</span> augmente, toutes autres choses étant égales par ailleurs. Pour chaque augmentation d’un an de <span class="math inline">\(X_5\)</span>, la cote est multipliée par <span class="math inline">\(\exp(0.1095)=1.116\)</span>, lorsque les autres variables demeurent fixes.</p>
<p>N’oubliez pas la nuance suivante concernant l’interprétation d’un test lorsque plusieurs variables explicatives font partie du modèle. Si un paramètre n’est pas significativement différent de zéro, cela ne veut pas dire qu’il n’y a pas de lien entre la variable correspondante et <span class="math inline">\(Y\)</span>. Cela veut seulement dire qu’il n’y a pas de lien significatif une fois que les autres variables sont dans le modèle.</p>
<p>Prenons l’exemple de la variable <span class="math inline">\(X_6\)</span>, qui représente le nombre de fois où l’individu a assisté à un rodéo au cours de la dernière année. Cette variable est modélisée à l’aide de deux variables indicatrices, <span class="math inline">\({\mathbf 1}_{X_6=1}\)</span> égale à un si <span class="math inline">\(X_6=1\)</span> et zéro autrement, et <span class="math inline">\({\mathbf 1}_{X_6=2}\)</span> égale à un si <span class="math inline">\(X_6=2\)</span> et zéro sinon. La catégorie de référence est <span class="math inline">\(X_6=3\)</span>, c’est-à-dire les personnes ayant assisté cinq fois ou moins à un rodéo au cours de la dernière année. Pour tester la significativité globale d’une variable catégorielle qui est modélisée avec plusieurs indicatrices, il faut aller dans le tableau <code>Analyse des effets Type 3</code>. On voit que la statistique de test est <span class="math inline">\(42.9364\)</span> et que la valeur-<span class="math inline">\(p\)</span> associée est négligeable: la variable <span class="math inline">\(X_6\)</span> est donc globalement significative. En fait, il s’agit du test conjoint sur toutes les indicatrices associées à cette variable. Plus précisément, il s’agit du test de l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0: \beta_{6_{\texttt{1}}}=\beta_{6_{\texttt{2}}}=0\)</span> versus la contre-hypothèse qu’au moins un de ces deux paramètres est différent de zéro.</p>
<p>L’interprétation des variables catégorielles est analogue à celle faite en régression linéaire. On peut aussi interpréter individuellement les paramètres des indicatrices: pour <span class="math inline">\({\mathbf 1}_{X_6=1}\)</span>, lorsque les autres variables demeurent fixes, les personnes ayant assisté 10 fois ou plus à un rodéo au cours de la dernière année voient leur cote multipliée par <span class="math inline">\(\exp(2.4122)=11.158\)</span> par rapport aux personnes ayant assisté cinq fois ou moins. Ce paramètre est significativement différent de zéro car sa valeur-<span class="math inline">\(p\)</span> est négligeable (tableau <code>Analyse des valeurs estimées du maximum de vraisemblance</code>); l’intervalle de confiance à 95% pour le rapport de cotes, basé sur la vraisemblance profilée, est [<span class="math inline">\(5.456; 23.882\)</span>] et un n’est pas dans l’intervalle. Ainsi, il y a une différence significative entre les gens qui ont assisté à 10 rodéos ou plus et les gens qui ont assisté à 5 rodéos ou moins, pour ce qui est de l’intérêt à acheter un produit recommandé par le PRCA.</p>
<p>On procède de la même façon pour <span class="math inline">\({\mathbf 1}_{X_6=2}\)</span>: lorsque les autres variables demeurent fixes, les personnes ayant assisté entre six et neuf fois à un rodéo au cours de la dernière année voient leur cote multipliée par <span class="math inline">\(2,842\)</span> par rapport aux personnes ayant assisté cinq fois ou moins. Ce paramètre est aussi significativement différent de zéro. Il y a donc une progression. Plus une personne a assisté à un grand nombre de rodéo au cours de la dernière année, plus elle est intéressée à acheter un produit recommandé par la PRCA.</p>
<p>Si on désire comparer les deux modalités <span class="math inline">\(X_6=1\)</span> et <span class="math inline">\(X_6=2\)</span>, il suffit de changer la modalité de référence dans la commande <code>class</code> et d’exécuter le modèle à nouveau. Une alternative est de calculer le rapport (de rapport) de cotes pour ces deux modalités.</p>
</div>
<div id="test-du-rapport-de-vraisemblance" class="section level3" number="5.4.4">
<h3><span class="header-section-number">5.4.4</span> Test du rapport de vraisemblance</h3>
<p>Les tests correspondants aux valeurs-<span class="math inline">\(p\)</span> dans le tableau des paramètres sont des tests de Wald. Ces tests feront l’affaire dans la plupart des applications. Par contre, il existe un autre test qui est généralement plus puissant, c’est-à-dire qu’il sera meilleur pour détecter que <span class="math inline">\(\mathcal{H}_0\)</span> n’est pas vraie lorsque c’est effectivement le cas. Ce test est le test du rapport de vraisemblance (<em>likelihood ratio test</em>). Il découle de la méthode d’estimation du maximum de vraisemblance et est donc généralement applicable lorsqu’on estime les paramètres avec cette méthode. Il est basé sur la quantité <span class="math inline">\(\ell\)</span> que nous avons vue plus tôt.</p>
<p>La procédure consiste à ajuster deux modèles <strong>emboîtés</strong>:</p>
<ul>
<li>Le premier modèle, le modèle complet, contient tous les paramètres et l’estimateur du maximum de vraisemblance <span class="math inline">\(\widehat{\boldsymbol{\beta}})\)</span>.</li>
<li>Le deuxième modèle correspondant à l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span>, le modèle réduit, contient tous les paramètres avec les restrictions imposées sous <span class="math inline">\(\mathcal{H}_0\)</span>; on dénote l’estimateur du maximum de vraisemblance <span class="math inline">\(\widehat{\boldsymbol{\beta}}_0\)</span></li>
</ul>
<p>Le test est basé sur la statistique
<span class="math display">\[\begin{align*}
 D = -2\{\ell(\widehat{\boldsymbol{\beta}}_0)-\ell(\widehat{\boldsymbol{\beta}})\}
\end{align*}\]</span>
ou la différence entre <code>-2 Log L</code> pour le modèle réduit et <code>-2 Log L</code> pour le modèle complet. Cette différence <span class="math inline">\(D\)</span>, lorsque l’hypothèse <span class="math inline">\(\mathcal{H}_0\)</span> est vraie suit approximativement une loi khi-deux avec un nombre de degrés de liberté égal au nombre de paramètre testé (le nombre de restrictions sous <span class="math inline">\(\mathcal{H}_0\)</span>). On peut donc calculer la valeur-<span class="math inline">\(p\)</span> en utilisant la distribution du khi-deux.</p>
<p>Prenons comme exemple le test de la significativité de <span class="math inline">\(X_6\)</span>, qui est modélisée à l’aide deux variables binaires <span class="math inline">\({\mathbf 1}_{X_6=1}\)</span> et <span class="math inline">\({\mathbf 1}_{X_6=2}\)</span> et dont les paramètres correspondants sont <span class="math inline">\(\beta_{6_{\texttt{1}}}\)</span> et <span class="math inline">\(\beta_{6_{\texttt{2}}}\)</span>. Nous avons déjà étudié la sortie pour le test de Wald de significativité globale de <span class="math inline">\(X_6\)</span>, soit le test de l’hypothèse <span class="math inline">\(\mathcal{H}_0: \beta_{6_{\texttt{1}}}=\beta_{6_{\texttt{2}}}=0\)</span> versus l’alternative qu’au moins un de ces deux paramètres est différent de zéro. La statistique de test (de Wald) est <span class="math inline">\(42.93\)</span> et la valeur-<span class="math inline">\(p\)</span> est moins de <span class="math inline">\(10^{-4}\)</span>. Pour effectuer le test du rapport de vraisemblance, il suffit de retirer la variable <span class="math inline">\(X_6\)</span> et de réajuster le modèle à nouveau avec toutes les autres variables; cette manipulation est effectuée dans <code>logit1_intro.sas</code>. On obtient donc
<code>-2 Log L</code> de 516,196 pour le modèle complet sans contrainte et <span class="math inline">\(566.447\)</span> pour le modèle excluant la variable <span class="math inline">\(X_6\)</span>.</p>
<p>La différence <span class="math inline">\(D = 566.447 - 516.196 = 50.25\)</span>. Il s’agit de la statistique du test de rapport de vraisemblance. La valeur-<span class="math inline">\(p\)</span> peut-être obtenue de la loi du khi-deux avec 2 degrés de liberté via le code suivant permet d’imprimer la valeur-<span class="math inline">\(p\)</span>, qui est <span class="math inline">\(1.22 \times 10^{-11}\)</span>.</p>
<pre class="sas"><code>data pval;
pval=1-CDF(&#39;CHISQ&#39;, 566.447 - 516.196, 2);
run;
proc print data=pval;
run;</code></pre>
<p>Comme la statistique du test de rapport de vraisemblance <span class="math inline">\(D=50.25\)</span> est encore plus grande est encore plus grande que la statistique de Wald (<span class="math inline">\(42.9364\)</span>), qui suit la même loi de probabilité sous <span class="math inline">\(\mathcal{H}_0\)</span>, cela indique que le test du rapport de vraisemblance est encore plus significatif que le test de Wald. Cela ne fait pas de différence ici mais, dans certains cas, il est possible que le test de Wald ne soit pas significatif (valeur-<span class="math inline">\(p\)</span> plus grande que <span class="math inline">\(0.05\)</span>) tandis que le test du rapport de vraisemblance le soit (valeur-<span class="math inline">\(p\)</span> inférieure à <span class="math inline">\(0.05\)</span>).</p>
</div>
<div id="multicolinéarité" class="section level3" number="5.4.5">
<h3><span class="header-section-number">5.4.5</span> Multicolinéarité</h3>
<p>Rappelez-vous que le terme multicolinéarité fait référence à la situation où les variables explicatives sont très corrélées entre elles ou bien, plus généralement, à la situation où une (ou plusieurs) variable(s) explicative(s) est (sont) très corrélée(s) à une combinaison linéaire des autres variables explicatives.</p>
<p>L’effet potentiellement néfaste de la multicolinéarité est le même qu’en régression linéaire, c’est-à-dire, elle peut réduire la précision des estimations des paramètres (augmenter leurs écarts-types estimés).</p>
<p>En pratique, le problème est qu’il devient difficile de départager l’effet individuel d’une variable explicative lorsqu’elle est fortement corrélée avec d’autres variables explicatives.</p>
<p>Comme la multicolinéarité est une propriété des variables explicatives (le <span class="math inline">\(Y\)</span> n’intervient pas) on peut utiliser les mêmes outils qu’en régression linéaire pour tenter de la détecter, par exemple, le facteur d’inflation de la variance (<em>variance inflation factor</em>). Cette quantité ne dépend que des variables explicatives <span class="math inline">\(\boldsymbol{X}\)</span>, pas du modèle ou de la variable réponse.</p>
<p>La multicolinéarité est surtout un problème lorsque vient le temps d’interpréter et tester l’effet des paramètres individuels. Si le but est seulement de faire de la classification (prédiction) et que l’interprétation des paramètres individuels n’est pas cruciale alors il n’y a pas lieu de se soucier de la multicolinéarité. Il faut alors plutôt comparer correctement la performance de classification des modèles en utilisant des méthodes permettant d’obtenir un bon modèle tout en se protégeant contre le surajustement. Certaines de ces méthodes (division de l’échantillon, validation croisée) ont déjà été présentées.</p>
</div>
</div>
<div id="classification-et-prédiction-à-laide-de-la-régression-logistique" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Classification et prédiction à l’aide de la régression logistique</h2>
<p>La finalité du modèle de régression logistique est fréquemment l’obtention de prédictions. Une fois qu’on a ajusté un modèle, on peut l’utiliser pour prévoir la valeur de <span class="math inline">\(Y\)</span> pour de nouvelles observations. Ceci consiste à assigner une classe (<span class="math inline">\(0\)</span> ou <span class="math inline">\(1\)</span>) à ces observations (pour lesquels <span class="math inline">\(Y\)</span> est inconnue) à partir des valeurs prises par <span class="math inline">\(X_1, \ldots, X_p\)</span>.</p>
<p>Le modèle ajusté nous fournit une estimation de <span class="math inline">\({\mathsf P}\left(Y=1 \mid \boldsymbol{X}=\boldsymbol{x}\right)\)</span> pour des valeurs <span class="math inline">\(X_1=x_1, \ldots, X_p=x_p\)</span> données. Cet estimé est
<span class="math display">\[\begin{align*}
 \widehat{p} = \frac{1}{1+ \exp\{- ( \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \cdots + \widehat{\beta}_p x_p)\}}.
\end{align*}\]</span></p>
<p>Classification de base: pour classifier des observations, il suffit de choisir un point de coupure <span class="math inline">\(c\)</span>, souvent <span class="math inline">\(c=0,5\)</span>, et de classifier une observation de la manière suivante:</p>
<ul>
<li>Si <span class="math inline">\(\widehat{p} &lt; c\)</span>, on assigne cette observation à la catégorie zéro et <span class="math inline">\(\widehat{Y}=0\)</span>.</li>
<li>Si <span class="math inline">\(\widehat{p} \geq c\)</span>, on assigne cette observation à la catégorie un et <span class="math inline">\(\widehat{Y}=1\)</span>.</li>
</ul>
<p>Si on prend <span class="math inline">\(c=0,5\)</span> comme point de coupure, cela revient à assigner l’observation à la classe (catégorie) la plus probable, un choix fort raisonnable. Nous verrons dans une section suivante que, lorsque les conséquences de faussement classifier une observation (succès, mais échec prédit et vice-versa) ne sont pas les mêmes, il peut être avantageux d’utiliser un autre point de coupure.</p>
<p>Dans un cadre de prédiction, il nous faudra un critère pour juger de la qualité de l’ajustement du modèle.
Rappelez-vous que pour une réponse continue, nous avons utilisé l’erreur moyenne quadratique,
<span class="math inline">\(\mathsf{EMQ} = \mathsf{E}\{(Y-\widehat{Y})^2\}\)</span>,
pour juger de la performance d’un modèle. Comme la réponse <span class="math inline">\(Y\)</span> est binaire ici, nous allons utiliser des critères différents.</p>
<p>Voyons d’abord un premier critère pour juger de la qualité d’un modèle de prédiction. Soit <span class="math inline">\(Y\)</span> la vraie valeur de la réponse binaire et <span class="math inline">\(\widehat{Y}\)</span> (soit 0 ou 1) la valeur de <span class="math inline">\(Y\)</span> prédite par un modèle pour une observation choisie au hasard dans la population. Un premier critère pour juger de la performance d’un modèle est <span class="math inline">\({\mathsf P}\left(Y \neq\widehat{Y}\right)\)</span>, soit la probabilité de mal classifier une observation choisie au hasard dans
la population. Ce critère est le <strong>taux de mauvaise classification</strong>. Plus <span class="math inline">\({\mathsf P}\left(Y \neq\widehat{Y}\right)\)</span> est petite, meilleure est la capacité prédictive du modèle.</p>
<p>Tout comme l’erreur moyenne quadratique, on ne peut pas calculer exactement le taux de mauvaise classification; tout au plus peut-on l’estimer. Pour les raisons vues au chapitre précédent, l’estimer en
calculant le taux de mauvaise classification des observations ayant servi à
l’ajustement du modèle sans aucune correction n’est pas une bonne approche.
Les approches couvertes dans le dernier chapitre pour l’estimation de l’erreur moyenne quadratique, telles la validation-croisée et la
division de l’échantillon, peuvent être utilisées pour estimer le taux de mauvaise classification <span class="math inline">\({\mathsf P}\left(Y \neq \widehat{Y}\right)\)</span>.</p>
<p>Cette utilisation d’un modèle de régression logistique sera illustrée avec l’exemple que nous avons traité au chapitre précédent: notre objectif final est de construire un modèle avec les 1000 clients de l’échantillon d’apprentissage et cibler ensuite lesquels des 100 000 clients restants seront choisis pour recevoir le catalogue. Les variables cibles sont:</p>
<ul>
<li><code>yachat</code>: variable binaire égale à un si le client a acheté quelque chose dans le catalogue et zéro sinon.</li>
<li><code>ymontant</code>: le montant de l’achat si le client a acheté quelque chose</li>
</ul>
<p>Les 10 variables suivantes sont disponibles pour tous les clients et serviront de variables explicatives,</p>
<ul>
<li><code>x1</code>: sexe de l’individu, soit homme (0) ou femme (1);</li>
<li><code>x2</code>: l’âge (en année);</li>
<li><code>x3</code>: variable catégorielle indiquant le revenu, soit moins de 35 000$ (1), entre 35 000$ et 75 000$ (2) ou plus de 75 000$ (3);</li>
<li><code>x4</code>: variable catégorielle indiquant la région où habite le client (de 1 à 5);</li>
<li><code>x5</code>: conjoint : le client a-t-il un conjoint, soit oui (1) ou non (0);</li>
<li><code>x6</code>: nombre d’année depuis que le client est avec la compagnie;</li>
<li><code>x7</code>: nombre de semaines depuis le dernier achat;</li>
<li><code>x8</code>: montant (en dollars) du dernier achat;</li>
<li><code>x9</code>: montant total (en dollars) dépensé depuis un an;</li>
<li><code>x10</code>: nombre d’achats différents depuis un an.</li>
</ul>
<p>Dans le chapitre précédent, nous avons cherché à développer un modèle pour prévoir <code>ymontant</code>, le montant dépensé, étant donné que le client achète quelque chose. Cette fois-ci, nous allons travailler avec la variable <code>yachat</code>, qui est binaire, à l’aide de la régression logistique.</p>
<p>Afin d’introduire différentes notions, nous allons, dans un premier temps, utiliser les 10 variables de base. À partir de la section suivante, nous chercherons à optimiser le modèle en considérant les interactions d’ordre deux. Pour ce faire, nous utiliserons des méthodes de sélections de variables. Les commandes se trouvent dans le fichier <code>logit2_classification_base.sas</code>. Dans le code qui suit, le fichier <code>train</code> contient les 1000 clients de l’échantillon d’apprentissage et le fichier <code>test</code> contient les 100 000 clients pour lesquels on veut prédire l’intention d’achat.</p>
<pre class="sas"><code>proc logistic data=train;
model yachat(ref=&#39;0&#39;) = x1x2 x3 x32 x41-x44 x5-x10;
output out=pred predprobs=crossvalidate;
run;</code></pre>
<p>Le modèle utilise seulement les 10 variables de base (en fait 14 avec les indicatrices pour les variables catégorielles). Des prévisions pour les clients restants seront exportées dans le fichier <code>pred</code>, grâce à la commande <code>score</code>. L’option <code>ctable</code> permet d’obtenir la <code>Table de classification</code> (sic). Tel que nous l’avons vu au chapitre précédent, il y a 210 clients qui ont acheté quelque chose parmi les 1000. Le tableau de classification contient des estimations de plusieurs quantités intéressantes, en faisant varier le point de coupure (<code>Niveau de proba</code>). Pour chaque point de coupure, ces estimations ont été obtenues à l’aide d’une approximation de la méthode de validation croisée à <span class="math inline">\(n\)</span> groupes (en anglais, <em>leave-one-out cross-validation</em>, ou LOOCV). Ainsi, ces estimations sont valides car elles ne sont pas obtenues en utilisant les mêmes observations que celles qui ont servi à estimer le modèle.</p>
<p><img src="MATH60602_files/figure-html/classification0-1.png" width="70%" style="display: block; margin: auto;" /></p>
<table>
<thead>
<tr>
<th style="text-align:right;">
coupe
</th>
<th style="text-align:right;">
VP
</th>
<th style="text-align:right;">
VN
</th>
<th style="text-align:right;">
FP
</th>
<th style="text-align:right;">
FN
</th>
<th style="text-align:right;">
correct (%)
</th>
<th style="text-align:right;">
sensibilité (%)
</th>
<th style="text-align:right;">
spécificité (%)
</th>
<th style="text-align:right;">
FP (%)
</th>
<th style="text-align:right;">
FN (%)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.02
</td>
<td style="text-align:right;">
210
</td>
<td style="text-align:right;">
209
</td>
<td style="text-align:right;">
581
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
41.9
</td>
<td style="text-align:right;">
100.0
</td>
<td style="text-align:right;">
26.5
</td>
<td style="text-align:right;">
73.5
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
207
</td>
<td style="text-align:right;">
320
</td>
<td style="text-align:right;">
470
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
52.7
</td>
<td style="text-align:right;">
98.6
</td>
<td style="text-align:right;">
40.5
</td>
<td style="text-align:right;">
69.4
</td>
<td style="text-align:right;">
0.9
</td>
</tr>
<tr>
<td style="text-align:right;">
0.06
</td>
<td style="text-align:right;">
201
</td>
<td style="text-align:right;">
398
</td>
<td style="text-align:right;">
392
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
59.9
</td>
<td style="text-align:right;">
95.7
</td>
<td style="text-align:right;">
50.4
</td>
<td style="text-align:right;">
66.1
</td>
<td style="text-align:right;">
2.2
</td>
</tr>
<tr>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
199
</td>
<td style="text-align:right;">
451
</td>
<td style="text-align:right;">
339
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
65.0
</td>
<td style="text-align:right;">
94.8
</td>
<td style="text-align:right;">
57.1
</td>
<td style="text-align:right;">
63.0
</td>
<td style="text-align:right;">
2.4
</td>
</tr>
<tr>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
193
</td>
<td style="text-align:right;">
480
</td>
<td style="text-align:right;">
310
</td>
<td style="text-align:right;">
17
</td>
<td style="text-align:right;">
67.3
</td>
<td style="text-align:right;">
91.9
</td>
<td style="text-align:right;">
60.8
</td>
<td style="text-align:right;">
61.6
</td>
<td style="text-align:right;">
3.4
</td>
</tr>
<tr>
<td style="text-align:right;">
0.12
</td>
<td style="text-align:right;">
191
</td>
<td style="text-align:right;">
512
</td>
<td style="text-align:right;">
278
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
70.3
</td>
<td style="text-align:right;">
91.0
</td>
<td style="text-align:right;">
64.8
</td>
<td style="text-align:right;">
59.3
</td>
<td style="text-align:right;">
3.6
</td>
</tr>
<tr>
<td style="text-align:right;">
0.14
</td>
<td style="text-align:right;">
184
</td>
<td style="text-align:right;">
547
</td>
<td style="text-align:right;">
243
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
73.1
</td>
<td style="text-align:right;">
87.6
</td>
<td style="text-align:right;">
69.2
</td>
<td style="text-align:right;">
56.9
</td>
<td style="text-align:right;">
4.5
</td>
</tr>
<tr>
<td style="text-align:right;">
0.16
</td>
<td style="text-align:right;">
176
</td>
<td style="text-align:right;">
572
</td>
<td style="text-align:right;">
218
</td>
<td style="text-align:right;">
34
</td>
<td style="text-align:right;">
74.8
</td>
<td style="text-align:right;">
83.8
</td>
<td style="text-align:right;">
72.4
</td>
<td style="text-align:right;">
55.3
</td>
<td style="text-align:right;">
5.6
</td>
</tr>
<tr>
<td style="text-align:right;">
0.18
</td>
<td style="text-align:right;">
172
</td>
<td style="text-align:right;">
598
</td>
<td style="text-align:right;">
192
</td>
<td style="text-align:right;">
38
</td>
<td style="text-align:right;">
77.0
</td>
<td style="text-align:right;">
81.9
</td>
<td style="text-align:right;">
75.7
</td>
<td style="text-align:right;">
52.7
</td>
<td style="text-align:right;">
6.0
</td>
</tr>
<tr>
<td style="text-align:right;">
0.20
</td>
<td style="text-align:right;">
164
</td>
<td style="text-align:right;">
611
</td>
<td style="text-align:right;">
179
</td>
<td style="text-align:right;">
46
</td>
<td style="text-align:right;">
77.5
</td>
<td style="text-align:right;">
78.1
</td>
<td style="text-align:right;">
77.3
</td>
<td style="text-align:right;">
52.2
</td>
<td style="text-align:right;">
7.0
</td>
</tr>
<tr>
<td style="text-align:right;">
0.22
</td>
<td style="text-align:right;">
162
</td>
<td style="text-align:right;">
626
</td>
<td style="text-align:right;">
164
</td>
<td style="text-align:right;">
48
</td>
<td style="text-align:right;">
78.8
</td>
<td style="text-align:right;">
77.1
</td>
<td style="text-align:right;">
79.2
</td>
<td style="text-align:right;">
50.3
</td>
<td style="text-align:right;">
7.1
</td>
</tr>
<tr>
<td style="text-align:right;">
0.24
</td>
<td style="text-align:right;">
158
</td>
<td style="text-align:right;">
639
</td>
<td style="text-align:right;">
151
</td>
<td style="text-align:right;">
52
</td>
<td style="text-align:right;">
79.7
</td>
<td style="text-align:right;">
75.2
</td>
<td style="text-align:right;">
80.9
</td>
<td style="text-align:right;">
48.9
</td>
<td style="text-align:right;">
7.5
</td>
</tr>
<tr>
<td style="text-align:right;">
0.26
</td>
<td style="text-align:right;">
153
</td>
<td style="text-align:right;">
645
</td>
<td style="text-align:right;">
145
</td>
<td style="text-align:right;">
57
</td>
<td style="text-align:right;">
79.8
</td>
<td style="text-align:right;">
72.9
</td>
<td style="text-align:right;">
81.6
</td>
<td style="text-align:right;">
48.7
</td>
<td style="text-align:right;">
8.1
</td>
</tr>
<tr>
<td style="text-align:right;">
0.28
</td>
<td style="text-align:right;">
150
</td>
<td style="text-align:right;">
657
</td>
<td style="text-align:right;">
133
</td>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
80.7
</td>
<td style="text-align:right;">
71.4
</td>
<td style="text-align:right;">
83.2
</td>
<td style="text-align:right;">
47.0
</td>
<td style="text-align:right;">
8.4
</td>
</tr>
<tr>
<td style="text-align:right;">
0.30
</td>
<td style="text-align:right;">
143
</td>
<td style="text-align:right;">
667
</td>
<td style="text-align:right;">
123
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:right;">
81.0
</td>
<td style="text-align:right;">
68.1
</td>
<td style="text-align:right;">
84.4
</td>
<td style="text-align:right;">
46.2
</td>
<td style="text-align:right;">
9.1
</td>
</tr>
<tr>
<td style="text-align:right;">
0.32
</td>
<td style="text-align:right;">
138
</td>
<td style="text-align:right;">
679
</td>
<td style="text-align:right;">
111
</td>
<td style="text-align:right;">
72
</td>
<td style="text-align:right;">
81.7
</td>
<td style="text-align:right;">
65.7
</td>
<td style="text-align:right;">
85.9
</td>
<td style="text-align:right;">
44.6
</td>
<td style="text-align:right;">
9.6
</td>
</tr>
<tr>
<td style="text-align:right;">
0.34
</td>
<td style="text-align:right;">
134
</td>
<td style="text-align:right;">
695
</td>
<td style="text-align:right;">
95
</td>
<td style="text-align:right;">
76
</td>
<td style="text-align:right;">
82.9
</td>
<td style="text-align:right;">
63.8
</td>
<td style="text-align:right;">
88.0
</td>
<td style="text-align:right;">
41.5
</td>
<td style="text-align:right;">
9.9
</td>
</tr>
<tr>
<td style="text-align:right;">
0.36
</td>
<td style="text-align:right;">
130
</td>
<td style="text-align:right;">
699
</td>
<td style="text-align:right;">
91
</td>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
82.9
</td>
<td style="text-align:right;">
61.9
</td>
<td style="text-align:right;">
88.5
</td>
<td style="text-align:right;">
41.2
</td>
<td style="text-align:right;">
10.3
</td>
</tr>
<tr>
<td style="text-align:right;">
0.38
</td>
<td style="text-align:right;">
126
</td>
<td style="text-align:right;">
708
</td>
<td style="text-align:right;">
82
</td>
<td style="text-align:right;">
84
</td>
<td style="text-align:right;">
83.4
</td>
<td style="text-align:right;">
60.0
</td>
<td style="text-align:right;">
89.6
</td>
<td style="text-align:right;">
39.4
</td>
<td style="text-align:right;">
10.6
</td>
</tr>
<tr>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
715
</td>
<td style="text-align:right;">
75
</td>
<td style="text-align:right;">
90
</td>
<td style="text-align:right;">
83.5
</td>
<td style="text-align:right;">
57.1
</td>
<td style="text-align:right;">
90.5
</td>
<td style="text-align:right;">
38.5
</td>
<td style="text-align:right;">
11.2
</td>
</tr>
<tr>
<td style="text-align:right;">
0.42
</td>
<td style="text-align:right;">
115
</td>
<td style="text-align:right;">
723
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:right;">
95
</td>
<td style="text-align:right;">
83.8
</td>
<td style="text-align:right;">
54.8
</td>
<td style="text-align:right;">
91.5
</td>
<td style="text-align:right;">
36.8
</td>
<td style="text-align:right;">
11.6
</td>
</tr>
<tr>
<td style="text-align:right;">
0.44
</td>
<td style="text-align:right;">
112
</td>
<td style="text-align:right;">
731
</td>
<td style="text-align:right;">
59
</td>
<td style="text-align:right;">
98
</td>
<td style="text-align:right;">
84.3
</td>
<td style="text-align:right;">
53.3
</td>
<td style="text-align:right;">
92.5
</td>
<td style="text-align:right;">
34.5
</td>
<td style="text-align:right;">
11.8
</td>
</tr>
<tr>
<td style="text-align:right;">
0.46
</td>
<td style="text-align:right;">
109
</td>
<td style="text-align:right;">
736
</td>
<td style="text-align:right;">
54
</td>
<td style="text-align:right;">
101
</td>
<td style="text-align:right;">
84.5
</td>
<td style="text-align:right;">
51.9
</td>
<td style="text-align:right;">
93.2
</td>
<td style="text-align:right;">
33.1
</td>
<td style="text-align:right;">
12.1
</td>
</tr>
<tr>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
106
</td>
<td style="text-align:right;">
739
</td>
<td style="text-align:right;">
51
</td>
<td style="text-align:right;">
104
</td>
<td style="text-align:right;">
84.5
</td>
<td style="text-align:right;">
50.5
</td>
<td style="text-align:right;">
93.5
</td>
<td style="text-align:right;">
32.5
</td>
<td style="text-align:right;">
12.3
</td>
</tr>
<tr>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
744
</td>
<td style="text-align:right;">
46
</td>
<td style="text-align:right;">
110
</td>
<td style="text-align:right;">
84.4
</td>
<td style="text-align:right;">
47.6
</td>
<td style="text-align:right;">
94.2
</td>
<td style="text-align:right;">
31.5
</td>
<td style="text-align:right;">
12.9
</td>
</tr>
<tr>
<td style="text-align:right;">
0.52
</td>
<td style="text-align:right;">
98
</td>
<td style="text-align:right;">
748
</td>
<td style="text-align:right;">
42
</td>
<td style="text-align:right;">
112
</td>
<td style="text-align:right;">
84.6
</td>
<td style="text-align:right;">
46.7
</td>
<td style="text-align:right;">
94.7
</td>
<td style="text-align:right;">
30.0
</td>
<td style="text-align:right;">
13.0
</td>
</tr>
<tr>
<td style="text-align:right;">
0.54
</td>
<td style="text-align:right;">
92
</td>
<td style="text-align:right;">
750
</td>
<td style="text-align:right;">
40
</td>
<td style="text-align:right;">
118
</td>
<td style="text-align:right;">
84.2
</td>
<td style="text-align:right;">
43.8
</td>
<td style="text-align:right;">
94.9
</td>
<td style="text-align:right;">
30.3
</td>
<td style="text-align:right;">
13.6
</td>
</tr>
<tr>
<td style="text-align:right;">
0.56
</td>
<td style="text-align:right;">
87
</td>
<td style="text-align:right;">
753
</td>
<td style="text-align:right;">
37
</td>
<td style="text-align:right;">
123
</td>
<td style="text-align:right;">
84.0
</td>
<td style="text-align:right;">
41.4
</td>
<td style="text-align:right;">
95.3
</td>
<td style="text-align:right;">
29.8
</td>
<td style="text-align:right;">
14.0
</td>
</tr>
<tr>
<td style="text-align:right;">
0.58
</td>
<td style="text-align:right;">
83
</td>
<td style="text-align:right;">
761
</td>
<td style="text-align:right;">
29
</td>
<td style="text-align:right;">
127
</td>
<td style="text-align:right;">
84.4
</td>
<td style="text-align:right;">
39.5
</td>
<td style="text-align:right;">
96.3
</td>
<td style="text-align:right;">
25.9
</td>
<td style="text-align:right;">
14.3
</td>
</tr>
<tr>
<td style="text-align:right;">
0.60
</td>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
766
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
130
</td>
<td style="text-align:right;">
84.6
</td>
<td style="text-align:right;">
38.1
</td>
<td style="text-align:right;">
97.0
</td>
<td style="text-align:right;">
23.1
</td>
<td style="text-align:right;">
14.5
</td>
</tr>
<tr>
<td style="text-align:right;">
0.62
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
769
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:right;">
133
</td>
<td style="text-align:right;">
84.6
</td>
<td style="text-align:right;">
36.7
</td>
<td style="text-align:right;">
97.3
</td>
<td style="text-align:right;">
21.4
</td>
<td style="text-align:right;">
14.7
</td>
</tr>
<tr>
<td style="text-align:right;">
0.64
</td>
<td style="text-align:right;">
74
</td>
<td style="text-align:right;">
771
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
136
</td>
<td style="text-align:right;">
84.5
</td>
<td style="text-align:right;">
35.2
</td>
<td style="text-align:right;">
97.6
</td>
<td style="text-align:right;">
20.4
</td>
<td style="text-align:right;">
15.0
</td>
</tr>
<tr>
<td style="text-align:right;">
0.66
</td>
<td style="text-align:right;">
68
</td>
<td style="text-align:right;">
772
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
142
</td>
<td style="text-align:right;">
84.0
</td>
<td style="text-align:right;">
32.4
</td>
<td style="text-align:right;">
97.7
</td>
<td style="text-align:right;">
20.9
</td>
<td style="text-align:right;">
15.5
</td>
</tr>
<tr>
<td style="text-align:right;">
0.68
</td>
<td style="text-align:right;">
62
</td>
<td style="text-align:right;">
774
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:right;">
148
</td>
<td style="text-align:right;">
83.6
</td>
<td style="text-align:right;">
29.5
</td>
<td style="text-align:right;">
98.0
</td>
<td style="text-align:right;">
20.5
</td>
<td style="text-align:right;">
16.1
</td>
</tr>
<tr>
<td style="text-align:right;">
0.70
</td>
<td style="text-align:right;">
54
</td>
<td style="text-align:right;">
775
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
156
</td>
<td style="text-align:right;">
82.9
</td>
<td style="text-align:right;">
25.7
</td>
<td style="text-align:right;">
98.1
</td>
<td style="text-align:right;">
21.7
</td>
<td style="text-align:right;">
16.8
</td>
</tr>
<tr>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
51
</td>
<td style="text-align:right;">
777
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
159
</td>
<td style="text-align:right;">
82.8
</td>
<td style="text-align:right;">
24.3
</td>
<td style="text-align:right;">
98.4
</td>
<td style="text-align:right;">
20.3
</td>
<td style="text-align:right;">
17.0
</td>
</tr>
<tr>
<td style="text-align:right;">
0.74
</td>
<td style="text-align:right;">
49
</td>
<td style="text-align:right;">
778
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
161
</td>
<td style="text-align:right;">
82.7
</td>
<td style="text-align:right;">
23.3
</td>
<td style="text-align:right;">
98.5
</td>
<td style="text-align:right;">
19.7
</td>
<td style="text-align:right;">
17.1
</td>
</tr>
<tr>
<td style="text-align:right;">
0.76
</td>
<td style="text-align:right;">
46
</td>
<td style="text-align:right;">
778
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
164
</td>
<td style="text-align:right;">
82.4
</td>
<td style="text-align:right;">
21.9
</td>
<td style="text-align:right;">
98.5
</td>
<td style="text-align:right;">
20.7
</td>
<td style="text-align:right;">
17.4
</td>
</tr>
<tr>
<td style="text-align:right;">
0.78
</td>
<td style="text-align:right;">
41
</td>
<td style="text-align:right;">
781
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
169
</td>
<td style="text-align:right;">
82.2
</td>
<td style="text-align:right;">
19.5
</td>
<td style="text-align:right;">
98.9
</td>
<td style="text-align:right;">
18.0
</td>
<td style="text-align:right;">
17.8
</td>
</tr>
<tr>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
35
</td>
<td style="text-align:right;">
783
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
175
</td>
<td style="text-align:right;">
81.8
</td>
<td style="text-align:right;">
16.7
</td>
<td style="text-align:right;">
99.1
</td>
<td style="text-align:right;">
16.7
</td>
<td style="text-align:right;">
18.3
</td>
</tr>
<tr>
<td style="text-align:right;">
0.82
</td>
<td style="text-align:right;">
33
</td>
<td style="text-align:right;">
783
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
177
</td>
<td style="text-align:right;">
81.6
</td>
<td style="text-align:right;">
15.7
</td>
<td style="text-align:right;">
99.1
</td>
<td style="text-align:right;">
17.5
</td>
<td style="text-align:right;">
18.4
</td>
</tr>
<tr>
<td style="text-align:right;">
0.84
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
783
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
178
</td>
<td style="text-align:right;">
81.5
</td>
<td style="text-align:right;">
15.2
</td>
<td style="text-align:right;">
99.1
</td>
<td style="text-align:right;">
17.9
</td>
<td style="text-align:right;">
18.5
</td>
</tr>
<tr>
<td style="text-align:right;">
0.86
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:right;">
784
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
182
</td>
<td style="text-align:right;">
81.2
</td>
<td style="text-align:right;">
13.3
</td>
<td style="text-align:right;">
99.2
</td>
<td style="text-align:right;">
17.6
</td>
<td style="text-align:right;">
18.8
</td>
</tr>
<tr>
<td style="text-align:right;">
0.88
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
786
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
185
</td>
<td style="text-align:right;">
81.1
</td>
<td style="text-align:right;">
11.9
</td>
<td style="text-align:right;">
99.5
</td>
<td style="text-align:right;">
13.8
</td>
<td style="text-align:right;">
19.1
</td>
</tr>
<tr>
<td style="text-align:right;">
0.90
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:right;">
787
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
189
</td>
<td style="text-align:right;">
80.8
</td>
<td style="text-align:right;">
10.0
</td>
<td style="text-align:right;">
99.6
</td>
<td style="text-align:right;">
12.5
</td>
<td style="text-align:right;">
19.4
</td>
</tr>
<tr>
<td style="text-align:right;">
0.92
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
787
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
192
</td>
<td style="text-align:right;">
80.5
</td>
<td style="text-align:right;">
8.6
</td>
<td style="text-align:right;">
99.6
</td>
<td style="text-align:right;">
14.3
</td>
<td style="text-align:right;">
19.6
</td>
</tr>
<tr>
<td style="text-align:right;">
0.94
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
788
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
196
</td>
<td style="text-align:right;">
80.2
</td>
<td style="text-align:right;">
6.7
</td>
<td style="text-align:right;">
99.7
</td>
<td style="text-align:right;">
12.5
</td>
<td style="text-align:right;">
19.9
</td>
</tr>
<tr>
<td style="text-align:right;">
0.96
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
788
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
204
</td>
<td style="text-align:right;">
79.4
</td>
<td style="text-align:right;">
2.9
</td>
<td style="text-align:right;">
99.7
</td>
<td style="text-align:right;">
25.0
</td>
<td style="text-align:right;">
20.6
</td>
</tr>
<tr>
<td style="text-align:right;">
0.98
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
790
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
208
</td>
<td style="text-align:right;">
79.2
</td>
<td style="text-align:right;">
1.0
</td>
<td style="text-align:right;">
100.0
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
20.8
</td>
</tr>
</tbody>
</table>
<p>Ce tableau contient des estimations de plusieurs quantités intéressantes, en faisant varier le point de coupure (<code>Niveau de proba</code> dans le tableau <strong>SAS</strong>). Pour chaque point de coupure, ces estimations ont été obtenues à l’aide de la validation-croisée <span class="math inline">\(n\)</span> observations, soit autant de groupes que d’observations. Ainsi, ces estimations sont valides car elles ne sont pas obtenues en utilisant les mêmes observations que celles qui ont servi à estimer le modèle.
La colonne <code>correct</code> donne une estimation du taux de bonne classification, <span class="math inline">\({\mathsf P}\left(Y = \widehat{Y}\right) = 1-{\mathsf P}\left(Y \neq \widehat{Y}\right)\)</span>, ou de manière équivalente un moins le taux de mauvaise classification.</p>
<p>Avec un point de coupure de <span class="math inline">\(0\)</span>, on classifie toutes les observations à la classe achat (<span class="math inline">\(1\)</span>), car <span class="math inline">\(\widehat{p}\)</span> est forcément plus grande que zéro. Le taux de bonne classification dans ce cas de figure sera de <span class="math inline">\(21\)</span>%, puisque 210 individus ont acheté un produit dans le catalogue dans l’échantillon d’apprentissage.
L’autre extrême, avec un point de coupure <span class="math inline">\(c=1\)</span>, donne un taux de bonne classification de <span class="math inline">\(79\)</span>%.</p>
<p>On peut chercher dans le tableau les points de coupure qui donnent le meilleur taux de bonne classification. Ce dernier est de 84,6% et est atteint par trois points de coupure, soit 0,52, soit 0,6, soit 0,62. Une recherche plus fine donne 0,465 comme point de coupure optimal, avec un taux de mauvaise classification de 15,3%.</p>
<p>La <strong>matrice de confusion</strong>, qui compare les vraies valeurs avec les prédictions, peut être construite à partir des colonnes <code>Correct - Événement</code>, <code>Correct - Non-événement</code>, <code>Incorrect - Événement</code>, <code>Incorrect - Non-événement</code>. Il y a deux classifications possibles et le tableau contient, en partant du coin supérieur gauche et dans le sens des aiguilles d’une montre, le nombre de vrai positif (<span class="math inline">\(Y=1\)</span>, <span class="math inline">\(\widehat{Y}=1\)</span>), de faux positif (<span class="math inline">\(Y=0\)</span>, <span class="math inline">\(\widehat{Y}=1\)</span>), de vrai négatif (<span class="math inline">\(Y=0\)</span>, <span class="math inline">\(\widehat{Y}=0\)</span>) et finalement de faux négatif (<span class="math inline">\(Y=1\)</span>, <span class="math inline">\(\widehat{Y}=0\)</span>). Ces nombres proviennent de la validation croisée à <span class="math inline">\(n\)</span> groupes et ne sont pas ceux qu’on obtiendrait si on appliquait directement le modèle ajusté à notre échantillon. Le taux de classification est <span class="math inline">\((\mathsf{FP}+\mathsf{FN})/n\)</span>.</p>
<table>
<caption>
<span id="tab:confumat">Tableau 5.2: </span>Matrice de confusion avec point de coupure 0.465
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
<span class="math inline">\(Y=1\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(Y=0\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\widehat{Y}=1\)</span>
</td>
<td style="text-align:right;">
109
</td>
<td style="text-align:right;">
52
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\widehat{Y}=0\)</span>
</td>
<td style="text-align:right;">
101
</td>
<td style="text-align:right;">
738
</td>
</tr>
</tbody>
</table>
<p>Quatre autres quantités, dérivées à partir de la matrice de confusion, sont parfois utilisées:</p>
<ul>
<li>la <strong>sensibilité</strong> (<em>sensitivity</em>), <span class="math inline">\({\mathsf P}\left(\widehat{Y}=1 \mid Y=1\right)\)</span>, ou <span class="math inline">\(\mathsf{VP}/(\mathsf{VP}+\mathsf{FN})\)</span>;</li>
<li>la <strong>spécificité</strong> (<em>specificity</em>), <span class="math inline">\({\mathsf P}\left(\widehat{Y}=0 \mid Y=0\right)\)</span>, ou <span class="math inline">\(\mathsf{VN}/(\mathsf{VN}+\mathsf{FP})\)</span>;</li>
<li>le <strong>taux de faux positifs</strong>, <span class="math inline">\({\mathsf P}\left(Y=0 \mid \widehat{Y}=1\right)\)</span>, ou <span class="math inline">\(\mathsf{FP}/(\mathsf{VP}+\mathsf{FP})\)</span>;</li>
<li>le <strong>taux de faux négatifs</strong>, <span class="math inline">\({\mathsf P}\left(Y=1 \mid \widehat{Y}=0\right)\)</span>, ou <span class="math inline">\(\mathsf{FN}/(\mathsf{VN}+\mathsf{FN})\)</span>.</li>
</ul>
<p>Les estimés empiriques sont simplement obtenus en calculant les rapports du nombre d’observations dans chaque classe. <strong>SAS</strong> rapporte ces quantités, mais notez les vieilles versions retournent le taux de faux positifs et de faux négatifs dans les deux dernières colonnes, tandis que les sorties des nouvelles version du logiciel donnent les taux de vrais positifs et de vrais négatifs.</p>
<p>La sensibilité mesure à quel point notre modèle est performant pour détecter un vrai positif (classe 1). La spécificité mesure à quel point notre modèle est performant pour détecter un résultat négatif (classe 0).</p>
<p>Plus le point de coupure augmente, plus la sensibilité et le taux de faux positifs diminuent mais plus la spécificité et le taux de faux négatifs augmentent.</p>
<p>La <strong>fonction d’efficacité du récepteur</strong>, parfois appelée courbe ROC (<em>receiver operating characteristic</em>) est parfois utilisée pour représenter globalement la performance du modèle. Elle est obtenue avec l’option <code>plots(only)=(roc)</code> dans <strong>SAS</strong>. Il s’agit du graphe de la sensibilité en fonction de un moins la spécificité, en faisant varier le point de coupure. Un modèle parfait aurait une sensibilité et une spécificité égales à 1 (correspondant au coin supérieur gauche de la fonction d’efficacité du récepteur). Ainsi, plus le couple (<span class="math inline">\(1-\)</span>spécificité, sensibilité) est près de (<span class="math inline">\(0\)</span>, <span class="math inline">\(1\)</span>), meilleur est le modèle. Par conséquent, plus la courbe ROC tend vers (<span class="math inline">\(0\)</span>, <span class="math inline">\(1\)</span>) meilleur est le pouvoir prévisionnel des variables.</p>
<p>L’<strong>aire sous la courbe</strong> (<em>area under the curve</em>) est souvent utilisée en parallèle
est simplement l’aire sous la courbe de la fonction d’efficacité du récepteur. Pour le modèle logistique ajusté, on a une aire sous la courbe de 0,8847. Plus cette valeur est élevée (au plus <span class="math inline">\(1\)</span>), mieux c’est.</p>
<p><img src="figures/03-logistic-e11.png" width="80%" style="display: block; margin: auto;" /></p>
<p>La courbe ROC et la valeur de l’aire sous la courbe (avec l’option <code>plots(only)=(roc)</code>), sont calculées avec les données d’apprentissage et ne sont pas corrigées. Si on veut les utiliser pour comparer des modèles, il faut plutôt utiliser l’option <code>crossvalidate</code> qui permet d’obtenir des estimations des probabilités par validation-croisée avec <span class="math inline">\(n\)</span> groupes tout comme celle utilisée dans le tableau de classification.</p>
<pre class="sas"><code>proc logistic data=train;
model yachat(ref=&#39;0&#39;) = x1 x2 x31 x32 x41-x44 x5-x10;
output out=pred predprobs=crossvalidate;
run;

proc logistic data=pred ;
model yachat(ref=&#39;0&#39;) = x1 x2 x31 x32 x41-x44 x5-x10;
roc pred=xp_1;
run;</code></pre>
<p>On sauvegarde d’abord les probabilités estimées par validation-croisée dans le
fichier <code>pred</code> avec la commande <code>output out=pred predprobs=crossvalidate</code>
La variable <code>xp_1</code> désigne cette probabilité dans le fichier <code>pred</code>. Ensuite, on
exécute de nouveau la procédure <code>logistic</code> avec ce fichier et la commande <code>roc</code>.
L’aire sous la courbe pour les prédictions avec la validation-croisée à <span class="math inline">\(n\)</span> groupes est 0,8723: cet estimé est légèrement inférieur à celui obtenu sans
la correction (trop optimiste) qui est 0,8847.</p>
<p><img src="figures/03-logistic-e15.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Un autre type de graphe qui est souvent utilisé dans des contextes de gestion
est la courbe lift (sic) (en anglais, <em>lift chart</em>). Cette courbe est obtenue en ordonnant les probabilités de succès estimées par le modèle, <span class="math inline">\(\widehat{p}\)</span>, en ordre croissant et en regardant quelle pourcentage de ces derniers seraient bien classifiés (le nombre de vrais positifs sur le nombre de succès).</p>
<p><strong>SAS</strong> ne permet pas de la tracer directement, mais le fichier <code>logit3_lift_chart.sas</code> contient une macro <strong>SAS</strong> qui permet de le faire.</p>
<pre class="sas"><code>proc logistic data=train;
model yachat(ref=&#39;0&#39;) = x1 x2 x31 x32 x41-x44 x5-x10;
output out=pred predprobs=crossvalidate;
run;
%liftchart1(pred,yachat,xp_1,10);</code></pre>
<p>Ici, le tableau présente les 10 déciles. Si on classifiait comme acheteurs les 10% qui ont la plus forte probabilité estimée d’achat, on détecterait 79 des 210 clients (37,6%). En comparaison, on s’attend que 21 clients soient sélectionnés en moyenne si on prend un échantillon aléatoire de 100 personnes. Le ratio 79/21 (dernière colonne) est le <em>lift</em> du modèle: il permet de détecter 3,76 fois plus de succès que le hasard.</p>
<p><img src="figures/03-logistic-e16.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Le graphe <a href="regression-logistique.html#fig:fig3-e17">5.1</a> présente le pourcentage d’observations bien classées parmi les variables (pourcentage des probabilités prédites qui correspondent à un succès parmi les <span class="math inline">\(k\)</span> plus susceptibles selon le modèle). La référence est la ligne diagonale, qui correspond à une détection aléatoire.</p>
<div class="figure" style="text-align: center"><span id="fig:fig3-e17"></span>
<img src="figures/03-logistic-e17.png" alt="Taux de classement en fonction du lift" width="80%" />
<p class="caption">
Figure 5.1: Taux de classement en fonction du lift
</p>
</div>
<p>Il peut être intéressant de vérifier la <strong>calibration</strong> de notre modèle, et une statistique simple proposée par <a href="https://doi.org/10.1002/sim.4780050506">Spiegelhalter (1986)</a> peut être utile à cette fin. Pour une variable binaire <span class="math inline">\(Y \in \{0,1\}\)</span>, l’erreur moyenne quadratique s’écrit
<span class="math display">\[\begin{align*}
\overline{B} &amp;= \frac{1}{n} \sum_{i=1}^n (Y_i-p_i)^2 
=\frac{1}{n} \sum_{i=1}^n(Y_i-p_i)(1-2p_i) + \frac{1}{n} \sum_{i=1}^n p_i(1-p_i).
\end{align*}\]</span>
Le premier terme représente le manque de calibration du modèle, tandis que le deuxième correspond à la séparation entre variables. Si notre modèle était parfaitement calibré, lalors <span class="math inline">\(\mathsf{E}_0(Y_i)=p_i\)</span> et <span class="math inline">\(\mathsf{Var}_0(Y_i) = p_i(1-p_i)\)</span>. On peut utiliser ce fait pour construire une statistique de Wald, <span class="math inline">\(Z = \{\overline{B} - \mathsf{E}_0(\overline{B})\}/\sqrt{\mathsf{Var}_0(\overline{B})}\)</span>, où
<span class="math display">\[\begin{align*}
\mathsf{E}_0(\overline{B})&amp;= \frac{1}{n} \sum_{i=1}^n p_i(1-p_i) \\
\mathsf{Var}_0(\overline{B})&amp;= \frac{1}{n^2} \sum_{i=1}^n p_i(1-p_i)(1-2p_i)^2
\end{align*}\]</span></p>
<p>Sous l’hypothèse nulle de calibration parfaite, <span class="math inline">\(Z \sim \mathsf{No}(0,1)\)</span> en grand échantillon. Pour le modèle simple avec toutes les covariables, la valeur-<span class="math inline">\(p\)</span> approximative calculée avec les probabilités de succès obtenues par validation-croisée et les données de l’échantillon d’apprentissage est 0.22 et il n’y a pas de preuve que le modèle est mal calibré. Cette technique est utile pour vérifier s’il n’y a pas de surajustement (auquel cas le modèle tend à retourner des probabilités très près de 0/1, mais qui ne correspondent pas à la réalité).</p>
</div>
<div id="classification-avec-une-matrice-de-gain" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> Classification avec une matrice de gain</h2>
<p>Utiliser le taux de mauvaise classification <span class="math inline">\({\mathsf P}\left(Y \neq \widehat{Y}\right)\)</span>, comme critère de performance, revient au même que d’utiliser le taux de bonne classification <span class="math inline">\({\mathsf P}\left(Y=\widehat{Y}\right)\)</span>, car <span class="math inline">\({\mathsf P}\left(Y \neq \widehat{Y}\right) = 1-{\mathsf P}\left(Y=\widehat{Y}\right)\)</span>. On veut un modèle avec un haut taux de bonne classification (ou un faible taux de mauvaise classification).</p>
<p>Lorsqu’on utilise <span class="math inline">\({\mathsf P}\left(Y \neq \widehat{Y}\right)\)</span> comme critère pour juger de la qualité d’un modèle prévisionnel, on fait l’hypothèse que le gain associé à bien classifier une observation dans la catégorie 0 lorsqu’elle est réellement dans la catégorie 0 est le même que celui associé à classifier une observation dans la catégorie 1 lorsqu’elle est réellement dans la catégorie 1: cela correspond à la matrice de gain.</p>
<table>
<caption><span id="tab:03-gain1">Tableau 5.3: </span> Matrice de gain correspondant au taux de bonne classification</caption>
<thead>
<tr class="header">
<th></th>
<th></th>
<th align="right">observation</th>
<th align="right"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>gain</td>
<td align="right"><span class="math inline">\(Y=1\)</span></td>
<td align="right"><span class="math inline">\(Y=0\)</span></td>
</tr>
<tr class="even">
<td>prédiction</td>
<td><span class="math inline">\(\widehat{Y}=1\)</span></td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td></td>
<td><span class="math inline">\(\widehat{Y}=0\)</span></td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>C’est-à-dire, le gain vaut 1 lorsque la prévision est bonne (les deux cas sur la diagonale) et 0 lorsque le modèle se trompe (les deux autres cas). L’unité de mesure du gain n’est pas importante pour l’instant. Le gain total est</p>
<p><span class="math display">\[\begin{align*}
\text{gain} &amp;= 1 {\mathsf P}\left(\widehat{Y}=1, Y=1\right) + 1 {\mathsf P}\left(\widehat{Y}=0, Y=0\right) 
\\ &amp;\quad + 0 {\mathsf P}\left(\widehat{Y}=1, Y=0\right)  + 0 {\mathsf P}\left(\widehat{Y}=0, Y=1\right)
\\&amp; = {\mathsf P}\left(Y = \widehat{Y}\right).
\end{align*}\]</span>
Maximiser le gain total revient donc à maximiser le taux de bonne classification.</p>
<p>Dans certaines situations, les gains (ou la perte si le gain est négatif) associés aux bonnes décisions et aux erreurs ne sont pas équivalents. Par exemple, un des types d’erreurs peut être plus grave que l’autre. Il peut alors être souhaitable d’en tenir compte dans le choix du modèle de classification.</p>
<p>Supposons que le gain de classer une observation à <span class="math inline">\(i\)</span> (<span class="math inline">\(i \in \{0,1\}\)</span>) lorsqu’elle vaut <span class="math inline">\(j\)</span> (<span class="math inline">\(j \in \{0,1\}\)</span>) en réalité est de <span class="math inline">\(c_{ij}\)</span>. La matrice de gain est alors</p>
<table>
<caption><span id="tab:03-gain2">Tableau 5.4: </span> Matrice de gain pondérée en fonction d’un coût</caption>
<thead>
<tr class="header">
<th></th>
<th></th>
<th align="right">observation</th>
<th align="right"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>gain</td>
<td align="right"><span class="math inline">\(Y=1\)</span></td>
<td align="right"><span class="math inline">\(Y=0\)</span></td>
</tr>
<tr class="even">
<td>prédiction</td>
<td><span class="math inline">\(\widehat{Y}=1\)</span></td>
<td align="right"><span class="math inline">\(c_{11}\)</span></td>
<td align="right"><span class="math inline">\(c_{10}\)</span></td>
</tr>
<tr class="odd">
<td></td>
<td><span class="math inline">\(\widehat{Y}=0\)</span></td>
<td align="right"><span class="math inline">\(c_{01}\)</span></td>
<td align="right"><span class="math inline">\(c_{00}\)</span></td>
</tr>
</tbody>
</table>
<p>En pratique, l’une de ces quatre quantités peut être fixée à un car seulement les poids relatifs (les ratios) des gains sont importants. Dans ce cas, le gain moyen est
<span class="math display">\[\begin{align*}
\text{gain} &amp;= c_{11} {\mathsf P}\left(\widehat{Y}=1, Y=1\right) + c_{00}{\mathsf P}\left(\widehat{Y}=0, Y=0\right) 
\\ &amp;\quad + c_{10} {\mathsf P}\left(\widehat{Y}=1, Y=0\right)  + c_{01} {\mathsf P}\left(\widehat{Y}=0, Y=1\right)
\end{align*}\]</span></p>
<p>Le meilleur modèle est alors celui qui maximise le gain moyen. Le fichier <code>logit4_macro_gain.sas</code> contient des macros <strong>SAS</strong> qui permettent d’estimer le gain moyen à l’aide de la validation croisée.</p>
<p>Nous allons encore une fois seulement utiliser les 10 variables de base. Mais nous allons intégrer des revenus et coûts afin de trouver le meilleur point de coupure. Rappelez-vous que le coût de l’envoi d’un catalogue est de 10$. Le tableau des variables descriptives qui suit montre que, pour les 210 clients qui ont acheté quelque chose, le revenu moyen est de 67,29$ (moyenne de la variable <code>ymontant</code>).</p>
<p><img src="figures/03-logistic-e18.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Nous allons travailler en termes de revenu net. Nous pouvons donc spécifier la matrice de gain du tableau <a href="regression-logistique.html#tab:03-gain3">5.5</a> pour notre problème. Si on n’envoit pas de catalogue, notre gain est nul. Si on envoie le catalogue à un client qui n’achète pas, on perd 10$ (le coût de l’envoi). En revanche, notre revenu net est de 57$ (revenu moyen moins coût de l’envoi).</p>
<table>
<caption><span id="tab:03-gain3">Tableau 5.5: </span> Matrice de gain pour l’envoi de catalogue</caption>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>observation</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>gain</td>
<td><span class="math inline">\(Y=1\)</span></td>
<td><span class="math inline">\(Y=0\)</span></td>
</tr>
<tr class="even">
<td>prédiction</td>
<td><span class="math inline">\(\widehat{Y}=1\)</span></td>
<td>57</td>
<td><span class="math inline">\(-10\)</span></td>
</tr>
<tr class="odd">
<td></td>
<td><span class="math inline">\(\widehat{Y}=0\)</span></td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>L’appel de la macro <code>manycut_cvlogistic</code>, dont les paramètres sont expliqués dans le script, se fait de la manière suivante:</p>
<pre class="sas"><code>%manycut_cvlogistic(
  yvar=yachat, xvar=x1 x2 x31 x32 
  x41 x42 x43 x44 x5 x6 x7 x8 x9 x10,
  n=1000, k=10, ncv=10, dataset=train,
  c00=0, c01=0, c10=-10, c11=57,
  manycut=.05 .06 .07 .08 .09 .1 .11 .12 .13 .14 .15 .16 .17 .18 .5);</code></pre>
<p>Cette macro produit le tableau suivant. Il donne l’estimation du gain moyen (<code>gain</code>) pour différents points de coupures (<code>cutpoint</code>). Cette estimation provient d’une validation-croisée avec 10 groupes (<code>k=10</code> dans la macro). En fait, on a répété 10 fois (<code>ncv=10</code> dans la macro) la validation croisée avec 10 groupes et fait la moyenne des 10 répétitions afin d’avoir plus de précisions. Il faut essayer plusieurs points de coupure afin de trouver le meilleur.</p>
<p>On voit que le meilleur point de coupure, celui qui maximise le gain est 0,12. Avec ce point de coupure, on estime que le taux de bonne classification est de 0,707 et que la sensitivité est de 0,899. Ainsi, on estime qu’on va détecter 90% des clients qui achètent.
<img src="figures/03-logistic-e19.png" width="60%" style="display: block; margin: auto;" /></p>
<p>On est loin du point de coupure usuel de 0,5 (présenté à la dernière ligne). La raison est simple. Comme il est très coûteux de rater un client qui aurait acheté quelque chose, il est préférable d’envoyer le catalogue à plus de clients, quitte à ce que plusieurs d’entre eux n’achètent rien. En fait, le point de coupure de 0,5 donne un meilleur taux de bonne classification mais un gain moyen plus faible car on rate trop de clients qui achètent (la sensitivité est seulement de 48,8%). Travailler avec la matrice de gain permet de trouver le point de coupure optimal en incorporant des notions de coûts et profits.</p>
<p>Ici, nous avons ajusté un seul modèle, celui contenant uniquement les 10 variables de base et nous nous sommes attardés au choix du point de coupure pour l’assignation aux classes. Il est possible qu’un autre modèle, contenant par exemple des termes d’interactions, des termes quadratiques ou d’autres transformations des variables, soit supérieur à celui-ci. Le choix du modèle de prévision se fait donc souvent en deux étapes</p>
<ol style="list-style-type: decimal">
<li>trouver les bonnes variables</li>
<li>trouver le bon point de coupure.</li>
</ol>
<p>Nous avons déjà vu des méthodes de sélections de variables au chapitre précédent. La section suivante reviendra sur ces méthodes dans le contexte de la régression logistique.</p>
</div>
<div id="sélection-de-variables-en-régression-logistique" class="section level2" number="5.7">
<h2><span class="header-section-number">5.7</span> Sélection de variables en régression logistique</h2>
<p>Les principes généraux, concernant la sélection de variables et de modèles, que nous avons vus au chapitre précédent sont toujours valides. Les critères <span class="math inline">\(\mathsf{AIC}\)</span> et <span class="math inline">\(\mathsf{BIC}\)</span> sont toujours disponibles puisqu’on estime le modèle par maximum de vraisemblance et les techniques générales de division de l’échantillon et de validation-croisée sont toujours valides. Nous allons voir comment appliquer spécifiquement ces techniques au cas de la régression logistique.</p>
<div id="recherche-exhaustive-de-tous-les-sous-modèles" class="section level3" number="5.7.1">
<h3><span class="header-section-number">5.7.1</span> Recherche exhaustive de tous les sous-modèles</h3>
<p>Rappelez-vous qu’avec une variable cible continue, nous avons utilisé avec la procédure <code>reg</code> pour faire une recherche du meilleur sous-ensemble de variables parmi tous les ensembles. Pour ce faire, on sélectionnait le meilleur modèle selon le <span class="math inline">\(R^2\)</span> pour un nombre de variables fixe et il suffisait ensuite de trouver parmi ces variables le meilleur selon le critère d’information choisi.</p>
<p>Une stratégie similaire est possible avec la procédure <code>logistic</code> sauf qu’au lieu de trouver une suite de meilleurs modèles selon le <span class="math inline">\(R^2\)</span>, un autre critère est retenu. Il s’agit de la statistique du score (ou test des multiplicateurs de Lagrange) pour tester si l’ajout d’une variable est utile ou pas.</p>
<p>Ce paragraphe est plus technique et peut être omis. Parce qu’il n’y a pas de solution explicite pour les estimateurs du maximum de vraisemblance du modèle logistique, ajuster chacun de ces modèles est coûteux. La statistique de score, qui est basée sur la vraisemblance, ne nécessite que d’obtenir le maximum de vraisemblance sous l’hypothèse nulle; cela permet d’éviter des ajustements coûteux lors de comparaisons. L’algorithme employé par <strong>SAS</strong> utilise une méthode de recherche arborescente dite méthode de séparation et d’évaluation, qui ne nécessite pas de tester tous les modèles; à noter que la solution à <span class="math inline">\(k\)</span> variables n’est pas nécessairement imbriquée dans celle à <span class="math inline">\(k+1\)</span> variables. Lorsque la taille d’échantillon tend vers l’infini, la statistique du rapport de vraisemblance et la statistique de score sont équivalentes. Choisir le modèle selon la statistique du score équivaut alors à choisir le modèle qui maximise la vraisemblance (ou qui minimise la quantité <span class="math inline">\(-2 \ell\)</span>). Ainsi, pour ce nombre fixé de variables, cela va donner le modèle avec le meilleur <span class="math inline">\(\mathsf{AIC}\)</span> (et <span class="math inline">\(\mathsf{BIC}\)</span>). Par conséquent, on peut trouver le meilleur modèle, globalement, en minimisant le <span class="math inline">\(\mathsf{AIC}\)</span> (ou le <span class="math inline">\(\mathsf{BIC}\)</span>) en faisant varier le nombre de variables. Par contre, cela n’est pas nécessairement vrai pour une taille d’échantillon finie. Le meilleur modèle selon le critère score n’est pas nécessairement celui qui maximise la vraisemblance. Mais en pratique, cette approximation est plus que suffisante et on va procéder comme on a fait avec la procédure <code>reg</code>.</p>
<p>À la section précédente, nous avons inclus les 10 variables de base (14 avec les indicatrices pour les variables catégorielles) dans notre exemple d’envoi ciblé. Nous allons ici faire une recherche de type <code>all-subset</code> parmi ces 14 variables. Le code est dans le fichier <code>logit5_selection_variables.sas</code>.</p>
<pre class="sas"><code>proc logistic data=train;
model yachat(ref=&#39;0&#39;) = x1 x2 x31 x32 x41-x44 x5-x10 / 
  selection=score best=1;
run;</code></pre>
<p><img src="figures/03-logistic-e20.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Le meilleur modèle avec une seule variable, selon la statistique du score, est celui avec <code>x8</code>, le meilleur avec deux variables est celui avec <code>x2</code> et <code>x8</code>, et ainsi de suite. Nous voulons ensuite choisir parmi ces 14 modèles, celui qui minimise le <span class="math inline">\(\mathsf{AIC}\)</span> ou le <span class="math inline">\(\mathsf{BIC}\)</span>. Le problème est que ces critères ne sont pas fournis (contrairement aux sorties de la procédure <code>reg</code>). La solution longue consiste à ajuster chacun de ces modèles, à extraire le <span class="math inline">\(\mathsf{AIC}\)</span> et le <span class="math inline">\(\mathsf{BIC}\)</span> et à ainsi trouver le meilleur modèle. Mais le faire manuellement en spécifiant plusieurs modèles est trop long. La macro <code>logistic_aic_BIC_score</code>, qui se trouve dans le fichier <code>logit6_macro_all_subset.sas</code> ajuste tous ces modèles automatiquement.</p>
<pre class="sas"><code>%logistic_aic_BIC_score(yvariable=yachat,
                        xvariables=x1 x2 x31 x32 x41-x44 x5-x10,
                        dataset=train, minvar=1, maxvar=14);</code></pre>
<p><img src="figures/03-logistic-e21.png" width="80%" style="display: block; margin: auto;" /></p>
<p>On voit que le meilleur modèle selon le <span class="math inline">\(\mathsf{AIC}\)</span> a neuf variables, contre sept pour le <span class="math inline">\(\mathsf{BIC}\)</span>. Nous verrons plus loin, dans un tableau synthèse, comment auraient performé ces modèles s’ils avaient été utilisés pour cibler les clients restants.</p>
</div>
<div id="recherche-séquentielle" class="section level3" number="5.7.2">
<h3><span class="header-section-number">5.7.2</span> Recherche séquentielle</h3>
<p>Faire une recherche de tous les sous-modèles possibles devient impraticable lorsqu’il y a trop de variables en jeu. La procédure <code>logistic</code> permet aussi une recherche de type séquentielle classique. Ceci permet aussi d’utiliser la même approche en deux temps présentée au chapitre précédent. Dans un premier temps, on fait une recherche séquentielle pour sélectionner un nombre de variables qui sera assez petit afin qu’une recherche exhaustive de tous les sous-modèles soit possible. Dans un second temps, on fait cette recherche avec ces variables uniquement. Idéalement, on débute la sélection avec le modèle qui contient toutes les variables, soit <code>start=n</code> où <span class="math inline">\(n=104\)</span> dans notre cas.</p>
<p>Si on inclut tous les termes quadratiques et les termes d’interactions d’ordre deux, nous avons 104 variables potentielles: c’est trop pour une recherche exhaustive.</p>
<p>Faisons d’abord une recherche séquentielle classique avec les 104 variables, en prenant 0.05 comme critère d’entrée et de sortie. Le code est</p>
<pre class="sas"><code>proc logistic data=train;
model yachat(ref=&#39;0&#39;) = x1 x2 x31 x32 x41 x42 x43 x44 x5 x6 x7 x8 x9 x10
cx2 cx6 cx7 cx8 cx9 cx10
i_x2_x1 i_x2_x5 i_x2_x31 i_x2_x32 i_x2_x41 i_x2_x42 i_x2_x43 i_x2_x44
i_x2_x7 i_x2_x6 i_x2_x8 i_x2_x9 i_x2_x10
i_x1_x5 i_x1_x31 i_x1_x32 i_x1_x41 i_x1_x42 i_x1_x43 i_x1_x44
i_x1_x7 i_x1_x6 i_x1_x8 i_x1_x9 i_x1_x10
i_x5_x31 i_x5_x32 i_x5_x41 i_x5_x42 i_x5_x43 i_x5_x44
i_x5_x7 i_x5_x6 i_x5_x8 i_x5_x9 i_x5_x10
i_x31_x41 i_x31_x42 i_x31_x43 i_x31_x44
i_x31_x7 i_x31_x6 i_x31_x8 i_x31_x9 i_x31_x10
i_x32_x41 i_x32_x42 i_x32_x43 i_x32_x44
i_x32_x7 i_x32_x6 i_x32_x8 i_x32_x9 i_x32_x10
i_x41_x7 i_x41_x6 i_x41_x8 i_x41_x9 i_x41_x10
i_x42_x7 i_x42_x6 i_x42_x8 i_x42_x9 i_x42_x10
i_x43_x7 i_x43_x6 i_x43_x8 i_x43_x9 i_x43_x10
i_x44_x7 i_x44_x6 i_x44_x8 i_x44_x9 i_x44_x10
i_x7_x6 i_x7_x8 i_x7_x9 i_x7_x10
i_x6_x8 i_x6_x9 i_x6_x10
i_x8_x9 i_x8_x10
i_x9_x10 
  / selection=stepwise start=104, sle=.05 sls=.05;  
run;</code></pre>
<p><img src="figures/03-logistic-e22.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Il y a eu 17 étapes dans la recherche séquentielle débutant avec le modèle qui ne contient que l’ordonnée à l’origine. La variable <code>i_x7_x8</code> est la première à être incluse, suivie de <code>x2</code> et ainsi de suite. Le modèle final contient 13 variables.
En faisant une recherche séquentielle avec 0.5 comme comme critère d’entrée et de sortie, nous obtenons un sous-ensemble de 47 variables. On peut ensuite faire une recherche exhaustive de tous les sous-modèles avec ces 47 variables en utilisant la macro; le fichier <code>logit5_selection_variables.sas</code> contient le code commenté.</p>
<p>Le modèle qui a le plus petit <span class="math inline">\(\mathsf{AIC}\)</span>, soit 579,701, est un modèle avec 28 variables. Le <span class="math inline">\(\mathsf{BIC}\)</span> mène à un modèle beaucoup plus parcimonieux qui inclut huit variables.</p>
</div>
<div id="algorithme-glouton-et-critères-alternatifs-avec-hpgenselect" class="section level3" number="5.7.3">
<h3><span class="header-section-number">5.7.3</span> Algorithme glouton et critères alternatifs avec <code>hpgenselect</code></h3>
<p>Nous avons vu au chapitre précédent que la procédure <code>glmselect</code> permet de faire une recherche de type séquentielle avec un critère autre que la valeur-<span class="math inline">\(p\)</span> du test de Wald pour rajouter ou retirer des variables explicatives du modèle final. Cette procédure est limitée à la régression linéaire, mais la procédure <code>hpgenselect</code> permet de faire une sélection de variables pour d’autres types de modèles, incluant la régression logistique.</p>
<p>Le code suivant fait une recherche séquentielle en ajoutant ou retranchant les variables selon leur valeur-<span class="math inline">\(p\)</span> (<code>select=sl</code>), la seule méthode disponible pour l’instant. En revanche, le modèle final peut-être choisi selon d’autres critères.</p>
<pre class="sas"><code>proc hpgenselect data=train;
class x3(ref=&#39;3&#39; split) x4(ref=&#39;5&#39; split);
model yachat(ref=&#39;0&#39;)=x1|x2|x3|x4|x5|x6|x7|x8|x9|x10 @2 
 x2*x2 x6*x6 x7*x7 x8*x8 x9*x9 x10*x10 /  
link=logit distribution=binary;
selection method=stepwise(select=sl choose=sbc);
run;</code></pre>
<p>Avec le critère <span class="math inline">\(\mathsf{BIC}\)</span>, on obtient 12 variables tandis que <code>choose=aic</code> donne 13 variables (seule la variable <code>x41</code> est ajoutée). Il s’agit des mêmes variables que celles sélectionnées par une sélection séquentielle classique en prenant 0,05 comme critère d’entrée et de sortie.</p>
</div>
</div>
<div id="performance-des-différents-modèles-pour-lexemple-des-clients-cibles" class="section level2" number="5.8">
<h2><span class="header-section-number">5.8</span> Performance des différents modèles pour l’exemple des clients cibles</h2>
<p>Nous allons conclure, pour l’instant, notre exemple dans cette section, en évaluant la performance de différentes stratégies. Le critère de performance sera le suivant : revenu net de la stratégie si elle était appliquée aux 100 000 clients restants. Pour chacun des 100 000 clients à catégoriser, nous allons calculer la quantité suivante :</p>
<ul>
<li>Si le client n’est pas ciblé pour l’envoi d’un catalogue par le modèle, alors le revenu est nul.</li>
<li>Si le client est ciblé pour l’envoi d’un catalogue par le modèle et qu’il n’achète rien, le revenu est de <span class="math inline">\(-10\)</span>$ (le coût de l’envoi).</li>
<li>Si le client est ciblé pour l’envoi d’un catalogue par le modèle et qu’il achète quelque chose, le revenu est de (<code>ymontant</code><span class="math inline">\(-10\)</span>)$, c’est-à-dire, le montant qu’il dépense moins le <span class="math inline">\(10\)</span>$ du coût de l’envoi.</li>
</ul>
<p>Pour une stratégie donnée, chaque individu n’appartient qu’à une seule des catégories. Le revenu net de la stratégie est la somme des revenus pour les 100 000 clients. Parmi ces derniers, 23 179 auraient acheté si on leur avait envoyé le catalogue et ces clients auraient généré des revenus de 1 601 212$. Si on enlève le coût des envois (100 000 X 10$ = 1 000 000$), on obtient que la stratégie de référence permet un revenu net de 601 212$.</p>
<p>Nous allons investiguer deux types de stratégies :</p>
<ol style="list-style-type: decimal">
<li>une basée sur la régression logistique seulement en utilisant le modèle pour prévoir l’achat et</li>
<li>une basée sur la combinaison de la régression logistique et la régression linéaire en utilisant un modèle pour prévoir l’achat et un autre pour prévoir le montant.</li>
</ol>
<div id="stratégies-en-utilisant-seulement-la-régression-logistique" class="section level3" number="5.8.1">
<h3><span class="header-section-number">5.8.1</span> Stratégies en utilisant seulement la régression logistique</h3>
<p>Dans ce cas, nous allons estimer la probabilité d’achat avec un modèle de régression logistique. Nous allons ensuite trouver le meilleur point de coupure, avec une matrice de gain adéquatement choisie, afin d’avoir une règle d’assignation optimale. Nous avons déterminé des modèles potentiels à la section précédente. De plus, nous avons déjà vu comment trouver le meilleur point de coupure en spécifiant une matrice de gain, afin de maximiser le gain moyen à partir de la matrice de gain du tableau <a href="regression-logistique.html#tab:03-gain3">5.5</a>. Nous allons donc trouver le meilleur point de coupure pour quelques-uns des modèles choisis à la section précédente, pour ensuite évaluer le revenu net de ces modèles.</p>
<p>Il faut encore une fois bien comprendre qu’en pratique, on ne pourrait pas faire cette comparaison, car on ne sait pas d’avance si les clients futurs vont acheter ou non. Mais dans cet exemple, les variables <code>yachat</code> et <code>ymontant</code> sont fournies pour ces 100 000 clients afin qu’on puisse voir ce qui se serait passé avec les différentes stratégies.</p>
<p>La stratégie de référence est celle qui consiste à envoyer le catalogue aux 100 000 clients sans les sélectionner. Le tableau qui suit montre des statistiques pour les variables <code>ymontant</code> et <code>yachat</code> pour les 100 000 clients à scorer. Le tableau <a href="regression-logistique.html#tab:03-summarylog">5.6</a> résume la performance des différentes stratégies basées exclusivement sur le modèle logistique.</p>
<p>Table:</p>
<table>
<caption>
<span id="tab:03-summarylog">Tableau 5.6: </span>Résumé des caractéristiques des modèles logistiques avec (a) référence, soit l’envoi sans sélection à tous les clients; (b) 10 variables de base sans sélection; (c) toutes les variables, incluant les termes quadratiques et les interactions d’ordre 2; (d) sélection séquentielle classique avec critère d’entrée et de sortie à 0,05; (e) idem que (d), mais avec meilleur modèle selon le <span class="math inline">\(\mathsf{AIC}\)</span>; (f) idem que (d), mais avec meilleur modèle selon le <span class="math inline">\(\mathsf{BIC}\)</span>; (g) recherche exhaustive avec 47 variables sélectionnées par recherche séquentielle et modèle final sélectionné selon le <span class="math inline">\(\mathsf{BIC}\)</span>; (h), idem mais sélection avec <span class="math inline">\(\mathsf{AIC}\)</span>. Les points de coupure optimaux ont été déterminés par validation-croisée sur l’échantillon d’apprentissage, tandis que la performance du modèle (sensibilité, taux de faux positifs et taux de bonne classification) ont été calculés à partir de l’échantillon test de 100 000 individus.
</caption>
<thead>
<tr>
<th style="text-align:left;">
modèle
</th>
<th style="text-align:right;">
# variables
</th>
<th style="text-align:right;">
point de coupure
</th>
<th style="text-align:right;">
sensibilité
</th>
<th style="text-align:right;">
taux de faux positifs
</th>
<th style="text-align:right;">
taux de bonne classification
</th>
<th style="text-align:right;">
revenu net
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<ol style="list-style-type: lower-alpha">
<li></td>
<td style="text-align:right;">
—
</td>
<td style="text-align:right;width: 2cm; ">
—
</td>
<td style="text-align:right;width: 2cm; ">
100
</td>
<td style="text-align:right;width: 2cm; ">
76.8
</td>
<td style="text-align:right;width: 2cm; ">
23.2
</td>
<td style="text-align:right;">
601212
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="2" style="list-style-type: lower-alpha">
<li></td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;width: 2cm; ">
0.12
</td>
<td style="text-align:right;width: 2cm; ">
89
</td>
<td style="text-align:right;width: 2cm; ">
56.2
</td>
<td style="text-align:right;width: 2cm; ">
70.9
</td>
<td style="text-align:right;">
940569
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="3" style="list-style-type: lower-alpha">
<li></td>
<td style="text-align:right;">
104
</td>
<td style="text-align:right;width: 2cm; ">
0.08
</td>
<td style="text-align:right;width: 2cm; ">
85.8
</td>
<td style="text-align:right;width: 2cm; ">
52.6
</td>
<td style="text-align:right;width: 2cm; ">
74.6
</td>
<td style="text-align:right;">
937150
</td>
</tr>
<tr>
<td style="text-align:left;">
(d), (e)
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;width: 2cm; ">
0.14
</td>
<td style="text-align:right;width: 2cm; ">
85.7
</td>
<td style="text-align:right;width: 2cm; ">
49.1
</td>
<td style="text-align:right;width: 2cm; ">
77.5
</td>
<td style="text-align:right;">
969350
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="6" style="list-style-type: lower-alpha">
<li></td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;width: 2cm; ">
0.19
</td>
<td style="text-align:right;width: 2cm; ">
81
</td>
<td style="text-align:right;width: 2cm; ">
44.7
</td>
<td style="text-align:right;width: 2cm; ">
80.4
</td>
<td style="text-align:right;">
943935
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="7" style="list-style-type: lower-alpha">
<li></td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;width: 2cm; ">
0.16
</td>
<td style="text-align:right;width: 2cm; ">
86
</td>
<td style="text-align:right;width: 2cm; ">
48.1
</td>
<td style="text-align:right;width: 2cm; ">
78.3
</td>
<td style="text-align:right;">
985069
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="8" style="list-style-type: lower-alpha">
<li></td>
<td style="text-align:right;">
28
</td>
<td style="text-align:right;width: 2cm; ">
0.15
</td>
<td style="text-align:right;width: 2cm; ">
83.5
</td>
<td style="text-align:right;width: 2cm; ">
47.4
</td>
<td style="text-align:right;width: 2cm; ">
78.8
</td>
<td style="text-align:right;">
952672
</td>
</tr>
</tbody>
</table>
Nous avons vu plus tôt, qu’avec les 10 variables de base, le meilleur point de coupure est de 0.12. En utilisant cette stratégie sur les 100 000 clients, le revenu net aurait été de 940 569$. C’est une énorme amélioration, de plus de 56%, par rapport à la stratégie de référence qui consiste à envoyer le catalogue à tout le monde (revenu net de 601 212$). Si on inclut tous les termes quadratiques et les termes les interactions d’ordre deux (104 variables en tout), le revenu net est inférieur avec une valeur de 937 150$. Ici, le modèle est trop complexe et surajusté. Si on fait une sélection de variables (quasi méthodes sont présentées), suivie de la détermination du meilleur point de coupure, on fait alors toujours mieux qu’avec le modèle incluant les 10 variables de base seulement. L’approche qui aurait fait le mieux est la recherche séquentielle pour réduire le nombre de variables considérées à 47, suivi d’une recherche exhaustive pour trouver le modèle avec le plus petit <span class="math inline">\(\mathsf{BIC}\)</span> : cette approche aurait généré 985 069$ de revenus nets. Il s’agit d’un gain de 4.7% par rapport au modèle avec les 10 variables de base.</li>
</ol></li>
</ol></li>
</ol></li>
</ol></li>
</ol></li>
</ol>
</div>
<div id="stratégies-alternatives" class="section level3" number="5.8.2">
<h3><span class="header-section-number">5.8.2</span> Stratégies alternatives</h3>
<p>Nous venons tout juste d’étudier des stratégies qui consistent essentiellement, à estimer <span class="math inline">\({\mathsf P}\left(\texttt{yachat}=1\right)\)</span> et un point de coupure afin de décider à qui envoyer le catalogue en partant du postulat que tous les clients dépensent le même montant; le tout est basé uniquement sur la régression logistique. Le revenu moyen peut être estimé à partir de l’équation
<span class="math display">\[{\mathsf E}\left(\texttt{ymontant}\right) = {\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right) {\mathsf P}\left(\texttt{yachat
}=1\right),
\]</span>
c’est-à-dire, la moyenne du montant dépensé est égale à la moyenne du montant dépensé étant donné qu’il y a eu achat, fois la probabilité qu’il ait eu achat. Une autre stratégie possible consiste donc à développer deux modèles : un pour <span class="math inline">\({\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right)\)</span> et un autre pour <span class="math inline">\({\mathsf P}\left(\texttt{yachat}=1\right)\)</span> et à les combiner afin d’obtenir des prévisions du montant dépensé.</p>
<p>Nous avons déjà développé des modèles de régression linéaire pour <span class="math inline">\({\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right)\)</span> au chapitre précédent et nous venons de développer des modèles de régression logistique pour <span class="math inline">\({\mathsf P}\left(\texttt{yachat}=1\right)\)</span> dans ce chapitre. Nous avons donc tous les ingrédients pour implanter cette stratégie.</p>
<p>Nous allons cibler les clients dont la prévision du montant dépensé est plus grande que 10$ (le coût de l’envoi du catalogue).</p>
<p>Les possibilités de modèles sont nombreuses. Par exemple, si on a cinq modèles potentiels pour <span class="math inline">\({\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right)\)</span> et cinq pour <span class="math inline">\({\mathsf P}\left(\texttt{yachat}=1\right)\)</span>, il y a 25 combinaisons possibles. Ici, nous allons seulement présenter les résultats pour deux combinaisons :</p>
<ol style="list-style-type: decimal">
<li>pour <span class="math inline">\(\texttt{ymontant}\)</span>, nous allons utiliser les variables choisies par <code>glmselect</code> avec les options <code>select=aic, choose=bic</code>, tandis que pour <span class="math inline">\(\texttt{yachat}\)</span>, nous allons utiliser les variables choisies par la procédure séquentielle suivie d’une recherche exhaustive avec le critère BIC</li>
<li>à la fois pour <span class="math inline">\(\texttt{ymontant}\)</span> et <span class="math inline">\(\texttt{yachat}\)</span>, nous allons utiliser les variables choisies en faisant une sélection séquentielle classique (tests-<span class="math inline">\(t\)</span>) avec critères d’entrée et de sortie fixés à 0,05.</li>
</ol>
<p>Pour obtenir les prévisions, nous allons estimer conjointement les modèles pour <span class="math inline">\({\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right)\)</span> et pour <span class="math inline">\({\mathsf P}\left(\texttt{yachat}=1\right)\)</span> avec un modèle Tobit de type 2 (aussi appelé modèle Heckit), dont une brève description est donnée dans la section <a href="regression-logistique.html#tobit2">5.8.3</a>.
L’avantage de l’estimation simultanée est que l’on a pas à sélectionner le point de coupure, puisque l’on enverra le catalogue uniquement si le montant prédit pour <span class="math inline">\({\mathsf E}\left(\texttt{ymontant}\right)\)</span> (non-conditionnel) est supérieur à 10$.
Les résultats du modèle Tobit sur l’échantillon de validation sont rapportés dans le tableau <a href="regression-logistique.html#tab:03-tobit">5.7</a>.</p>
<table>
<caption>
<span id="tab:03-tobit">Tableau 5.7: </span>Matrice de gain pour l’envoi de catalogue avec des modèle Tobit de type II: sensibilité, taux de faux positifs et de bonne classification et gain net de la stratégie.
</caption>
<thead>
<tr>
<th style="text-align:left;">
modèle
</th>
<th style="text-align:right;">
sensibilité
</th>
<th style="text-align:right;">
FP (%)
</th>
<th style="text-align:right;">
bonne classification (%)
</th>
<th style="text-align:right;">
revenu net
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<ol style="list-style-type: decimal">
<li></td>
<td style="text-align:right;width: 2.5cm; ">
88.3
</td>
<td style="text-align:right;width: 2.5cm; ">
50.9
</td>
<td style="text-align:right;width: 2.5cm; ">
76.1
</td>
<td style="text-align:right;">
997 238
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="2" style="list-style-type: decimal">
<li></td>
<td style="text-align:right;width: 2.5cm; ">
86.3
</td>
<td style="text-align:right;width: 2.5cm; ">
49.9
</td>
<td style="text-align:right;width: 2.5cm; ">
76,9
</td>
<td style="text-align:right;">
977 422
</td>
</tr>
</tbody>
</table></li>
</ol></li>
</ol>
<p>Il s’avère qu’on aurait eu des performances semblables aux stratégies basées uniquement sur la régression logistique vues à la sous-section précédente. La première combinaison aurait tout de même produit un revenu net de 997 238$, supérieur au revenu net de 985 069$, qui était le meilleur trouvé à la sous-section précédente.</p>
<p>Pour conclure cet exemple, il s’avère donc que la régression logistique permet d’effectuer un bon ciblage des clients potentiels afin de maximiser les revenus. L’approche générale consistant à obtenir des prévisions pour <span class="math inline">\({\mathsf P}\left(\texttt{yachat}=1\right)\)</span> et ensuite trouver le meilleur point de coupure est très générale. D’autres types de modèles (arbre de classification, forêt aléatoire, réseau de neurones) pourraient être utilisés à la place de la régression logistique.</p>
<p>Nous reviendrons une dernière fois sur cet exemple dans le chapitre traitant des données manquantes. Nous verrons alors comment procéder si des valeurs manquantes sont présentes dans les variables explicatives.</p>
</div>
<div id="tobit2" class="section level3" number="5.8.3">
<h3><span class="header-section-number">5.8.3</span> Modèle Tobit de type 2</h3>
<p>Cette partie est plus technique et peut être omise.</p>
<p>Il ne serait pas justifié d’ajuster séparément les deux modèles pour <span class="math inline">\({\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right)\)</span> et <span class="math inline">\({\mathsf P}\left(\texttt{yachat}=1\right)\)</span> et de calculer les prévisions en prenant le produit: <span class="math inline">\({\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right){\mathsf P}\left(\texttt{yachat}=1\right)\)</span>. Cela provient du fait que le modèle pour <span class="math inline">\({\mathsf E}\left(\texttt{ymontant} \mid \texttt{yachat}=1\right)\)</span> aurait été estimé seulement avec les clients qui ont acheté quelque chose et qu’ensuite on l‘appliquerait (au moment de calculer les prévisions) à la fois aux clients qui vont acheter et à ceux qui ne vont pas acheter. Il y a donc un biais de sélection dans l’échantillon qui a servi à ajuster le modèle au départ. Une manière de contourner ce problème est d’ajuster conjointement les deux modèles. Le modèle de Tobit de type 2 permet de faire cela. Ce modèle est basé sur l’hypothèse que les deux variables observées (<span class="math inline">\(Y_1\)</span> et <span class="math inline">\(Y_2\)</span>) proviennent de deux variables latentes non observées (<span class="math inline">\(Y_1^{\star}\)</span> et <span class="math inline">\(Y_2^{\star}\)</span>), où
<span class="math display">\[\begin{align*}
Y_1 = \begin{cases}
1 &amp; \text{ si } Y_1^{\star} \ge 0, \\
0 &amp; \text{ si } Y_1^{\star} &lt; 0,
\end{cases}
\qquad \qquad 
Y_2 = \begin{cases}
Y_2^{\star} &amp; \text{ si } Y_1^{\star} \ge 0, \\
0 &amp; \text{ si } Y_1^{\star} &lt; 0.
\end{cases}
\end{align*}\]</span>
Dans notre exemple, <span class="math inline">\(Y_1\)</span> correspond à <span class="math inline">\(\texttt{yachat}\)</span> et <span class="math inline">\(Y_2\)</span> à <span class="math inline">\(\texttt{ymontant}\)</span>.
Ce qui lie les deux équations est le fait qu’on suppose que les variables sont binormales: les deux termes d’erreur sont de loi normale et sont corrélés, <span class="math inline">\(\boldsymbol{\varepsilon} \sim \mathcal{N}_2(\boldsymbol{0}_2, \boldsymbol{\Sigma})\)</span>. Les variables dépendantes observées sont :
<span class="math display">\[\begin{align*}
Y_{1}^{\star} &amp;= \beta_{01} + \beta_{11} X_{11} + \cdots + \beta_{1p}X_{p1} + \varepsilon_{1}\\
Y_{2}^{\star} &amp;= \beta_{02} + \beta_{12} X_{12} + \cdots + \beta_{1p}X_{q2} + \varepsilon_{2}
\end{align*}\]</span>
Notez que les variables explicatives ne sont pas nécessairement les mêmes dans les deux équations. En estimant conjointement les deux équations, on élimine le biais de sélection mentionné plus haut. La procédure <code>qlim</code> permet d’estimer ce modèle. Cependant, <code>qlim</code> ne fait pas de sélection de variables. Le choix des variables doit être fait avant avec les méthodes qu’on a vues. De plus, pour être précis, le modèle Tobit ajuste un modèle probit et non logistique à la variable binaire.</p>
</div>
</div>
<div id="extensions-du-modèle-de-régression-logistique-à-plus-de-deux-catégories" class="section level2" number="5.9">
<h2><span class="header-section-number">5.9</span> Extensions du modèle de régression logistique à plus de deux catégories</h2>
<p>Supposons que la variable <span class="math inline">\(Y\)</span> que vous cherchez à modéliser est une variable catégorielle pouvant prendre trois valeurs ou plus. Voici quelques exemples :</p>
<ul>
<li>Destination de vacances l’année dernière (Québec, États-Unis, ailleurs).</li>
<li>Si les élections avaient lieu aujourd’hui au Québec, pour quel parti voteriez-vous (PLQ, PQ, CAQ, QS).</li>
<li>Combien de fois êtes-vous allé au cinéma l’année dernière: moins de cinq fois (<span class="math inline">\(\texttt{1}\)</span>), entre cinq et 10 fois (<span class="math inline">\(\texttt{2}\)</span>), ou plus de 10 fois (<span class="math inline">\(\texttt{3}\)</span>).</li>
<li>Quelle importance accordez-vous au service après-vente? Un parmi « pas important » (<span class="math inline">\(\texttt{1}\)</span>), « peu important »(<span class="math inline">\(\texttt{2}\)</span>), « moyennement important » (<span class="math inline">\(\texttt{3}\)</span>), « assez important » (<span class="math inline">\(\texttt{4}\)</span>), « très important » (<span class="math inline">\(\texttt{5}\)</span>).</li>
</ul>
<p>Dans les deux premiers exemples, la variable réponse <span class="math inline">\(Y\)</span> est nominale (elle n’a pas d’ordre) alors qu’elle est ordinale dans les deux derniers. Pour une variable ordinale, le modèle logit multinomial peut être utilisé mais il existe d’autres possibilités comme le modèle logit cumulé. Nous couvrirons ces deux modèles.</p>
<div id="régression-logistique-multinomiale" class="section level3" number="5.9.1">
<h3><span class="header-section-number">5.9.1</span> Régression logistique multinomiale</h3>
<p>Afin de simplifier la notation, on suppose qu’il y a une seule variable explicative <span class="math inline">\(X\)</span> à disposition et que la variable <span class="math inline">\(Y\)</span> représente trois catégories, une parmi 0, 1 et 2.</p>
<p>En régression logistique, <span class="math inline">\(Y\)</span> est une variable binaire qui vaut soit 0, soit 1 et la probabilité de succès est
<span class="math display">\[\begin{align*}
\ln\left(\frac{p_i}{1-p_i}\right) = \beta_0 + \beta_1 X_{i}, \qquad p_i = {\mathsf P}\left(Y_i=1 \mid X_i\right) = \mathrm{expit}(\beta_0 + \beta_1X_i).
\end{align*}\]</span>
Dans ce modèle logistique, <span class="math inline">\(\ln(p_i)-\ln(1-p_i) = \ln\{{\mathsf P}\left(Y_i=1 \mid X_i\right)\} - \ln\{{\mathsf P}\left(Y_i=0 \mid X_i\right)\}\)</span> peut être vu comme étant le logit de la catégorie 1 en utilisant 0 comme catégorie de référence.
Le modèle logistique multinomial procède de même en fixant une catégorie de référence et en modélisant le logit de chacune des autres catégories par rapport à la catégorie de référence. Avec <span class="math inline">\(K+1\)</span> catégories et en choisissant la catégorie 0 comme référence, le modèle devient
<span class="math display">\[\begin{align*}
 \ln\left(\frac{p_{i1}}{p_{i0}}\right) = \beta_{01} + \beta_{11} X_i, \, \ldots, \, \ln\left(\frac{p_{iK}}{p_{i0}}\right) = \beta_{0K} + \beta_{1K} X_i,
\end{align*}\]</span>
où <span class="math inline">\(p_{ik} = {\mathsf P}\left(Y_i=k \mid X_i\right)\)</span> <span class="math inline">\((k=0, \ldots, K)\)</span>. Comme en régression logistique, on peut facilement exprimer ce modèle en termes des différentes probabilités,
<span class="math display">\[\begin{align*}
 p_{i0} &amp;= {\mathsf P}\left(Y_i=0 \mid X_i\right) = \frac{1}{1+ \sum_{j=1}^K\exp(\beta_{0j}+\beta_{1j}X_i)}\\
 p_{ik} &amp;= {\mathsf P}\left(Y_i=k \mid X_i\right) = \frac{\exp(\beta_{0k}+\beta_{1k}X_i)}{1+ \sum_{j=1}^K\exp(\beta_{0k}+\beta_{1k}X_i)}, \qquad k =1, \ldots, K.
\end{align*}\]</span>
On voit facilement que la somme des probabilités égale 1, c’est-à-dire <span class="math inline">\(p_{i0} + \cdots + p_{iK} = 1\)</span>. En fait, le modèle logit multinomial ne fait que combiner plusieurs logit dans un seul modèle. L’interprétation des paramètres se fait comme en régression logistique sauf qu’il faut y aller équation par équation.</p>
<p>Destination vacances. Le fichier <code>logit6.sas7bdat</code> contient 100 observations obtenues par voie de sondage auprès d’adultes âgés de 18 à 45 ans. Le fichier contient les réponses aux questions suivantes:</p>
<ul>
<li><code>y1</code>: quelle a été votre destination vacances l’année dernière: Québec (<span class="math inline">\(\texttt{0}\)</span>), États-Unis (<span class="math inline">\(\texttt{1}\)</span>) ou ailleurs (<span class="math inline">\(\texttt{2}\)</span>)?</li>
<li><code>y2</code>: combien de fois êtes-vous allé au cinéma l’année dernière: moins de 5 fois (<span class="math inline">\(\texttt{1}\)</span>), entre 5 et 10 fois (<span class="math inline">\(\texttt{2}\)</span>), ou plus de 10 fois (<span class="math inline">\(\texttt{3}\)</span>).</li>
<li><code>x</code>: âge (en année) du répondant.</li>
</ul>
<p>Nous allons modéliser la destination vacance <span class="math inline">\(Y_1\)</span> à l’aide d’une régression logistique multinomiale avec l’âge comme variable explicative.</p>
<p><img src="figures/03-logistic-e31.png" width="50%" style="display: block; margin: auto;" /></p>
<p>On voit que les gens qui ont passé leurs vacances au Québec (<span class="math inline">\(Y_1=0\)</span>) ont 26.5 ans en moyenne. Ils sont plus jeunes que ceux qui ont passé leurs vacances aux États-Unis (âge moyen de 33 ans). Finalement, ceux dont la destination vacances était ailleurs sont les plus vieux avec une moyenne de 37.3 ans.</p>
<p>Pour le modèle logit multinomial, nous allons prendre <span class="math inline">\(Y_1=0\)</span> comme catégorie de référence. Les commandes sont</p>
<pre class="sas"><code>proc logistic data=multi.logit6 ;
model y1(ref=&#39;0&#39;) = x / clparm=pl clodds=pl expb link=glogit;
run; </code></pre>
<p>L’option <code>link=glogit</code> spécifie le type de fonction de lien, ici celle du modèle logistique multinomial.</p>
<p><img src="figures/03-logistic-e23.png" width="75%" style="display: block; margin: auto;" /></p>
<p><img src="figures/03-logistic-e24.png" width="80%" style="display: block; margin: auto;" /></p>
<p><img src="figures/03-logistic-e25.png" width="82%" style="display: block; margin: auto;" /></p>
<p>Comme il y a trois catégories pour la variable dépendante, il y a deux équations pour le modèle ajusté,
<span class="math display">\[\begin{align*}
\ln \left\{\frac{{\mathsf P}\left(Y_{1i}=1 \mid X_i\right)}{{\mathsf P}\left(Y_{1i}=0 \mid X_i\right)} \right\} = -4.10 + 0.13X_i, \qquad \qquad \ln \left\{\frac{{\mathsf P}\left(Y_{1i}=2 \mid X_i\right)}{{\mathsf P}\left(Y_{1i}=0 \mid X_i\right)} \right\} = -7.98+0.22X_i. 
\end{align*}\]</span></p>
<p>Plus l’âge du répondant augmente, plus la probabilité qu’il ait passé ses vacances aux États-Unis par rapport au Québec augmente. En fait, pour chaque augmentation de 1 de l’âge, le rapport des cote pour <span class="math inline">\(Y_1=1\)</span> par rapport à <span class="math inline">\(Y_1=0\)</span> est multipliée par <span class="math inline">\({1.133}=\exp({0.1253})\)</span>. Cette valeur est donnée dans la dernière colonne du tableau. De plus, cet effet est significatif car la valeur-<span class="math inline">\(p\)</span> est inférieure à <span class="math inline">\(10^{-4}\)</span>.</p>
<p>De même, plus l’âge du répondant augmente, plus la probabilité qu’il ait passé ses vacances ailleurs qu’aux États-Unis ou au Québec par rapport au Québec augmente. En fait, pour chaque augmentation de l’âge d’un an, le rapport des cote pour <span class="math inline">\(Y_1=1\)</span> par rapport à <span class="math inline">\(Y_1=0\)</span> est multiplié par <span class="math inline">\({1.25}\)</span>. Cet effet est également statistiquement significatif.</p>
<p>Nous venons donc de comparer chacune des catégories <span class="math inline">\(Y_1=1\)</span> et <span class="math inline">\(Y_1=2\)</span> à la catégorie de référence <span class="math inline">\(Y_1=0\)</span>. Pour une comparaison directe entre <span class="math inline">\(Y_1=1\)</span> et <span class="math inline">\(Y_1=2\)</span>, il suffit de changer la catégorie de référence et de resoumettre le programme <strong>SAS</strong>.</p>
</div>
<div id="régression-logistique-cumulative-à-cotes-proportionnelles" class="section level3" number="5.9.2">
<h3><span class="header-section-number">5.9.2</span> Régression logistique cumulative à cotes proportionnelles</h3>
<p>Si les modalités de la réponse sont ordinales, la régression logistique multinomiale est toujours appropriée. Il peut néanmoins être préférable d’utiliser un modèle qui utilise l’ordre des modalités pour obtenir un modèle plus facile à interpréter et plus parcimonieux. Le modèle de régression logistique cumulative à cotes proportionnelles est un simplification sous l’hypothèse que les cotes sont proportionnelles.</p>
<p>Supposons que la variable <span class="math inline">\(Y\)</span> est ordinale et peut prendre les <span class="math inline">\(K+1\)</span> valeurs ordonnées de la plus petite à la plus grande selon les catégories de <span class="math inline">\(Y\)</span> (<span class="math inline">\(0, 1, 2, \ldots, K\)</span>). Supposons que l’on dispose de <span class="math inline">\(p\)</span> variables explicatives <span class="math inline">\(X_1, \ldots, X_p\)</span>.</p>
<p>Soit <span class="math inline">\(p_{ik}={\mathsf P}\left(Y_i \mid X_{i1}, \ldots, X_{ip}\right)\)</span> (<span class="math inline">\(k=0, 1, \ldots, K\)</span>) la probabilité que <span class="math inline">\(Y_{ik}\)</span> prenne la valeur <span class="math inline">\(k\)</span>. On dénote la fonction de survie
<span class="math display">\[S_{ij}=\sum_{k=j}^K p_{ik}= {\mathsf P}\left(Y_{i} \geq j\mid X_{i1}, \ldots, X_{ip}\right), \qquad j=1, \ldots, K.
\]</span>
La quantité <span class="math inline">\(S_{ij}\)</span> est la probabilité que <span class="math inline">\(Y_i\)</span> soit plus grand ou égal à <span class="math inline">\(j\)</span>; <span class="math inline">\(S_{i0}\)</span> est égal à 1 et <span class="math inline">\(S_{ik} = {\mathsf P}\left(Y_i=K \mid X_{i1}, \ldots, X_{ip}\right)=p_{iK}\)</span>.</p>
<p>Le modèle logistique cumulé spécifie que
<span class="math display">\[\begin{align*}
\ln \left( \frac{S_{ij}}{1-S_{ij}}\right) = \beta_{0j} + \beta_1 X_{i1} + \cdots + \beta_p X_{ip}, \qquad \qquad  j=1, \ldots, K.
\end{align*}\]</span></p>
<p>Il y a donc <span class="math inline">\(K-1\)</span> équations logistiques. Les paramètres quantifiant les effets des variables explicatives, <span class="math inline">\(\beta_1, \ldots, \beta_K\)</span> sont les mêmes pour chacune des log-cotes, mais il y a une ordonnée à l’origine différente par log de rapport de cote. Par conséquent, pour modéliser une variable ordinale <span class="math inline">\(Y\)</span> ayant <span class="math inline">\(K+1\)</span> valeurs possibles avec p variables explicatives, le modèle cumulatif logistique utilise <span class="math inline">\(p + K\)</span> paramètres. Le modèle logit multinomial, qui peut également être utilisé pour les données ordinales, utilise <span class="math inline">\(p\cdot (K+1)\)</span> paramètres. Le modèle multinomial ordonné est donc plus parcimonieux et, pour autan qu’il soit approprié, mènera à des estimations des paramètres plus précises qu’avec le modèle de régression logistique multinomiale. Les deux modèles sont identiques au modèle de régression logistique si la variable ordinale a deux modalités.</p>
<p>La cote <span class="math inline">\(S_{ij}/(1-S_{ij})\)</span> mesure à quel point il est plus probable que <span class="math inline">\(Y_i\)</span> prenne une valeur plus grande ou égale à <span class="math inline">\(j\)</span> par rapport à une valeur plus petite que <span class="math inline">\(j\)</span>, viz.
<span class="math display">\[\begin{align*}
\frac{S_{ij}}{1-S_{ij}} = \exp( \beta_{0j} + \beta_1X_{i1} + \cdots + \beta_p X_{ip}).
\end{align*}\]</span>
Dans cet exemple, aucune fonction autre qu’additive en <span class="math inline">\(X\)</span>, ni aucune interaction n’est présente. Si le paramètre <span class="math inline">\(\beta_j\)</span> est positif, cela indique que plus <span class="math inline">\(X_j\)</span> prend une valeur élevée, plus la variable <span class="math inline">\(Y\)</span> a tendance à prendre aussi une valeur élevée. Inversement, si le paramètre <span class="math inline">\(\beta_j\)</span> est négatif, cela indique que plus <span class="math inline">\(X_j\)</span> prend une valeur élevée, plus la variable <span class="math inline">\(Y\)</span> a tendance à prendre une valeur basse. Plus précisément, pour chaque augmentation d’une unité de <span class="math inline">\(X_j\)</span>, la cote <span class="math inline">\(S_k/(1-S_k)\)</span> est multipliée par <span class="math inline">\(\exp(\beta_j)\)</span>, peu importe la valeur de <span class="math inline">\(Y\)</span>. Ainsi, la cote d’être dans une catégorie plus élevée, par rapport à une catégorie moins élevée, est multipliée par <span class="math inline">\(\exp(\beta_j)\)</span>. En terme de probabilités cumulées d’excéder <span class="math inline">\(k\)</span>,
<span class="math display">\[\begin{align*}
S_{ik} = {\mathsf P}\left(Y_i \geq k \mid X_{i1}, \ldots, X_{ip}\right) = \mathrm{expit}(\beta_{0k} + \beta_1 X_{i1} + \cdots + \beta_p X_{ip}), \qquad j =1, \ldots, K.
\end{align*}\]</span>
En utilisant ces expressions, on peut obtenir la probabilité de chaque catégorie,
<span class="math display">\[\begin{align*}
{\mathsf P}\left(Y_i = k \mid X_{i1}, \ldots, X_{ip}\right) ={\mathsf P}\left(Y_i \geq k \mid X_{i1}, \ldots, X_{ip}\right) -{\mathsf P}\left(Y_i \geq k+1 \mid X_{i1}, \ldots, X_{ip}\right) = S_{k} - S_{k+1}.
\end{align*}\]</span></p>
<p>Nous considérons maintenant la variable <span class="math inline">\(Y_2\)</span> du fichier <code>logit6.sas7bdat</code>, qui donne le nombre de visites au cinéma. Pour cet exemple, nous allons chercher à modéliser <span class="math inline">\(Y_2\)</span> à l’aide de <span class="math inline">\(X\)</span> (âge) en utilisant le modèle multinomial cumulé à cotes proportionnelles.</p>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:right;">
y2
</th>
<th style="text-align:right;">
n
</th>
<th style="text-align:right;">
moyenne
</th>
<th style="text-align:right;">
écart-type
</th>
<th style="text-align:right;">
minimum
</th>
<th style="text-align:right;">
maximum
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
44
</td>
<td style="text-align:right;">
33.5
</td>
<td style="text-align:right;">
7.23
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
44
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
38
</td>
<td style="text-align:right;">
30.4
</td>
<td style="text-align:right;">
8.16
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
44
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
25.1
</td>
<td style="text-align:right;">
6.58
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
39
</td>
</tr>
</tbody>
</table>
<p>Ainsi, les répondants qui sont allés moins de cinq fois au cinéma ont en moyenne 33.5 ans, ceux qui sont allés entre cinq et 10 fois ont 30.4 ans en moyenne, et ceux qui sont allés plus de 10 fois ont 25.1 ans en moyenne. Il y a une progression et on voit que les répondants plus jeunes vont plus souvent au cinéma.</p>
<p>Nous utilisons exactement le même programme que pour une régression logistique habituelle. Si la variable <span class="math inline">\(Y\)</span> prend plus de deux valeurs, <strong>SAS</strong> utilisera automatiquement le modèle de régression multinomiale cumulé.</p>
<pre class="sas"><code>proc logistic data=multi.logit6 descending;
model y2 = x / clparm=pl clodds=pl expb;
run;</code></pre>
<p>L’option <code>descending</code> impose la paramétrisation discutée précédemment. Sans cette option, ce serait plutôt les probabilités de prendre une valeur plus petite, par rapport à une plus grande qui serait modélisée. Le modèle est le même, mais les signes des paramètres des variables explicatives seraient inversés.</p>
<p><img src="figures/03-logistic-e26.png" width="80%" style="display: block; margin: auto;" /></p>
<p><img src="figures/03-logistic-e27.png" width="80%" style="display: block; margin: auto;" /></p>
<p><img src="figures/03-logistic-e28.png" width="80%" style="display: block; margin: auto;" /></p>
<p><img src="figures/03-logistic-e29.png" width="80%" style="display: block; margin: auto;" /></p>
<p><img src="figures/03-logistic-e30.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Avant toute chose, il faut s’assurer que le modèle est approprié. Rappelez-vous que l’une des hypothèses de ce modèle est que les effets des variables explicatives sont les mêmes pour chaque équation. Le tableau « Test de score pour l’hypothèse des cotes proportionnelles » est un test de l’hypothèse nulle</p>
<ul>
<li><span class="math inline">\(\mathcal{H}_0\)</span> : l’effet de chaque variable est le même pour les <span class="math inline">\(K\)</span> logit du modèle multinomial logistique, soit <span class="math inline">\(\beta_{11} = \cdots =\beta_{1K}\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(\beta_{p1} = \cdots =\beta_{pK}\)</span>.</li>
</ul>
<p>Une très petite valeur-<span class="math inline">\(p\)</span> (rejet de <span class="math inline">\(\mathcal{H}_0\)</span>) pour ce test serait une indication que le modèle de régression multinomiale ordinale n’est pas approprié. Comme la valeur-<span class="math inline">\(p\)</span> est 0.2577 ici, on ne rejette pas <span class="math inline">\(\mathcal{H}_0\)</span> et il n’y a pas lieu de douter de cette hypothèse. On peut donc aller de l’avant et interpréter le modèle.</p>
<p>Ici, l’effet estimé de l’âge (<span class="math inline">\(X\)</span>) est <span class="math inline">\(-{0.0916}\)</span> et ce paramètre est significativement différent de zéro (valeur-<span class="math inline">\(p\)</span> de 0.0004). Rappelez-vous que <span class="math inline">\(Y_2\)</span> représente le nombre d’entrées au cinéma dans la dernière année.</p>
<p>Ainsi, plus l’âge augmente, plus <span class="math inline">\(Y_2\)</span> a tendance à prendre une petite valeur, c’est-à-dire, plus la personne a tendance à aller moins souvent au cinéma. Plus précisément, lorsque l’âge augmente de 1, la cote d’être dans une catégorie plus élevée de <span class="math inline">\(Y_2\)</span>, par rapport à une catégorie plus basse, est multipliée par 0.912 (la cote diminue donc et aussi la probabilité d’être dans une catégorie plus élevée).</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="selection-modele.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="analyse-survie.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MATH60602.pdf"],
"toc": {
"collapse": "section",
"split_by": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
